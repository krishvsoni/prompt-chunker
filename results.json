{
  "summary": {
    "pypdf": {
      "docs_processed": 4,
      "total_docs": 4,
      "total_chunks": 4,
      "avg_chunks_per_doc": 1.0,
      "avg_chunk_length": 59757.5,
      "avg_quality_score": 0.0,
      "relevant_chunks": 4,
      "relevance_pct": 100.0,
      "optimal_size_chunks": 1,
      "optimal_pct": 25.0,
      "total_time": 5.57
    },
    "sherpa": {
      "docs_processed": 0,
      "total_docs": 4,
      "total_chunks": 0,
      "avg_chunks_per_doc": 0.0,
      "avg_chunk_length": 0,
      "avg_quality_score": 0,
      "relevant_chunks": 0,
      "relevance_pct": 0,
      "optimal_size_chunks": 0,
      "optimal_pct": 0,
      "total_time": 22.94
    },
    "prompt": {
      "docs_processed": 3,
      "total_docs": 4,
      "total_chunks": 85,
      "avg_chunks_per_doc": 21.25,
      "avg_chunk_length": 2804.4,
      "avg_quality_score": 0.47,
      "relevant_chunks": 85,
      "relevance_pct": 100.0,
      "optimal_size_chunks": 2,
      "optimal_pct": 2.4,
      "total_time": 351.39
    }
  },
  "results": [
    {
      "pypdf": {
        "chunks": [
          {
            "chunk_id": "pypdf_0",
            "title": "__entire_document__",
            "text": "Design and Scheduling of an AI-based Queueing System\nJiung Lee1 Hongseok Namkoong2 Yibo Zeng2\nCoupang1 Columbia University2\njiunglee28@gmail.com namkoong@gsb.columbia.edu yibo.zeng@columbia.edu\nAbstract\nTo leverage prediction models to make optimal scheduling decisions in service systems, we\nmust understand how predictive errors impact congestion due to externalities on the delay\nof other jobs. Motivated by applications where prediction models interact with human servers\n(e.g., content moderation), we consider a large queueing system comprising of many single server\nqueues where the class of a job is estimated using a prediction model. By characterizing the\nimpact of mispredictions on congestion cost in heavy traffic, we design an index-based policy that\nincorporates the predicted class information in a near-optimal manner. Our theoretical results\nguide the design of predictive models by providing a simple model selection procedure with\ndownstream queueing performance as a central concern, and offer novel insights on how to design\nqueueing systems with AI-based triage. We illustrate our framework on a content moderation\ntask based on real online comments, where we construct toxicity classifiers by finetuning large\nlanguage models.\n1 Introduction\nRecent advances in predictive models present significant opportunities for utilizing unstructured\ninformation such as images and text to solve real-world sequential decision-making problems. A\nmajor challenge to effective decision-making is modeling complex endogenous interactions. For\ninstance, prioritizing a particular job in a service system incurs negative externalities that affect the\ncongestion of other jobs. Building effective scheduling policies requires a fundamental understanding\nof how decisions based on (potentially erroneous) predictions propagate through the system.\nIn this paper, we explore the use of predictive information to allocate scarce resources across\nstochastic workloads. We are motivated by content moderation systems on social media, a critical\nprocess for maintaining the health and sustainability of online platforms. Delays in removing\nviolating posts (e.g., hate speech) can exacerbate their negative impact. While clear-cut cases can\nbe filtered out by an initial AI-based filtering system, nuanced moderation requires human reviewers\nto account for nonstationary social contexts and avoid unnecessary censorship and violations of\nfreedom of speech [3, 39].\nWe model content moderation as a large-scale service system involving human reviewers and\nstate-of-the-art AI models (Figure 1). To ensure fairness and similar workload between human\nreviewers, jobs are typically assigned to different human reviewers in an identically random manner.\nThe dynamic scheduling problem can thus be reduced to a single-server queuing system for each\nhuman reviewer, where jobs are categorized into different classes according to toxicity and whether\nthe content targets protected demographic features such as race or religion. Online platforms incur\ndifferential cost of delay across job classes depending on their potential harm, and AI models present\nopportunities to utilize predictions of harm based on sophisticated content and user features.\nThe random assignment assumption allows us to model the system as a set of single-server\nqueues where job classes (e.g., toxicity) are a priori unknown. Here, misclassifications have endoge-\nnous impact on congestion since prioritizing a job delays the processing of others. To minimize the\n1\narXiv:2406.06855v1  [math.OC]  11 Jun 2024\n\n1\nFiltering \nSystem\nContents \ufb02agged for review\nContents deemed safe by AI-based \ufb01ltering system\n\u2026\nHuman  \nreviewers\nrandomly \nassigned\nContents require human review\n\u0393\n2\u2026\nEach reviewer\nAI model\nGI/GI/1 queue with \npredicted classes\nContents require \nhuman review\nAn AI model classifies each content into  \npredicted job classes  green ,  pink ,  red \nFigure 1. Schematic of a content moderation system as a triage system. Each content\nmay be violating the user agreement (red toxicity symbol) or considered safe (green checkmark).\nThis ground truth requires human review to uncover (\u201cservice\u201d). Contents are flagged for review by\nusers or automated filters, which we view as \u201centering\u201d the triage system. The online platform uses\nan initial AI model to filter out contents most deemed to be safe. Then, remaining jobs/contents\nare randomly assigned to the human reviewers, a common practice due to fairness considerations in\nterms of mental workload. An AI model classifies each content into different classes (e.g., hate speech\non a protected group), placing them in the corresponding virtual queue for the predicted class.\noverall cost, we must balance heterogeneous service rates\u2014such as political misinformation being\nharder to review than nudity\u2014and the adverse effects of congestion, like toxic content going viral,\nby accounting for how misclassification errors reverberates through the queueing system.\nWhen the class of every job is known, a simple index-based myopic policy\u2014the oracle G c\u00b5-\nrule\u2014is optimal in highly congested systems [63, 40]. Concretely, consider a single-server queue\nwith K distinct job classes with arrival and service rates \u03bbk and \u00b5k, which we assume are known\nto the modeler. Let Ck(\u00b7) be a convex cost function defined on sojourn time of jobs in class\nk = 1, . . . , K(time between job arrival and service completion). The oracle G c\u00b5-rule is intuitive\nand simple: it greedily prioritizes jobs with the highest marginal cost of delay\nargmax\nk\u2208[K]\n\u00b5k(t)(Ck)\u2032(ak(t)) Oracle G c\u00b5-rule, (1.1)\nwhere ak(\u00b7) is the age or the waiting time of the oldest unfinished job of class k.\nWhen the true classes are unknown, we predict the job class using a classifier. Letting \u03bbl and\n\u00b5l be the arrival and service rates for a predicted class l, a naive adaptation of the G c\u00b5-rule is\nargmax\nl\u2208[K]\n\u00b5l(t)(Cl)\u2032(al(t)) Naive G c\u00b5-rule, (1.2)\nwhere al(\u00b7) is the age or the waiting time of the oldest unfinished job with predicted class l (Defini-\ntion 2). This index policy does not consider misclassifications and ignores the fact that delay cost\ndepends on the true class label instead of the predicted class: the delay cost of a content depends\non whether it is toxic, rather than the prediction of toxicity. This mismatch leads to suboptimal\nscheduling decisions as we show in Theorem 3 to come.\nWe propose and analyze an index policy that optimally incorporates the impact of prediction\nerrors in the overall cost of delay. We consider the weighted average of true class costs Ck using\nthe conditional probability that a job predicted as class l belongs to class k\nCl(t) :=\nKX\nk=1\npkqklPK\nk\u2032=1 pk\u2032 qk\u2032l\n\u00b7 Ck(t), t \u2208 [0, \u221e), (1.3)\n2\n\n20 40 60 80\nAverage Cumulative Cost\n1\n10\n100# of Hyperparameters\n# of Hyperparameters\nCDF\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nCDF\nFigure 2. Histogram of average cumulative\nqueueing cost of deep Q-learning policies over\n672 hyperparameter configurations.\nOracle Gc\n Our Method DRL\n6.0\n6.5\n7.0\n7.5\n8.0\n8.5Cumulative Cost\nFigure 3. Cumulative cost with 2 \u00d7 stan-\ndard errors\nwhere pk is the probability that an arbitrary job in the system belongs to class k, and qkl is the\nprobability that an arbitrary class k job is predicted as class l. This gives rise to the index rule\nargmax\nl\u2208[K]\n\u00b5l(t)(Cl)\u2032(al(t)) P c\u00b5-rule, (1.4)\nwhich is easy to implement since the arrival rates and misclassification errors that determine Cl(t)\ncan be efficiently estimated. In the specific case of linear delay costs and steady-state waiting time\nas the performance metric, the Pc\u00b5-rule bears resemblance to Argon and Ziya [4, Section 8]\u2019s policy\ndefined with conditional distributions of the true classes given the signal from a job. In contrast,\nwe model increasing marginal cost of delay in content moderation through strongly convex cost\nfunctions and prove (heavy traffic) optimality over all feasible policies, in contrast to Argon and\nZiya [4]\u2019s analysis focusing on dominance over first-come-first-serve policies.\nOffline deep reinforcement learning (DRL) methods are a popular contender to sequential\ndecision-making. While flexible, DRL methods require significant engineering efforts to be reli-\nably trained [29, 66, 16], and the performance of DRL methods is known to be highly sensitive to\nhyperparameters, implementation details, and even random seeds [29]. On a single-server queue\nwith 10 classes, we observe that deep Q-learning policies with experience replay exhibits substantial\nvariation in performance across hyperparameters, even when using identical instant rewards func-\ntions, training/testing enviroments, and same random seeds across training runs (Figure 2). The\nsimple index policy P c\u00b5-rule significantly outperforms the best-performing DRL hyperparameter\nconfiguration (Figure 3), as we illustrate in detail in Section 5.\nIn contrast to the growing body of work on learning in queueing that develop online learning\nalgorithms [13, 34, 36, 59, 65, 22], we propose an off-policy method to model applications where\nexperimentation is risky or unwieldy. This reflects operational constraints that arise from modern\nAI-based service systems where models are trained offline using previously collected data. Since\nwe assume service times are determined by true classes, in principle observed service times contain\ninformation about true class labels that can be used to improve the classifier in real time. Even\nin the largest industrial scenarios, however, online learning requires prohibitive infrastructure due\nto the high engineering complexity required for implementation. Any prediction model must be\nthoroughly validated prior to deployment, and the timescale for model development is typically\nlonger (weeks to months) than that for scheduling decisions (hours to days). We thus view our\noffline heavy traffic analysis to be an useful analytic device for modeling AI-based queueing systems\nthat operate close to system capacity. See Section 8 for a thorough literature review.\n3\n\nContributions Our work contributes to the growing literature studying the interface between\npredictive models and decision-making [4, 41, 57, 33, 12, 60]. Prediction is rarely the end goal\nin operational scenarios, but the link between predictive performance and downstream decision-\nmaking performance is complex due to endogeneity\u2014misclassifications have downstream impact on\ndelays. This work crystallizes how classical tools from queueing theory can be modified to provide\nmanagerial insights on the control and design of AI-based service systems.\nSince solving for the optimal scheduling policy is computationally intractable even when job\nclasses are known due to large state/policy spaces [46], we study highly congested systems in the\nheavy traffic limit as is standard in the queueing literature [50, 63, 28, 68, 40]. Our theoretical\nframework characterizes the optimal queueing performance in the presence of misclassification errors\n(Sections 3, 4), and offers several insights on the design of AI-based service systems like the one\nwe study in Figure 1. Along the way, we identify a number of technical errors in the classical\nframework [63] and identify conditions under which prior results hold by giving corrected proofs\nbased on our new techniques.\nFirst, we derive a simple scheduling algorithm (1.4) with strong optimality and robustness\nguarantees by analyzing the stochastic fluctuations in the queue lengths of the unobservable true\nclass jobs, and aggregating them to represent the fluctuation in the queue length of each predicted\nclass (Section 3). We quantify the optimal workload allocation across the predicted classes and\nderive the Pc\u00b5 cost function from the KKT conditions of the optimal resource allocation problem\nin the heavy traffic limit (3.4) (Section 4). Our theoretical results show that the P c\u00b5-rule induces\nqueueing dynamics that achieve the asymptotic optimality with exogenous costs Cl(\u00b7).\nNext, we study the design of AI models with a central focus on decision-making. Although\npredictive performance is rarely the final goal, models are typically validated based on predictive\nmeasures such as precision or recall for convenience. But overparameterized models (e.g., neural\nnetworks) can achieve the same predictive performance, yet exhibit very different downstream deci-\nsion performance [17, 8]. We quantify the connection between predictive performance and the cost\nof delay, allowing us to design AI models with downstream decision-making performance as a cen-\ntral concern (Section 6). We propose a model selection procedure based on the cumulative queueing\ncost, and demonstrate its advantages in contrast to conventional model selection approaches in ML\nthat solely rely on predictive measures.\nFinally, we use our characterization of the optimal queueing cost under misclassifications to\ninform the design of the queueing system itself. In the context of our motivating content mod-\neration problem, we design an AI-based triaging system that helps determine staffing levels and\ncorresponding filtering levels based on predictions from an initial round AI model (which may or\nmay not be the same model used to classify jobs into classes). We propose a holistic framework\ntrading off filtering cost, predictive performance, hiring costs, and congestion in the queueing sys-\ntem (Section 7). Our formulation significantly contributes to the practical discussion on designing\ncontent moderation systems, which traditionally focuses on pure prediction metrics [2, 54, 67, 1].\nIn Section 7.4, we demonstrate that traditional prediction-based metrics may accurately reflect the\noverall costs of a triage system when either filtering costs or hiring costs are the predominant fac-\ntor. However, these metrics fall short in more complex scenarios where there are trade-offs between\ndifferent types of costs. As a result, optimizing for these metrics typically requires computationally\nexpensive queueing simulations. In contrast, our method reliably determines the optimal staffing\nand filtering levels across all scenarios by simulating a (reflected) Brownian motion.\n4\n\n2 Model\nWe begin by presenting our analytic framework in the heavy traffic regime. There are two possible\ndata generating processes we can study. We could view jobs as originating from a single common\narrival process, where interarrival times are independent of job features, true classes labels, and\nservice times. This single arrival stream allows us to disentangle the arrival and service processes\nof predicted classes, and directly use the diffusion limit to show optimality of the P c\u00b5-rule. On\nthe other hand, we may consider a more general generating process where the arrival and service\nprocesses for different classes are exogenously given. In this setting, we can still show similar\nmathematical guarantees as under the single stream model using heavy traffic analysis techniques\npioneered by Mandelbaum and Stolyar [40]. However, this proof approach weakens our optimality\nresults: we can only show optimality of the P c\u00b5-rule over first-come-first-serve policies, whereas\nunder the single stream model, the direct analysis allows proving optimality over all feasible policies\n(see Section B.4). Furthermore, this proof approach requires more restrictive regularity conditions\nthan the direct method that is possible under the single arrival stream model\u2014see Section E.3\nfor a detailed discussion. We view the practical modeling capabilities of the two data generating\nassumptions to be similar; the singe arrival stream is a good model of the content moderation\nsystem (as depicted in Figure 1). Henceforth, we thus focus on the single common arrival process\nfor expositional clarity and crisp mathematical results.\nWe consider a sequence of single-server multi-class queueing systems indexed by n \u2208 N, con-\nnected through a heavy traffic condition. Each system n operates on a finite time horizon [0 , n],\nand starts empty. Let un\ni be i.i.d. interarrival times with an arrival rate \u03bbn. For t \u2208 [0, n], let\nUn\n0 (t) := P\u230at\u230b\ni=1 un\ni be the arrival time of the \u230at\u230bth job in the system and An\n0 (t) = max{m : Un\n0 (m) \u2264\nt} be the total number of jobs that arrive up to time t. For each class k, let pn\nk := Pn[Y n\n1k = 1]\nbe the class prevalence and ( \u00b5n\nk)\u22121 := En[vn\n1 | Y n\n1k = 1] the expected service time. For each job, a\ntuple (Xn\ni , Yn\ni , vi) is generated independently of its interarrival time un\ni where Xn\ni \u2208 Rd represents\nthe feature vector associated with the ith job, vn\ni indicates the time required to serve the ith job,\nand Y n\ni = ( Y n\ni1, ..., Yn\niK) denotes the one-hot encoded representation of its true class label. Let\nV n\n0 (t) := P\u230at\u230b\ni=1 vn\ni , \u2200 t \u2208 [0, n] be the total service time required by the first \u230at\u230b jobs.\nA classifier f\u03b8 predicts a class for each job i using observed features Xn\ni , and the job i joins the\n(virtual) queue corresponding to the (one-hot encoded) predicted class Y n\ni := f\u03b8(Xn\ni ) to wait for\nservice. Let qn\nkl := Pn[Y n\n1l = 1 | Y n\n1k = 1] be the probability of a class k job being predicted as class\nl; Qn := (qn\nkl)k,l\u2208[K] is the confusion matrix.\nWe assume service time is conditionally independent of the covariates given the true class label\nY n\ni , vn\ni \u22a5 Xn\ni | Y n\ni , which simplies our anlysis by only considering true class label\u2019s impact on\nservice time. In practice, if covariates influence service time (e.g., content length), we can mitigate\nsuch dependency by creating more fine-grained true classes. We summarize our data generating\nprocess as in the following assumption.\nAssumption A (Data Generating Processes). For any system n \u2208 N, i) {(un\ni , vn\ni , Xn\ni , Yn\ni ) : i \u2208 N}\nis a sequence of i.i.d. random vectors, ii) {un\ni : i \u2208 N} and {(vn\ni , Xn\ni , Yn\ni ) : i \u2208 N} are independent,\nand iii) for any i \u2208 N, vn\ni and Xn\ni are conditionally independent given Y n\ni .\nThe following assumption formalizes the notion of heavy traffic.\n5\n\nAssumption B (Heavy Traffic Condition). Given a classifier f\u03b8 and a sequence of queueing sys-\ntems, there exist pk, qkl \u2208 [0, 1] and \u03bb, \u00b5k such that PK\nk=1 pkqkl > 0, \u03bb PK\nk=1\npk\n\u00b5k\n= 1, and\nn1/2\u0000\n\u03bbn \u2212 \u03bb\n\u0001\n\u2192 0, n 1/2\u0000\n\u00b5n\nk \u2212 \u00b5k\n\u0001\n\u2192 0, n 1/2\u0000\npn\nk \u2212 pk\n\u0001\n\u2192 0, n 1/2\u0000\nqn\nkl \u2212 qkl\n\u0001\n\u2192 0. (2.1)\n\u03bbn \u2212 \u03bb = o(n\u22121/2) and \u00b5n\nk \u2212 \u00b5k = o(n\u22121/2) aligns with classical assumptions [40, Eq. (2)], and as\nusual we have that traffic intensity \u03c1n := \u03bbn P\nk pn\nk/\u00b5n\nk converges to 1 at o(n\u22121/2)-rate\nn1/2[\u03c1n \u2212 1] = n1/2\nh\n\u03bbn\nKX\nk=1\npn\nk\n\u00b5n\nk\n\u2212 1\ni\n\u2192 0. (2.2)\nThe convergence rates in Assumption B are necessary for the results in Theorem 2 and Theorem 3\nto come.\nNotation Let C be the space of continuous [0, 1] 7\u2192 R functions, D the set of the right-continuous\nwith left limits (RCLL); all stochastic processes will be RCLL. Let Dk be its product space and\n\u2225x(t)\u2225 := maxi\u2208[k] |xi(t)|. Define dJ1(\u00b7, \u00b7) : D \u00d7 D \u2192R+ to be the J1 (Skhorohod) metic [68, Page\n79]. For any vector-valued functions x(t), y(t) \u2208 Dk, define dp(x, y) = Pk\ni=1 dJ1(xi, yi) [68, Page 83]\nand its topology W J1 (weak J1 topology). For a stochastic process, An\nk(t), the underlined format\nis used to denote the counterpart process associated with the predicted class, An\nl (t).\n3 Lower bound on queueing cost\nOur analysis relies on a diffusion limit for predicted classes of the model. Scheduling is based on\npredicted classes, but service times are determined by the true classes. We characterize how mis-\nclassifications incur externalities on other jobs, and derive the optimal queueing cost in Theorem 2\nto come. Compared to classical results in queueing that assume job classes are known [63, Proposi-\ntion 6], our analysis requires handling the unobservable queue lengths of true classes as mentioned\nearlier; see the discussion in Section C.1.\nWhen the job classifier is \u201cperfect\u201d, we haveQn = I where Qn is the confusion matrix defined in\nthe previous section. In this case, our setting reduces to the classical setting where true classes are\nknown, and our proofs to come give the counterpart results in Van Mieghem [63] and Mandelbaum\nand Stolyar [40]. Even in this classical setting, our analysis identifies missing assumptions (e.g.,\nthe zero limits in Assumption B) and provides proofs of missing arguments in Van Mieghem [63],\nMandelbaum and Stolyar [40].\n3.1 Convergence of endogenous processes\nDefine the counting processes for arrivals and service completions in the predicted classes. Let the\nl-th component of An : [0, n] \u2192 NK be the number of jobs that are predicted as class l until time\nt \u2208 [0, n], and similarly let Sn : [0, n] \u2192 NK count service completions as a function of the total\ntime that the server dedicates to each predicted class. Let \u00b5n\nl be the service rate of jobs in predicted\nclass l, with \u00b5l as the corresponding limit. For ease of exposition, we defer a formal discussion of\ndiffusion limits Section A and defer precise definitions to Section B.3.\nFeasible Policies A scheduling policy \u03c0n is characterized by an allocation process Tn : [0, n] \u2192\nRK whose l-th coordinate denotes the total time dedicated to predicted class l up to t \u2208 [0, n].\n6\n\nWe use \u03c0n and Tn interchangably. Let Nn(t) : [0 , n] \u2192 NK be the queue length process; its\nl-th coordinate denotes total jobs from predicted class l remaining in system at t \u2208 [0, n]. Let\nIn(t) := t \u2212 P\nl Tn\nl (t) be the cumulative idling time up to t \u2208 [0, n]. The scheduler has full\nknowledge of arrivals and the queue of predicted classes.\nDefinition 1 (Feasible Policies). The sequence of scheduling policies {\u03c0n} is feasible if the associ-\nated processes {Tn(t), Nn(t), In(t)} satisfy for all n \u2208 N,\n(i) Tn(0) = 0, Tn is continuous and nondecreasing, Nn \u2265 0, and In is nondecreasing;\n(ii) {Tn(t), t\u2208 [0, n]} is adapted to the filtration \u03c3{(An(s), Nn(s)) : 0 \u2264 s < t}.\nCondition (i) is natural, and condition (ii) ensures that {\u03c0n} only relies on arrivals and queue\nstatus of predicted classes up to time t. We allow preemption (preemptive-resume policy) so that\nthe server is able to pause serving one job and switch to another in a different predicted class.\nPreemption is not allowed between jobs from the same predicted class, consistent with classical\nsettings [40].\nCumulative Queueing Cost Our goal is to minimize the cumulative queueing cost determined\nby true class labels. For a true class k job, its queueing cost is Cn\nk (\u03c4) where \u03c4 is sojourn time.\nLet \u03c4n\nlj be the sojourn time of the jth job of predicted class l, and \u03c4 n = {\u03c4n\nl }l\u2208[K] be the sojourn\ntime process tracking that of the most recently arriving job in predicted class l by time t, i.e.,\n\u03c4n\nl (t) = \u03c4n\nlAn\nl (t). Since ( \u03c4n\nl )l\u2208[K] is of order n1/2 (see Proposition 1 to come), we also assume\ncommensurate scaling on {Cn\nk }k\u2208[K] in Assumption C.\nAssumption C (Cost functions I) . For all k \u2208 [K], Cn\nk (\u00b7) is differentiable, nondecreasing, and\nconvex for all n. There exists a continuously differentiable and strictly convex function Ck with\nC\u2032\nk(0) = 0 such that Cn\nk (n1/2\u00b7) \u2192 Ck(\u00b7) and n1/2(Cn\nk )\u2032(n1/2\u00b7) \u2192 C\u2032\nk(\u00b7) uniformly on compact sets.\nThe scaled cumulative cost function incurred by \u03c0n is\n\u02dcJn\n\u03c0n(t; Qn) = n\u22121\nKX\nl=1\nKX\nk=1\nZ nt\n0\nCn\nk (\u03c4n\nl (s))dAn\nkl(s), \u2200 t \u2208 [0, 1], (3.1)\nwhere dAn\nkl is the the Lebesgue-Stieltjes measure induced byAn\nkl. \u02dcJn\n\u03c0n(t; Qn) relies on the scheduling\npolicy via the sojourn time process {\u03c4n\nl }. Similar to the classical settings [63, 40], we study p-\nFCFS policies\u2014those serving each predicted class in a first-come-first-served manner. Given a\nfeasible policy \u03c0n, we can reorder service within each predicted class to derive a feasible p-FCFS\ncounterpart, \u03c0n,p-FCFS, which dominates the original policy stochastically, i.e., Pn[ \u02dcJn\n\u03c0n,p-FCFS(t) >\nx] \u2264 Pn[ \u02dcJn\n\u03c0n(t) > x], \u2200 x \u2208 R, t \u2208 [0, 1] (see Lemma 11). Since the objective (3.1) does not\ninclude preemption cost like [63, 40], work-conserving policies\u2014the server never idles when jobs\nare present\u2014dominates non-work-conserving policies in cumulative cost \u02dcJn a.s. (see Lemma 12).\nThus, we henceforth focus on p-FCFS and work-conserving feasible policies.\nSample path analysis Let \u02dcUn\n0 , \u02dcV n\n0 be diffusion-scaled versions of partial sums of interarrival\nand service times:\n\u02dcUn\n0 (t) = n\u22121/2[Un\n0 (nt) \u2212 (\u03bbn)\u22121 \u00b7 nt], \u02dcV n\n0 (t) = n\u22121/2[V n\n0 (nt) \u2212\nnX\nk=1\npn\nk\n\u00b5n\nk\n\u00b7 nt], t \u2208 [0, 1]. (3.2)\n7\n\nIn Lemma 3 to come, we show there exist Brownian motions (\u02dcU0, \u02dcV0) such that (\u02dcUn\n0 , \u02dcV\nn\n0 ) \u21d2 ( \u02dcU0, \u02dcV 0)\nin (D2, W J1). Building off of our diffusion limit, we can strengthen the convergence to the uniform\ntopology using standard tools (e.g., see Lemma 6 and Lemma 7), and conduct a sample path\nanalysis where we construct copies of ( \u02dcUn\n0 , \u02dcV n\n0 ) and ( \u02dcU0, \u02dcV0) that are identical in distribution with\ntheir original counterparts and converge almost surely under a common probability space. With a\nslight abuse of notations, we use the same notation for the newly construced processes.\nSample path analysis allows us to leverage properties of uniform convergence and significantly\nsimplifies our analysis. All subsequent results and their proofs in the appendix, will be established\non the copied processes in the common probability space (\u2126 copy, Fcopy, Pcopy) with probability\none, i.e., Pcopy-a.s., and all of the convergence results will be understood to hold in the uniform\nnorm \u2225 \u00b7 \u2225. For instance, Lemma 3 can be strengthen to ( \u02dcUn\n0 , \u02dcV\nn\n0 ) \u21d2 ( \u02dcU0, \u02dcV 0) in ( D2, \u2225 \u00b7 \u2225),\nPcopy \u2212 a.s. as shown in Lemma 4. Also, in Lemma 10 to come, the diffusion-scaled process for\nAn\n0 converges to \u02dcA0 in ( D2, W J1), Pcopy \u2212 a.s., where \u02dcA0 a function of \u02dcU0. In addition, since\nthese newly constructed processes are identical in distribution with their original counterparts, all\nsubsequent results regarding almost sure convergence for the copied processes can be converted into\ncorresponding weak convergence results for the original processes; see more discussion in Theorems 2\nand 3.\nConvergence of the Endogenous processes Let Wn : [0, n] \u2192 RK be the remaining workload\nprocess representing the service requirement of remaining\u2014waiting or being served\u2014jobs predicted\nas class l at t \u2208 [0, n]. Then, Wn\n+(t) = P\nl Wn\nl (t) is the total remaining workload. Let \u02dcWn\n+, \u02dcW\nn\n,\n\u02dc\u03c4 n, and \u02dcN\nn\nbe the diffusion-scaled processes corresponding to Wn\n+, Wn, \u03c4 n, and Nn.\nProposition 1 (Fundamental Convergence Results). Under Assumptions A, B, and H, and any\nwork-conserving p-FCFS feasible policy\n(i) (Invariant Convergence) \u02dcWn\n+ \u2192 \u02dcW+ := \u03d5\n\u0010\n\u02dcV0 \u25e6 \u03bbe + PK\nk=1\npk\n\u00b5k\n\u02dcA0\n\u0011\n, where \u03d5 is the reflection\nmapping as defined in [68, Page 140, (2.5)];\n(ii) (Equivalence of Convergence) For any predicted class l \u2208 [K], lim supn \u2225 \u02dcT\nn\nl \u2225, lim supn \u2225 \u02dcN\nn\nl \u2225,\nlim supn \u2225\u02dc\u03c4n\nl \u2225, and lim supn \u2225 \u02dcW\nn\nl \u2225 are all bounded for any predicted class l \u2208 [K]. Moreover,\nif any of the processes \u02dcT\nn\nl , \u02dcN\nn\nl , \u02dc\u03c4n\nl , or \u02dcW\nn\nl converges, then all of \u02dcT\nn\nl , \u02dcN\nn\nl , \u02dc\u03c4n\nl , and \u02dcW\nn\nl converge.\nProposition 1 extends the classical results of Van Mieghem [63, Proposition 2] by relaxing the\nassumption that true classes are known. When true classes are known, convergence for arrival\nand service processes of true classes ( \u02dcAn and \u02dcSn) can be derived directly via the the Functional\nCentral Limit Theorem (FCLT) [63, Assumption 1]. In comparison, our generalization requires\nnovel analysis approaches to establish convergence of diffusion-scaled arrival and service processes\nof predicted classes ( \u02dcA\nn\nand \u02dcS\nn\n) in Proposition 6. Specifically, we exploit the joint convergence\nresult in Lemma 4 and characterize how misclassifications impact each subprocess. We develop\nnovel connections from the primitives \u02dcZ\nn\nand \u02dcR\nn\nto \u02dcA\nn\nand \u02dcS\nn\n, which involves techniques of\nrandom time change and continuous mapping approach. We give the full proof in Section B.1.\n3.2 Asymptotic lower bound of the scaled delay cost function\nWe are now ready to present the main result of this section, the asymptotic lower bound for the\ncumulative queueing cost in the heavy traffic limit. Our lower bound motivates the design of the\nPc\u00b5-rule in Section 4. For predicted class l \u2208 [K], we let \u03c1l := P\nk\n\u03bbpkqkl\n\u00b5k\n> 0 (Assumption B).\n8\n\nTheorem 2 (Heavy-traffic lower bound). Given a classifier f\u03b8 and a sequence of queueing systems,\nsuppose that Assumptions A, B, C, and H hold. Under any feasible scheduling policies {\u03c0n}, the\nassociated sequence of cumulative costs { \u02dcJn\n\u03c0n(\u00b7; Qn) : n \u2208 N} satisfies\nlim inf\nn\u2192\u221e\n\u02dcJn\n\u03c0n(t; Qn) \u2265 \u02dcJ\u2217(t; Q) :=\nKX\nk=1\nKX\nl=1\nZ t\n0\n\u03bbpkqklCk\n\u0010\u0002\nh\n\u0000 \u02dcW+(s)\n\u0001\u0003\nl\n\u03c1l\n\u0011\nds, \u2200t \u2208 [0, 1], (3.3)\nPcopy-a.s., where h(r) is an optimal solution to the following resource allocation problem\nOpt(r) := min\nx\nKX\nl=1\nKX\nk=1\n\u03bbpkqklCk\n\u0010xl\n\u03c1l\n\u0011\ns.t.\nKX\nl=1\nxl = r, x l \u2265 0, \u2200 l \u2208 [K].\n(3.4)\nMoreover, for the original processes under Pn, under any feasible policies {\u03c0\u2032\nn},\nlim inf\nn\u2192\u221e\nPn[ \u02dcJn\n\u03c0\u2032n\n(t; Qn) > x] \u2265 Pcopy[ \u02dcJ\u2217(t; Q) > x], \u2200 x \u2208 R, \u2200 t \u2208 [0, 1]. (3.5)\nAccording to Proposition 1, \u02dcW+ is solely determined by the exogenous processes \u02dcA0 and \u02dcV0. Con-\nsequently, the lower bound in Theorem 2 is independent of the scheduling policy Tn. Our proof is\ninvolved and deferred to Section C, where we also contrast our analytic approach to classical proof\ntechniques.\n4 Heavy-traffic optimality of the P c\u00b5-rule\nWe are ready to formally derive the P c\u00b5-rule, which is motivated by the convex optimization\nproblem (3.4). We prove heavy traffic optimality of the P c\u00b5-rule by showing that it attains the\nlower bound in Theorem 2. Our result (Theorem 3) extends the classical result in Van Mieghem\n[63, Proposition 7].\nWhile not the main contribution of this work, our analytic framework extend the standard\nheavy traffic analysis techniques [63, 40] in subtle ways as we detail in Sections E.2 and E.3. Even\nwhen specialized to the classical setting of known true classes, our analysis fills gaps in classical\nproofs for the optimality of the Gc\u00b5-rule [63] and D-Gc\u00b5 [40]. The two methods use ages of waiting\njobs, but only establish optimality stated in terms of the sojourn times . To bridge this gap, we\nprovide a rigorous proof in Proposition 13. The proof of the proposition is nontrivial (to us) and\nreveals a necessary condition that was previously unstated in [63]: strong convexity of the cost\nfunctions. Also, our analysis circumvents the stronger assumptions on the cost functions in [40] in\nthe single-server case by directly analyzing the age dynamics. See Sections E.3 for details.\nWe first characterize the limiting cumulative cost of a convergent policy. Let let \u00afAkl be the limit\nof n\u22121An\nkl(n\u00b7) (see Definition 10 for a formal statement). In the following, \u02dcJ\u03c0(t; Q) is dependent on\n\u02dc\u03c4 = {\u02dc\u03c4l}l\u2208[K] through the subscript \u03c0.\nLemma 1 (Convergence of \u02dcJn\n\u03c0n(\u00b7; Qn)). Given a classifier f\u03b8, suppose that Assumption A, B, C,\nand H hold. For feasible policies {\u03c0n} satisfying \u02dc\u03c4n\nl \u2192 \u02dc\u03c4l, \u2200 l \u2208 [K],\nsup\nt\u2208[0,1]\n| \u02dcJn\n\u03c0n(t; Qn) \u2212 \u02dcJ\u03c0(t; Q)| \u21920, (4.1)\n9\n\nwhere the limiting cumulative cost \u02dcJ\u03c0(t; Q) is defined by\n\u02dcJ\u03c0(t; Q) :=\nKX\nl=1\nKX\nk=1\nZ t\n0\nCk(\u02dc\u03c4l(s))d \u00afAkl(s) =\nKX\nl=1\nKX\nk=1\nZ t\n0\n\u03bbpkqklCk(\u02dc\u03c4l(s)) ds.\nSee Section B.5 for the proof.\nCombining our characterization of the cumulative cost with the lower bound in Theorem 2,\nwe conclude that {\u03c0n} is asymptotically optimal if the following conditions are satisfied: i) the\nscaled sojourn time processes converge, i.e., \u02dc\u03c4n\nl \u2192 \u02dc\u03c4l, \u2200 l \u2208 [K], and ii) the limiting sojourn time\nprocesses satisfy \u02dc\u03c4l(t) = [h( \u02dcW+(t))]l/\u03c1l, \u2200 t \u2208 [0, 1], l \u2208 [K], where h(\u00b7) is an optimal solution to\nthe optimization problem (3.4). Recalling Opt( \u02dcW+(t)), the optimization problem (3.4), is convex\nwith linear constraints, its KKT conditions characterize the optimal workload allocation h. For\npredicted class l, recall its limiting service rate \u00b5l and the Pc\u00b5 cost function (1.3).\nLemma 2 (KKT conditions). {xl}l\u2208[K] is an optimal solution for Opt ( \u02dcW+(t)) if xl > 0, \u2200 l \u2208 [K]\nand is a solution to\n\u00b5lC\u2032\nl\n\u0010xl\n\u03c1l\n\u0011\n= \u00b5mC\u2032\nm\n\u0010xm\n\u03c1m\n\u0011\n, \u2200 l, m\u2208 [K],\nKX\nl=1\nxl = \u02dcW+(t). (4.2)\nWe also show that the KKT conditions (4.2) have a unique solution (Proposition 15, Section C)\nand thus h( \u02dcW+(t)) is well-defined.\nThe cost function Cl(t) (1.3) arises from the KKT conditions of Opt( \u02dcW+(t)) as a weighted\naverage with weights proportional to pkqkl, reflecting how predicted class l is composed of jobs\nfrom different true classes. As pk and qkl rely on the arrival rates and misclassification errors, Cl(t)\ncan be viewed as the exogenous average cost function associated with predicted class l. We aim to\ndevelop a scheduling policy that induces the workload allocation to align with the exogenous cost\nCl(t), in the sense that the conditions (4.2) are satisfied for all t \u2208 [0, 1].\nAccording to Proposition 1, convergence of the sojourn time process \u02dc\u03c4 n \u2192 \u02dc\u03c4 is equivalent to\nconvergence of workload \u02dcW\nn\n\u2192 \u02dcW. Moreover, if \u02dcW\nn\nconverges, then \u02dc\u03c4l = \u02dcWl/\u03c1l, \u2200 l \u2208 [K] (see\nLemma 8 and Lemma 16). Consequently, our goal is to develop a policy that satisfies \u02dc\u03c4 n \u2192 \u02dc\u03c4 and\n\u00b5lC\u2032\nl(\u02dc\u03c4l) = \u00b5mC\u2032\nm(\u02dc\u03c4m), \u2200 l, m\u2208 [K], (4.3)\nin the heavy traffic limit. When the balance (4.3) is achieved, the limiting workload allocation\n\u02dcWl = xl := \u02dc\u03c4l\u03c1l satisfies the KKT conditions (4.2) and both conditions (a) and (b) are met, which\nleads to the policy\u2019s optimality.\nSince the sojourn time\u2014time between job arrival and service completion\u2014is not observable, we\nsubstitute \u03c4 n = {\u03c4n\nl }l\u2208[K] with the observable age processes.\nDefinition 2 (Age Process) . Given a classifier f\u03b8 and feasible policies {\u03c0n}, a predicted class l\nand time t \u2208 [0, n], let an\nl (t) be the waiting time of the oldest job in predicted class l at time t,\nwhere a job being served is defined to be waiting in the system. Let an\nl be the age process of the\npredicted class l \u2208 [K] in system n, and let \u02dcan\nl (t) := n\u22121/2an\nl (nt), t \u2208 [0, 1] and \u02dcan := {\u02dcan\nl }l\u2208[K] be\nthe corresponding diffusion-scaled process and its vector-valued version.\nIf either {\u02dcan\nl }l\u2208[K] or {\u02dc\u03c4n\nl }l\u2208[K] converges, then both of the processes converge to the same limit,\ni.e., \u02dc\u03c4l(t) = \u02dcal(t), \u2200 l \u2208 [K], t\u2208 [0, 1] (see Proposition 12). Thus, we can equivalently reformulate\nthe optimality condition for sojourn time (4.3) into that with observable age processes\n\u00b5lC\u2032\nl(\u02dcal) = \u00b5mC\u2032\nm(\u02dcam), \u2200 l, m\u2208 [K]. (4.4)\n10\n\nHeavy-Traffic Optimality We design the Pc\u00b5-rule in the prelimit systems to achieve (4.4) in the\nheavy traffic limit. The P c\u00b5-rule prioritizes predicted classes with the highest prelimit Pc \u00b5 index,\ndefined as follows.\nDefinition 3 (Pc\u00b5-rule). Given a classifier f\u03b8, for any system n at time nt with t \u2208 [0, 1], the\nPc\u00b5-rule serves the oldest job in the predicted class having the maximum P c\u00b5-rule index, i.e.,\nl \u2208 arg maxm\u2208[K] In\nm(t), with preemption, where\nIn\nl (t) := \u00b5n\nl \u00b7 n1/2(Cn\nl )\u2032(an\nl (nt)), \u2200 t \u2208 [0, 1], (4.5)\nis the P c\u00b5-rule index for predicted class l at time nt in system n, and Cn\nl (t) :=\nP\nk pn\nk qn\nklCn\nk (t)P\nk\u2032 pn\nk\u2032 qn\nk\u2032l\n, t \u2208\n[0, \u221e), l \u2208 [K], is the weighted average of Cn\nk and the prelimit counterpart of Cl(t).\nThe Pc\u00b5-rule is a work-conserving p-FCFS policy by definition, and the n1/2 scaling ensures a\nwell-defined heavy traffic limit. The P c\u00b5-rule naturally allows for preemption: since we consider\njobs being served as waiting in the system, the age process an\nl corresponds to the same job waiting\nin the queue until its service completion. We adopt preemption for analysis purposes. In particular,\nwe can develop a non-preemptive counterpart of the P c\u00b5-rule and show its optimality using the\nsame analytic framework.\nWe are now ready to present our optimality result, which shows that the cumulative queueing\ncost associated with the P c\u00b5-rule, \u02dcJn\nPc\u00b5(\u00b7; Qn), converges to the asymptotic lower bound \u02dcJ\u2217(\u00b7; Q).\nOur proof relies on the fact that the Pc\u00b5-rule is a greedy method minimizing the largest difference of\nthe Pc\u00b5 indices , supt\u2208[0,1] maxl,m\u2208[K] |In\nl (t)\u2212In\nm(t)|, which guarantees (Proposition 13, Section E.1)\nsup\nt\u2208[0,1]\nmax\nl,m\u2208[K]\n|In\nl (t) \u2212 In\nm(t)| \u21920. (4.6)\nWe develop novel analysis techniques to show the convergence (4.6), which requires strong convexity\nof the cost function.\nAssumption D (Cost functions II). The limiting cost Ck is strongly convex for all k \u2208 [K].\nTheorem 3 (Optimality of P c\u00b5-rule). Given a classifier f\u03b8 and a sequence of queueing systems,\nsuppose that Assumptions A, B, C, D, and H hold. Then, \u02dcJn\nPc\u00b5(\u00b7; Qn) \u2192 \u02dcJ\u2217(\u00b7; Q) in (D, \u2225\u00b7\u2225 ) Pcopy-\na.s.. For the original processes under Pn, \u02dcJn\nPc\u00b5(\u00b7; Qn) \u21d2 \u02dcJ\u2217(\u00b7; Q) in (D, J1), and in particular,\nPn[ \u02dcJn(t; Qn) > x] \u2192 Pcopy[ \u02dcJ\u2217(t; Q) > x], \u2200 x \u2208 R, t \u2208 [0, 1].\nOur proof is highly involved so we provide a brief overview in Section E.1 and defer detailed\narguments to Section D and E. Our analytic framework extends upon prior work in subtle ways;\nsee Sections E.2 and E.3 for an in-depth discussion of our proof compared to Van Mieghem [63]\nand Mandelbaum and Stolyar [40].\n5 Empirical demonstration of the P c\u00b5-rule\nWe demonstrate the effectiveness of P c\u00b5-rule on a content moderation problem using real-world\nuser-generated text comments with the data generating process in Section 2. To operate at a\nmassive scale, online platforms use AI models to provide initial toxicity predictions. However,\nthese models are imperfect due to the inherent nonstationarity in the system; for example, they\n11\n\ncannot reliably detect context related to hate speech following a recent terrorist attack. As a result,\nplatforms must rely on human reviewers as the final inspectors [39], especially since they bear the\ncost of mistakenly removing non-violating comments. Our goal is to analyze the downstream impact\nof prediction errors on scheduling decisions in the content moderation queueing system.\nDifferent comments incur varying levels of negative impact on the platform. If not removed in\na timely manner, toxic comments attacking historically marginalized or oppressed groups can have\nparticularly harmful effects. We model this using heterogeneous delay costs based on the level of\ntoxicity and the demographic group targeted by the comment. These factors also affect processing\ntime; for instance, reviewing comments about an ethnic minority group in a foreign nation is more\nchallenging and time-consuming compared to domestic content.\nWe use real user-generated text comments on online articles from the CivilComments dataset [10].\nEach comment has been labeled by at least ten crowdsourcing workers with binary toxicity labels\nand whether it mentions one of the 8 demographic identities: male, female, LGBTQ, Christian,\nMuslim, other religions, Black, White . For simplicity, we focus on comments that mention one and\nonly one of the common groups white, black, male, female, LGBTQ . By crossing them with binary\ntoxicity labels, we derive 10 job classes. We assume the system has exact knowledge of target group\n(using simple rule-based logic), but can only predict the toxicity through an AI model.\nThe toxicity predictor, which can also be viewed as the job class predictor f\u03b8, utilizes the same\nneural network architecture and training approach as described in Koh et al. [32]. To showcase\nthe versatility of our scheduling algorithm regardless of the underlying prediction model, we study\nthree models fine-tuned based on a pre-trained language model (DistilBERT-base-uncased [53]):\nempirical risk minimization (ERM), reweighted ERM that upsamples toxic comments, and a sim-\nple distributionally robust model trained to optimize worst-group performance over target demo-\ngraphic groups (GroupDRO [52]). We observe significant variation in predictive performance across\nthe 10 job classes defined by {toxicity \u00d7 target demographic}. Across the three models (ERM,\nReweighted, GroupDRO), the worst-class accuracy (55%, 68%, 67%) is significantly lower than the\nmean accuracy (88%, 84%, 84%), leading to diverse patterns in the confusion matrix Q.\nQueueing system We assume jobs are assigned to reviewers randomly to ensure fairness, as\nmentioned in Section 1, and view each reviewer as a single-server queueing system. For simplicity,\nwe consider a queueing model operating in a finite time interval [0 , 1] with 10 job classes. New\njobs/comments arrive with i.i.d. exponential interarrival times with rate 100 (uniformly drawn from\nthe test set). Toxic comments have a lower service rate and toxic comments mentioning minority\ngroups have an even lower service rate. The service times follow exponentially distributions that\nsolely depend on the true class label Y : for white, black, male, female, LGBTQ , respectively,\n\u00b5toxic = [100, 30, 110, 25, 15] and \u00b5non-toxic = [150, 150, 150, 150, 150]. (If the service rate depends on\nthe covariate X, e.g., length of the comment, we can create further classes by splitting on relevant\ncovariates.) Our queueing system operates in heavy traffic with overall traffic intensity\u2248 1, aligning\nwith Assumption B. We set higher delay costs for toxic comments and coments targeting historically\nmarginalized or oppressed groups. Specifically, for each demographic group i, we set the delay cost\nas Ci,\u00b7(t) = ci,\u00b7t2/2, with ci,toxic = [10 , 22, 12, 20, 25] and ci,non-toxic = [1 , 1, 1, 1, 1] for toxic and\nnontoxic comments mentioning the aforementioned demographic groups, respectively.\nQueueing policies We compare our proposed P c\u00b5-rule against three scheduling approaches.\nFirst, we consider the Naive G c\u00b5-rule (1.2) that treats the predicted classes as true, and employs\n12\n\nOracle Gc\n Our Method Naive Gc\n DRL\n6.0\n6.5\n7.0\n7.5\n8.0\n8.5Cumulative Cost\n0.0 0.2 0.4 0.6 0.8 1.0\nTime\n0.0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7Traffic intensity\nNo Distribution Shift\nwhite\nblack\nmale\nfemale\nLGBTQ\nOracle Gc\n Our Method Naive Gc\n DRL8.5\n9.0\n9.5\n10.0\n10.5\n11.0\n11.5Cumulative Cost\n0.0 0.2 0.4 0.6 0.8 1.0\nTime\n0.0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7Traffic intensity\nDistribution Shift I\nwhite\nblack\nmale\nfemale\nLGBTQ\nOracle Gc\n Our Method Naive Gc\n DRL\n6.5\n7.0\n7.5\n8.0\n8.5\n9.0\n9.5Cumulative Cost\n0.0 0.2 0.4 0.6 0.8 1.0\nTime\n0.0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7Traffic intensity\nDistribution Shift II\nwhite\nblack\nmale\nfemale\nLGBTQ\nFigure 4. We present the cumulative cost for different policies under different testing environments\n(with 2\u00d7 the standard error encapsulated in the orange bracket).\nthe usual Gc\u00b5-rule. For both P c\u00b5-rule and Naive Gc\u00b5-rule, we assume the scheduler has complete\nknowledge of the arrival/service rates of the predicted classes, and use the confusion matrix Q\ncomputed on the validation dataset. Second, we study a black-box approach scheduling using\ndeep reinforcement learning methods (DRL), where we use a Q-learning method to estimate the\nvalue function using a feedforward neural network (deep Q-Networks [42]). Finally, we consider\nthe Oracle Gc \u00b5 policy, which knows the true class as well as associated arrival/service rates. All\npolicies are evaluated in the aforementioned setup, where the scheduler predicts the class label\nusing the AI model f\u03b8.\nTo train our DRL policy, we use Namkoong et al. [44]\u2019s discrete event queueing simulator. We\nuse {(queue length, age of the oldest job) } of all predicted classes as our state space and let the\npredicted classes {1, . . . , K= 10} be the action space. We learn a Q-function parameterized by a\nthree-layer fully connected network, and serve the oldest job in the predicted class that maximizes\nthe Q-function. As instantaneous rewards, we use the sum of cost rates, ci,\u00b7 times the age, for all\nclasses. We employ a similar training procedure as described in [44, Section D.1], and impose a\nlarge penalty to discourage the policy from serving empty queues.\nInstability of reinforcement learning We run the deep Q-learning method with experience\nreplay over 672 distinct sets of hyperparameters and evaluate them based on the average cumula-\ntive queuing cost over 5000 independent sample paths simulated from the testing enviroment. In\nFigure 2, we observe substantial variation in queueing performance across hyperparameters even\nwhen using identical instant reward functions and training/testing enviroments. (We also use the\nsame random seed across training runs.) In particular, the minimum, bottom & top deciles of\ncumulative costs are 7.98, 9.79, and 60.46. Our empirical observation highlights the significant\nengineering effort required to apply DRL approaches to scheduling and replicates previous findings\nin the RL literature (e.g., [29]). In the rest of the experiments, we select the best hyperparameter\nbased on average queueing costs reported in Figure 2.\n13\n\nMain results In Figure 4, we present cumulative cost averaged over 50 K sample paths. In the\nfirst column of Figure 4, we test scheduling policies under the environment they were designed\nfor: constant arrival/service rates as we described above, with traffic intensity \u2248 1. The P c\u00b5-rule\noutperforms Naive G c\u00b5-rule by \u223c 30% and DRL by 60 \u2212 70% in terms of the cost gap towards\nthe Oracle G c\u00b5-rule. While we expect the DRL policy can be further improved by additional\nengineering (reward shaping, neural network architecture search etc), we view the simplicity of\nour index-based policy as a significant practical advantage. Next, we assess the robustness of\nthe scheduling policies against nonstationarity in the system. We consider two additional testing\nenviroments with heavy traffic conditions that differ from that the policies were designed for. We\nobserve the performance gains of the P c\u00b5-rule hold over nonstationarities in the system.\nThe Pc\u00b5-rule consistently shows superior performance across different scenarios, demonstrating\nits robustness and practical utility in real-world content moderation tasks.\n6 Model selection based on queueing cost\nPredictive models with similar accuracy levels can exhibit significant differences in queueing per-\nformance. By explicitly deriving the optimal queueing cost under misclassification, our theoretical\nresults allow designing AI models with queueing cost as a central concern. Since the P c\u00b5-rule is\noptimal in the heavy traffic limit, the corresponding \u02dcJ\u2217(t; Q) represents the best possible cost when\nemploying the given classifer, f\u03b8, and the relative regret \u02dcJ\u2217(t; Q)/ \u02dcJ\u2217(t; I) serves as an evaluation\nmetric with queueing performance as the central consideration. We empirically demonstrate that\nthis simple model selection criteria based on our theory can provide substantial practical benefits\nin our content moderation simulator.\nFor quadratic cost functions, we can explicitly solve the optimization problem (3.4) and derive\nanalytic expressions for \u02dcJ\u2217(\u00b7; Q) and \u02dcJ\u2217(\u00b7; I).\nAssumption E (Quadratic Cost Functions) . For all k \u2208 [K], the cost functions are defined as\nCn\nk (t) = 1\n2ncn\nkt2, t \u2208 [0, n], n \u2208 N, and Ck(t) = 1\n2ckt2, t \u2208 [0, 1], where {cn\nk}n\u2208N and ck are positive\nconstants such that cn\nk \u2192 ck as n \u2192 \u221e.\nThe following formulas are easy to approximate since the confusion matrix Q can be effectively\nestimated on held-out data.\nProposition 4 (Cumulative Cost Rate of the P c\u00b5-rule). Given a classifier f\u03b8 and a sequence of\nqueueing systems, suppose that Assumptions A, B, E, and H hold. Then, we have that\n\u02dcJ\u2217(t; Q) = 1PK\nm=1(\u03b2m(Q))\u22121 \u00b7 1\n2\nZ t\n0\n\u02dcW+(s)2ds, \u2200 t \u2208 [0, 1],\nwhere \u03b2l(Q) := \u00b5lcl/\u03c1l. Under the Naive G c\u00b5-rule, the scaled cumulative queueing cost \u02dcJn\nNaive(\u00b7; Qn)\nhas the limit\n\u02dcJNaive(t; Q) =\nKX\nl=1\n\u03b2l(Q)\u0010P\nm\n\u03b2l,Naive(Q)\n\u03b2m,Naive(Q)\n\u00112 \u00b7 1\n2\nZ t\n0\n\u02dcW+(s)2ds,\nwhere \u03b2l,Naive(Q) = \u00b5lcl/\u03c1l.\nSee Section F.1 for the proof of Proposition 4. \u02dcJ\u2217(\u00b7; Q) is dominated by small values of \u03b2m(Q), as\nis the case for the limiting workload \u02dcWm under the Pc\u00b5-rule(see Section F.1). Small \u03b2m(Q) implies\n14\n\n50% 60% 70% 80% 90% 100%\nAccuracy\n100%\n110%\n120%\n130%\n140%\n150%Theoretical Criteria\nMax Theoretical Criteria\nMin Theoretical Criteria\n(a) High arrival rate of positive\nclass\n50% 60% 70% 80% 90% 100%\nAccuracy\n100%\n120%\n140%\n160%\n180%\n200%\n220%Theoretical Criteria\nMax Theoretical Criteria\nMin Theoretical Criteria\n(b) Low arrival rate of positive\nclass\n75% 80% 85%\nAccuracy\n0%\n20%\n40%\n60%\n80%\n100%\n120%Theoretical Gap\nHigh Arrival Rate of Positive Class\nLow Arrival Rate of Positive Class\n(c) Theoretical gap under\ndifferent accuracy levels\nFigure 5. Maximum and minimum relative regret \u02dcJ(t; Q)/ \u02dcJ\u2217(t; I) in the heavy traffic limit (\u201cthe-\noretical criteria\u201d) across accuracy levels. Each green dot corresponds to theoretical criteria and\naccuracy of a simulated confusion matrix Q.\neither high intensity or low priority of the predicted class, meaning the impact of f\u03b8 is determined\nby the \u201cimbalance\u201d of {\u03b2m(Q) : m \u2208 [K]} between the predicted classes.\nIn what follows, we heavily rely on the independence between \u02dcW+ and misclassification errors\nfrom Proposition 1.\nModel Multiplicity It is well known that models of equal prediction accuracy can perform\ndifferently in downstream decision-making tasks [17, 8]. This phenomenon, known as model multi-\nplicity [8], is particularly important in our setting, since prediction errors over different classes can\nhave disproportionate impacts on downstream queueing performance. We consider a two-class toy\nexample to showcase that models with high accuracy levels can still exhibit significant differences\nin queueing performances.\nWe simplify the setting from Section 5 to two classes: toxic comments (positive class, class 1),\nand non-toxic comments (negative class, class 2), where delay costs are set as Ck(t) = ckt2/2 with\nc1 = 15, c2 = 1. We examine two settings: (i) high arrival rate of the positive class, with [ \u03bb1, \u03bb2] =\n[25, 100], [\u00b51, \u00b52] = [50, 200]; and (ii) low arrival rate of the positive class, with [ \u03bb1, \u03bb2] = [1, 100],\n[\u00b51, \u00b52] = [2 , 200]. The arrival and service rates are chosen to achieve an overall traffic intensity\nclose to 1 and approximate heavy traffic limits.\nGiven fixed costs, arrival rates, and service rates, we can explcitly quantify the relative regret\n\u02dcJ\u2217(t; Q)/ \u02dcJ\u2217(t; I) for different classifiers through the confusion matrix Q, considering the maximum\nand minimum possible relative regret given a fixed accuracy level. In Figure 5(a)-(b), we study\nsystems with two different arrival rates. We randomly generate 500 confusion matrix Q (q11, q22\niid\u223c\nUnif[0, 1]) and plot the resulting accuracy level and theoretical criteria in green dots. The variation\nin relative regret is substantial in both settings, and in Figure 5(c), even at high accuracy levels\n(75%, 80%, 85%), the relative regret can vary by 30% to 80%. This indicates that model multiplicity\nsignificantly affects queuing performance, which highlights the potential of using our evaluation\nmetric in guiding model selection.\nComparison to Traditional Model Selection Criterias Next, we explore the effectiveness of\nour model selection criterion by comparing it with traditional criteria that focus on predictive per-\nformance, such as accuracy, precision, recall, or their weighted combinations. In particular, we com-\npare our evaluation metric \u02dcJ\u2217(t; Q)/ \u02dcJ\u2217(t; I) against two straightforward criteria: (i) cost-weighted\naccuracy, defined as c1q11+c2q22\nc1+c2\n, and (ii) frequency-weighted accuracy, defined as \u03bb1q11+\u03bb2q22\n\u03bb1+\u03bb2\n. As we\n15\n\nSimulated Criteria Theoretical Criteria\n100%\n101%\n102%\n103%\n104%\n105%\n106%\nSimulated Criteria\nHigh Arrival Rate of Positive Class\nOur Method\nCost-Weighted\nFreq-Weighted\n100%\n102%\n104%\n106%\n108%\n110%\nTheoretical Criteria\nSimulated Criteria Theoretical Criteria\n100%\n101%\n102%\n103%\n104%\nSimulated Criteria\nLow Arrival Rate of Positive Class\nOur Method\nCost-Weighted\nFreq-Weighted\n100%\n105%\n110%\n115%\n120%\n125%\n130%\nTheoretical Criteria\n(a) threshold selection for a fixed classifer\nSimulated Criteria Theoretical Criteria\n100%\n101%\n102%\n103%\n104%\n105%\n106%\n107%\nSimulated Criteria\nHigh Arrival Rate of Positive Class\nOur Method\nCost-Weighted\nFreq-Weighted\n100%\n102%\n104%\n106%\n108%\n110%\n112%\n114%\nTheoretical Criteria\nSimulated Criteria Theoretical Criteria\n100%\n101%\n102%\n103%\n104%\nSimulated Criteria\nLow Arrival Rate of Positive Class\nOur Method\nCost-Weighted\nFreq-Weighted\n100%\n110%\n120%\n130%\n140%\n150%\nTheoretical Criteria (b) model training\nFigure 6. Our model selection approach vs. traditional weighted-accuracy-based methods. For\nthresholds or models optimized for each criteria, we present normalized simulated queueing cost\n(simulated critera) and relative regret in the heavy traffic limit (theoretical criteria). Our method\nreduces cumulative queueing costs; traditional methods exhibit varying rankings across settings.\nobserve below, model rankings under the traditional methods change across arrival rates, indicating\ntheir unreliability in queueing tasks.\nWe consider two different approaches for utilizing our metric: (i) setting the threshold for\npredicting the positive class for a fixed classifier, and (ii) model training. For threshold selection,\nwe adopt the two environments from the above and generate covariatesX for positive and negative\nclasses from independent normal distributions, N(0, 0.5) and N(1, 0.5), respectively. We focus on\nf\u03b8(X) := I(X \u2265 \u03b8), \u2200 \u03b8 \u2208 [0, 1], study thresholds selected by our method, cost-weighted accuracy,\nand frequency-weighted accuracy, and present corresponding simulated queueing cost under the\nPc\u00b5-rule in Figure 6 (a). (We use line search to to optimize each critera.) In Figure 6, we show the\naverage simulated queueing costs (simulated criteria) at T = 1 over 3 \u00d7 106 independent sample\npaths using solid bars, with 2\u00d7 the standard error encapsulated in the orange brackets. The shaded\nbar depicts the relative regret (theoretical criteria) corresponding to the selected thresholds in the\nheavy traffic limit. To facilitate comparison with our method, we normalize the theoretical and\nsimulated criteria by the relative regret and the average simulated cumulative cost associated with\nour method, respectively.\nWe also study model training using relative regret. Specifically, we consider the 2 dimensional\nlogistic regression problem, where covariates X \u2208 R2 for positive and negative classes are generated\nfrom N([1, 0], [[1, \u22120.25], [\u22120.25, 1]]) and N([\u22121, 0], [[1, 0.75], [0.75, 1]]), respectively. For simplicity,\nwe fix the threshold at 0.5 and focus on classifiers defined as:fa,b(X) := I([1+exp{\u2212(a\u22a4X+b)}]\u22121 \u2265\n16\n\nSimulated Criteria Theoretical Criteria\n100%\n105%\n110%\n115%\n120%\nSimulated Criteria\nOracle Gc\nOur Method, threshold = 0.05\nOur Method, threshold = 0.5\nOur Method, threshold = 0.95\nNaive Gc\n100%\n120%\n140%\n160%\n180%\nTheoretical Criteria\n(a) Threshold selection\nSimulated Criteria Theoretical Criteria\n100%\n105%\n110%\n115%\n120%\nSimulated Criteria\nOracle Gc\nOur Method, GroupDRO\nOur Method, Reweighted\nOur Method, ERM\nNaive Gc\n100%\n120%\n140%\n160%\n180%\nTheoretical Criteria (b) Model selection\nFigure 7. For different policies, we present our proposed model selection criteria (theoretical criteria)\nbased on the relative regret \u02dcJ(t; Q)/ \u02dcJ\u2217(t; I) in the heavy traffic limit. To test its validity, we plot the\nsimulated/acutal counterpart (simulated criteria) in the left. The relative ranking of policies based\non our theoretical criteria exactly matches that given by the simulated quantities.\n0.5), \u2200 a \u2208 R2, b\u2208 R. Due to the simplicity of the toy problem, we can directly minimize relative\nregret by grid search.\nWe compare our method with traditional methods using weighted cross-entropy loss as the\ntraining objective. Given weight w = [w1, w2], predicted logits pred, and true labels Y, the loss\nfunction is defined as \u2113w(pred, Y) := \u2212P\ni:Yi=1 w1 log(predi) \u2212 P\nj:Yj=2 w2 log(1 \u2212 predj). We\nstudy two straightforward methods: (i) cost-weighted loss, where w1 = c1/\u03bb1, w2 = c2/\u03bb2, and (ii)\nfrequency-weighted loss, where w1 = 1, w2 = 1. For both methods, we use the Adam optimizer\nwith a learning rate of 0 .1, a batch size of 512, and train the model over 5 epochs using 10 5 datas\npoints. We present the normalized theoretical and simulated criteria in Figure 6 (b).\nAs shown in Figure 6, in this simplified toy example, our method still outperforms traditional\nmethods by \u223c 1 \u2212 4% in cumulative queueing costs. This demonstrates the effectiveness of our\nevaluation metric when queueing performance is the major concern. However, we note that there\nare discrepancies between the theoretical and simulated criteria in Figure 6 due to deviations from\nthe heavy traffic limit. While we conduct a brute force grid search over classifier parameters in this\nsimple setting, developing a practical and scalable training algorithm in more complex scenarios\nis an important direction of future work. As an interim solution, we can select between several\ncandidate classifiers as we present next.\nNumerical Experiments on CivilComments Dataset To further understand the validity of\nour proposed model selection criteria, we revisit the fully general testing enviroment from Section 5.\nWe study the performance of the P c\u00b5-rule, Oracle Gc\u00b5, and Naive Gc\u00b5-rule, using the cumulative\nqueueing cost at T = 1 across 5\u00d7104 independent sample paths. As the queueing cost of the Oracle\nGc\u00b5-rule converges to \u02dcJ\u2217(t; I), we normalize all simulated cumulative cost over each sample path\nby the average cumulative cost of the Oracle Gc \u00b5-rule. We refer to this quantity as \u201csimulated\u201d\nrelative regret.\nWe demonstrate the utility of selecting and evaluating classifiers based on\u02dcJ\u2217(t, Q)/ \u02dcJ\u2217(t, I) using\ntwo tasks: (i) threshold selection for a fixed classifier, and (ii) model selection for a given collection\nof classifiers. In both cases, the ranking according to our proposed criteria aligns with simulated\n17\n\ncounterparts, illustrating how an analytic characterization of queueing cost can provide an effective\ncomparison between ML models without extensive queueing simulation. For threshold selection,\nwe consider the P c\u00b5-rule using the aforementioned ERM predictor and compare its queueing per-\nformance with thresholds being [0 .05, 0.5, 0.95], positioned from left to right in Figure 7 (a). In\nFigure 7, we present simulated relative regret using solid bars, with 2 \u00d7 the standard error encap-\nsulated in the orange brackets. The shaded bar depicts our proposed model selection (theoretical\ncriteria) given by the relative regret in the heavy traffic limit. For model selection, we consider\nthe aforementioned three different classifiers: GroupDRO, Reweighted, and ERM with thresholds\n0.05, 0.05, and 0.95. (These thresholds are chosen to showcase diverse queueing performances). In\nFigure 7 (b), we evaluate the Pc\u00b5-rule using these models. We also compare P c\u00b5-rule to the Naive\nGc\u00b5-rule, where the classifier is fixed to the aforementeioned ERM classifier with threshold 0.5 in\nFigure 7 (a)(b).\nWe demonstrated that our proposed evaluation metric \u02dcJ\u2217(t, Q)/ \u02dcJ\u2217(t, I) effectively guides model\nselection by focusing on queueing performance. This approach ensures that the selected models\noptimize overall system performance, not just predictive accuracy, providing a robust basis for\ndesigning and selecting AI models in service systems.\n7 Design of an AI-based triage system\nOur characterization of queueing cost can be further utilized to design comprehensive job process-\ning systems assisted by AI models. Motivated by content moderation systems on social media\nplatforms [11, 64, 62], we study a triage system where an initial AI model filters out clear-cut cases,\nafter which the queueing system serves remaining jobs (Figure 1). Standard triage systems in on-\nline platforms determine the filtering level using simple metrics such as maximizing recall subject\nto a fixed high precision level (e.g., [11]). These designs [2, 54, 67, 1] lead to suboptimal system\nperformance as they do not consider the downstream operational cost such as hiring cost of human\nreviewers and queueing costs.\nIn this section, we provide a novel framework for designing AI-assisted triage systems that\njointly optimize the filtering and queueing systems, taking into account all four types of costs:\nfiltering costs, hiring costs, misclassification costs, and queueing congestion costs. Our objective\ncan be easily estimated using a small set of validation data and a simple simulation of a (reflected)\nBrownian motion, allowing us to find the optimal filtering level through methods like line search.\nIn Section 7.4, we conduct numerical experiments to demonstrate effectiveness of this approach.\nWe find that prediction-based metrics, which is a norm in practice, may align with the total cost\nwhen either filtering cost or hiring cost dominates, but it fails to do so in more complicated settings\nwith trade-offs between different types of costs. Our method avoids computationally expensive\nqueueing simulations, and consistently identifies the optimal filtering and staffing levels in all of\nthese scenarios by simply simulating a (reflected) Brownian motion.\n7.1 Model of the AI-based triage system\nWe consider a sequence of single-stream incoming jobs that arrive at the triage system. We assume\nthe nth system operates on a finite time horizon [0 , n], starts empty, has i.i.d. interarrival times\nwith an arrival rate of \u039b n. With a slight abuse of notation, we let un\ni be the interarrival time of\nthe ith job in system n, Un\n0 (t) be the arrival time of the \u230at\u230bth job in system n, and An\n0 (t) be the\n18\n\ntotal number of jobs arriving in the triage system n up to time t. For simplicity, we consider a\ntwo-class setting, with class 1 representing toxic content and class 2 representing non-toxic content.\nFor each job, a tuple of (observed features, true class label, service time), denoted as ( Xn\ni , Yn\ni , vn\ni ),\nis generated identically and indepedently of its arrival time un\ni . Similar to our model in Section 2,\nvn\ni and Xn\ni are conditionally independent given Y n\ni .\nWe use the binary classifier f\u03b8 for the filtering procedure across all systems n. With a slight\nabuse of notation, let f\u03b8(\u00b7) \u2208 [0, 1] now be the toxicity score instead of the predicted class label.\nSpecifically, the classifier outputs f\u03b8(Xn\ni ) \u2208 [0, 1] based on the observed features Xn\ni for each job\ni. The system designer is tasked with choosing a threshold zFL that affects the (triage) filtering\nlevel: an arriving job in system n can pass the filtering system and enter the queueing system if\nand only if f\u03b8(Xn\ni ) \u2265 zFL.1 Content that are filtered out are not reviewed and can remain on the\nplatform. A higher filtering level zFL filters more jobs out, resulting in higher false negative rate\n(more filtering and misclassification costs), fewer human reviewers required (lower hiring cost), and\na complex effect on the downstream queueing cost.\nEach job that passes the filtering system is subsequently sent to human reviewers (queueing\nsystem). Given the filtering level zFL, we use the same number of reviewers \u0393( zFL) across all\nsystems, where \u0393( zFL) is a predetermined decision variable, fixed in advance and not subject to\nrandomness. We assume that for each system n, all reviewers have the same service rate for class\nk jobs, i.e., \u00b5n\nk,r = \u00b5n\nk, \u2200 k \u2208 {1, 2} for each reviewer r \u2208 [\u0393(zFL)]. To ensure workload equality\nand fairness among reviewers, we assume jobs passing through the filtering system are assigned\nto one and only one human reviewer with equal probability 1 /\u0393(zFL), independently of any other\nrandom objects. Each human reviewer operates their own single-server queueing system. The jobs\nallocated to the rth reviewer corresponds to their arrival processes, denoted as An\nps,r(t), which are\nsplited from the common arrival process after filtering, denoted as An\nps,0(t). For the jth job passing\nthrough the filtering system, let Bn\nj := (Bn\nj1, . . . , Bn\nj\u0393(zFL)) be the one-hot encoded representation\nof the reviewer it is assigned to. Then, An\nps,r(t) := PAn\nps,0(t)\nj=1 Bjr, \u2200 t \u2208 [0, n], r\u2208 [\u0393(zFL)].\nFor simplicity, we assume all reviewers utilizef\u03b8 to predict the class labels of incoming jobs. The\nsystem designer must decide another threshold zTX \u2265 zFL that affects the toxicity classification. In\nparticular, for the sth job assigned to reviewer r, it is predicted to be toxic (class 1), i.e., Y n\ns1,r = 1,\nif and only if f\u03b8(Xn\ns,r) \u2265 zTX. We assume all human reviewers adopt the same scheduling policy.\nSimilar to our model in Section 2, reviewers use the predicted class Yn\ns,r and feasible scheduling\npolicies must satisfy a variant of Definition 1.\nThroughout this section, we use i when counting jobs that arrive at the triage system; j for jobs\nthat pass the filtering system and arrive at the queueing system; s for jobs assigned to a human\nreviewer; and r for human reviewers (servers). For a stochastic process An\nps,0(t), the subscript ps\nindicates processes associated with jobs passing through the filter and arriving at the queueing\nsystem. We use the subscript 0 to indicate the total arrival process and r to indicate processes\nassociated with the reviewer r. We denote our decision variables ( zFL, zTX) by z. We summarize\nour assumptions for the AI-based triage system below.\nAssumption F (Data generating processes for the AI-based triage system). For any system n \u2208 N,\n(i) {(un\ni , vn\ni , Xn\ni , Yn\ni ) : i \u2208 N} is a sequence of i.i.d. random vectors; (ii) {un\ni : i \u2208 N} and\n1For simplicity, we only consider filtering out clearly safe content in this section, though in practice, the system\ndesigner can choose another threshold to filter out clearly toxic contents from the human review process and directly\ntake further actions.\n19\n\n{(vn\ni , Xn\ni , Yn\ni ) : i \u2208 N} are independent; (iii) for any i \u2208 N, vn\ni and Xn\ni are conditionally independent\ngiven Y n\ni ; (iv) {Bn\nj : j \u2208 N} is a sequence of i.i.d. random vectors; (v) {Bn\nj : j \u2208 N} is independent\nof {un\ni : i \u2208 N} and {(vn\ni , Xn\ni , Yn\ni ) : i \u2208 N}.\nThe data generating process for the AI-based triage system is crucial to our analysis, because it\nenables the reduction of the scheduling problem for all reviewers to stochastically identical single-\nserver scheduling problems across the reviewers. Assumption F (i), (iv) and (v) ensure that each\nreviewer r has a single stream of jobs with i.i.d. tuples {(vn\ns,r, Xn\ns,r, Yn\ns,r) : s \u2208 N}. More importantly,\nthe tuples associated with reviewer r become independent of those of any other reviewers. This\nleads to the joint convergence of the diffusion-scaled processes defined by {(vn\ns,r, Xn\ns,r, Yn\ns,r) : s \u2208 N}\nacross all reviewers r \u2208 [\u0393(zFL)]. In addition, similar to Section 2, Assumption F (i), (iv), and\n(v) allow us to disentangle the interarrival times {un\ns,r : s \u2208 N} from the filtering process, service\nprocesses, and the covariates, ensuring the joint convergence of the diffusion-scaled processes defined\nby {un\ns,r : s \u2208 N} across the reviewers r \u2208 [\u0393(zFL)]. Since Assumption F (ii) and (v) imply\nindependence between {(vn\ns,r, Xn\ns,r, Yn\ns,r) : s \u2208 N}r\u2208[\u0393(zFL)] and {un\ns,r : s \u2208 N}r\u2208[\u0393(zFL)], we can derive\nthe desired joint convergence (Lemma 30) and apply our sample path analysis at the reviewer level .\nFor further discussion, see Appendix G.1.\n7.2 Heavy traffic conditions for the AI-based triage system\nIn the sequel, we assume the triage system operates under heavy traffic conditions and analyze the\nlimiting system. Denote the conditional probability of a class k job passing through the level z as\ngn\nk (z) := Pn[f\u03b8(Xn\ni ) \u2265 z | Y n\nik = 1], \u2200 z \u2208 [0, 1], k \u2208 {1, 2}. Similar to Assumption B, we adopt the\nfollowing heavy traffic conditions for the AI-based triage system.\nAssumption G (Heavy traffic conditions for AI-based triage system) . Given a classifier f\u03b8 and a\nsequence of triage systems, we assume that there exist \u039b, \u00b5k, and gk : [0, 1] \u2192 [0, 1] such that (i)\nfor any filtering level zFL \u2208 [0, 1] and class k \u2208 {1, 2}, we have that\nn1/2(\u039bn \u2212 \u039b) \u2192 0, n 1/2(\u00b5n\nk \u2212 \u00b5k) \u2192 0, n 1/2(gn\nk (zFL) \u2212 gk(zFL)) \u2192 0;\n(ii) given the filtering level zFL, the number of hired reviewers satisfies \u0393(zFL) = \u039b P2\nk=1\npkgk(zFL)\n\u00b5k\n.\nWe adopt Assumption G to ensure that each reviewer aligns with Assumption B. Specifically,\naccording to Assumption G (i) and [68, Theorem 9.5.1], we can show that for each reviewer r,\ntheir class prevalence pn\nk,r(zFL) := Pn[Y n\nsk,r = 1 | f\u03b8(Xn\ns,r) \u2265 zFL] and confusion matrix qn\nkl,r(z) :=\nPn[Y n\nsl,r = 1 | f\u03b8(Xn\ns,r) \u2265 zFL, Yn\nsk,r = 1] all converge to their limits pk(zFL) and qkl(z) at the rate\nof o(n\u22121/2) (Lemma 32). We use Qn(z) and Q(z) to denote the prelimit and limiting confusion\nmatrix for each reviewer. In addition, by Assumption G (ii), we have that\nn1/2\nh \u039bn\n\u0393(zFL)\n2X\nk=1\npn\nkgn\nk (zFL)\n\u00b5n\nk\n\u2212 1\ni\n\u2192 0, (7.1)\nwhich indicates that each reviewer operates under heavy traffic conditions and matches (2.2).\nAccording to Assumption G (ii), when all reviewers operates under heavy traffic conditions, the\nnumber of reviewers is solely determined by limiting traffic indensity and the filtering level zFL.\nThus, our decision variables are filtering level zFL and toxicity level zTX, with the number of\nreviewers determined accordingly. Intuitively, as the filtering levelzFL increases, the traffic intensity\ndecreases and the number of reviewers hired also decreases.\n20\n\nStarting from Assumptions F and G, we first establish the joint convergence result in Lemma 30.\nAs Assumptions F and G are compatible with Assumptions A and B, we derive a common proba-\nbility space Pcopy in Lemma 31 and apply the previous results on single-server queueing systems to\neach reviewer. This allows us to establish the limiting total cost of the triage system in Section 7.3.\n7.3 Total Cost of the AI-based triage system\nMotivated by content moderation problems, we divide the total cost into four components: filtering\ncost, hiring cost, misclassification cost, and queueing cost. Since the P c\u00b5-rule is optimal for each\nsingle-server queueing system under heavy traffic conditions, we can explicitly quantify the best\npossible queueing cost of the limiting system under quadratic cost assumption (Assumption E).\nThis enables us to determine the limiting total cost and minimize it to find the optimal filtering\nand classification levels (zFL, zTX) for a fixed classifier f\u03b8. In the following, we first define each cost\ncomponent and then establish the limiting total cost in Theorem 5.\nDefinition 4 (Total cost of the AI-based triage system) . Given a classifier f\u03b8, filtering level zFL,\ntoxicity level zTX, the number of hired reviewers \u0393(zFL), and a sequence of AI-based triage system,\nfor a sequence of feasible policies {\u03c0n}, define the cost incurred as the following.\n(i) (Filtering cost) For each job that is filtered out, the unit costs for toxic and non-toxic jobs are\ncFL,1 > 0 and cFL,2 < 0. The total filtering cost up to time t \u2208 [0, n] is\nGn(t; zFL) := cFL,1\nAn\n0 (t)X\ni=1\nI(f\u03b8(Xn\ni ) < zFL) \u00b7 Y n\ni1 + cFL,2\nAn\n0 (t)X\ni=1\nI(f\u03b8(Xn\ni ) < zFL) \u00b7 Y n\ni2,\nand \u02dcGn(t; zFL) := n\u22121Gn(nt; zFL) is the scaled filtering cost.\n(ii) (Hiring Cost) Each reviewer costs cr > 0 per unit of time.\n(iii) (Misclassification Cost) The per-job cost of false positive, false negative, true positive, or\ntrue negative are cfp, cfn, ctp, ctn, respectively. The total misclassification cost up to time t is\nMn(z, t), and its scaled counterpart is \u02dcMn(t; z) := n\u22121Mn(nt; z).\n(iv) (Queueing Cost) For each system n and reviewer r, Jn\n\u03c0n,r(t; Qn(z)) is the cumulative queue-\ning cost as defined in Section 3.1, and \u02dcJn\n\u03c0n,r(t; Qn(z)) := n\u22121Jn\n\u03c0n,r(nt; Qn(z)) is its scaled\ncounterpart.\nThe total cost incurred up to time t is defined by\nFn\n\u03c0n(t; z) = Gn(t; zFL)| {z }\nfiltering\n+ cr\u0393(zFL)t| {z }\nhiring\n+ Mn(t; z)| {z }\nmisclassification\n+\n\u0393(zFL)X\nr=1\nJn\n\u03c0n,r(t; Qn(z))\n| {z }\nqueueing\n, \u2200 t \u2208 [0, n],\nand \u02dcFn\n\u03c0n(t; z) := n\u22121Fn\n\u03c0n(nt; z) is its scaled counterpart.\nFor any filtering level zFL and toxicity level zTX, we can easily establish the optimal total cost\nof the AI-based triage system under heavy traffic limits by extending Proposition 6, Theorem 3,\nand Proposition 4. Such optimal cost can be achieved by applying the P c\u00b5-rule to all reviewers as\nshown in (7.2).\n21\n\nTheorem 5 (Total cost the AI-based triage system) . Given a classifier f\u03b8, filtering level zFL,\ntoxicity level zTX, the number of hired reviewers \u0393(zFL), and a sequence of AI-based triage system,\nsuppose that Assumptions E, F, G, and H hold. There exists a common probability space Pcopy such\nthat\n(i) (Lower bound) under any feasible policies {\u03c0n}, the associated total cost \u02dcFn\n\u03c0n(t; z) satisfies\nlim inf\nn\n\u02dcFn\n\u03c0n(t; z) \u2265 \u02dcF\u2217(t; z), \u2200 t \u2208 [0, 1] Pcopy \u2212a.s.. For the original processes under Pn, under\nany feasible policies {\u03c0\u2032\nn},\nlim inf\nn\nPn[ \u02dcFn\n\u03c0\u2032n\n(t; z) > x] \u2265 Pcopy[ \u02dcF\u2217(t; z) > x], \u2200x \u2208 R, t\u2208 [0, 1];\n(ii) (Optimality) under the P c\u00b5-rule, we have that \u02dcFn\nPc\u00b5(\u00b7; z) \u2192 \u02dcF\u2217(\u00b7; z) in (D, \u2225 \u00b7 \u2225), Pcopy \u2212\na.s.. For the original processes under Pn, \u02dcFn\nPc\u00b5(\u00b7; z) \u21d2 \u02dcF\u2217(\u00b7; z) in (D, J1), and in particular,\nPn[ \u02dcFn\nPc\u00b5(t; z) > x] \u2192 Pcopy[ \u02dcF\u2217(t; z) > x], \u2200 x \u2208 R, t\u2208 [0, 1].\nHere, the optimal total cost \u02dcF\u2217(t; z) is defined as\n\u02dcF\u2217(t; z) := \u02dcG\u2217(t; zFL) + cr\u0393(zFL)t + \u02dcM\u2217(t; z) +\n\u0393(zFL)X\nr=1\n\u02dcJ\u2217\nr (t; Q(z)), (7.2)\nwhere\n\u02dcG\u2217(t; zFL) = \u039bt \u00b7 [cFL,1p1(1 \u2212 g1(zFL)) + cFL,2p2(1 \u2212 g2(zFL))],\n\u02dcM\u2217(t; z) = \u039bt \u00b7\n\u0002\np1g1(zFL)[ctpq11(z) + cfnq12(z)] + p2g2(zFL)[cfpq21(z) + ctnq22(z)]\n\u0003\n\u02dcJ\u2217\nr (t; Q(z)) = \u03b21(Q(z))\u03b22(Q(z))\n2\n\u0002\n\u03b21(Q(z)) + \u03b22(Q(z))\n\u0003\nZ t\n0\n\u02dcW+(s; z, r)2ds,\nfor all t \u2208 [0, 1], and \u02dcW+(t; z, r) is the limiting remaining total workload process of reviewer r as\ndefined in Lemma 33.\nAccording to Theorem 5, we can minimize (7.2) to find the optimal filtering and toxicity levels\n(zFL, zTX) for a given classifier f\u03b8. In particular, (7.2) depends solely on limiting exogenous quan-\ntities such as \u039b, pk(zFL), qkl(zFL) that can be easily estimated given a small set of validation data.\n\u02dcWn\n+(t; z, r) is a reflected Brownian motion with a known drift and covariance (see further discussion\nin Appendix G.3), so we can estimate the total cost using a simulated (reflected) Brownian motion.\nThe optimal level z\u2217 can be then found through a simple line search over [0, 1]. Our approach avoids\ntraditional queueing simulations, which can be costly and time-consuming, making it practical and\nscalable for real-world applications.\n7.4 Numerical Experiments for the AI-based triage system\nOur formulation trades off multiple desiderata, in contrast to the standard industry practice that\nchoose z solely based on prediction metrics, such as maximizing recall subject to a fixed high preci-\nsion level [11]. To compare our proposed approach with such standard triage design approaches, we\nconsider the 2-class content moderation problem described in Section 6. We assume the covariates\nfor positive and negative classes are generated in the same fasion as in the 2d logistic regression\nproblem in Section 6, and consider the logistic regression classifier f\u03b8 developed by minimizing\n22\n\nOur Method Classical Method\n100%\n150%\n200%\n250%\n300%\n350%\nEstimtaed T otal Cost\n(i) Filtering costs dominate\nOur Method Classical Method\n100%\n120%\n140%\n160%\nEstimtaed T otal Cost (ii) Hiring costs dominate\nOur Method Classical Method\n100%\n103%\n105%\n108%\n110%\n112%\n115%\nEstimtaed T otal Cost (iii) Trade-off between\nfiltering and hiring costs\nFigure 8. For different methods, we consider the selected filtering level zFL and present the asso-\nciated estimated total cost of the AI-based triage system. The classical method maximizes recall\nsubject to the precision level [0 .93, 0.94, 0.95, 0.96, 0.97], positioned from left to right. This method\nexhibits highly varying total cost even at high precision levels, making it hard to determine the best\nfiltering level. In contrast, our method effectively minimizes the total cost by cheap simulations of\n(reflected) Brownian motion.\nthe equally-weighted cross-entropy loss ( w1 = 1, w2 = 1). For simplicity, we fix the toxicity level\nzTX = 0.5 and only study how filtering level zFL affects the total cost.\nWe examine the setting where the positive class has a relatively high arrival rate to mimic\nthe setting where only flagged content is sent to the triage system, which results in a relatively\nhigh proportion of positive class; recall Figure 1. In particular, we set [\u039b 1, \u039b2] = [10000 , 40000],\n[\u00b51, \u00b52] = [50, 200], where [\u039b 1, \u039b2] is the arrival rate of positive and negative classes to the triage\nsystem, and [ \u00b51, \u00b52] is the common service rate for the positive and negative classes across all\nreviewers. We consider three cases: (i) filtering costs dominate, (ii) hiring costs dominate, and\n(iii) a trade-off between filtering cost and hiring costs. The filtering costs and hiring costs are\nset as follows: (i) [ cFL,1, cFL,2] = [200 , \u22123], cr = 500, (ii) [ cFL,1, cFL,2] = [20 , \u22123], cr = 5000,\nand (iii) [ cFL,1, cFL,2] = [20 , \u22123], cr = 500. In all cases, the misclassification costs are set as\n[cfp, cfn, ctp, ctn] = [3, 3, \u22123, \u22123], and the delay costs are set as C\u00b7(t) = c\u00b7t2/2 with c1 = 15, c2 = 1.\nOur goal is to find the best filtering level zFL that minimizes the total cost. We compare our\nmethod that minimizes (7.2) to the following classical method from Chandak [11], which finds the\nfiltering level zFL by maximizing recall subject to a high precision level lower bound zprec \u2208 [0, 1]. 2\nBoth methods can be effectively implemented using small set of validation data and a linear search.\nWe set the search range for zFL as [0.05, 0.48].\nIn Figure 8, we present the average total cost over 10K sample paths of the simulated (reflected)\nBrownian motion, with 2\u00d7 the standard error encapsulated in the orange brackets. For the classical\nmethod, we set the precision level as [0 .93, 0.94, 0.95, 0.96, 0.97], positioned from left to right. To\nfacilitate comparison with our method, we normalize the estimated total cost by that of our method.\nWe observe that the classical method exhibits highly varying total cost (by \u223c 10% \u2212250%) even at\nhigh precision levels in Figure 8. This demonstrates the importance of selecting the right filtering\nlevel to minimize the total cost. In addition, for the classical method, it also shows the total\ncost is highly sensitive to the precision level. Therefore, the precision level serves as an important\nhyperparameter, and it is challenging to determine the best precision level that corresponds to\noptimal filtering level using the classical method.\nSuch challenge arises since our method takes a holistic view of the entire triage system, yet the\nclassical method only considers the prediction metrics. In our toy example, a higher precision level\n2We follow notations used in Chandak [11]. For the filtering system, precision and recall are calculated by treating\nsafe content as the positive class.\n23\n\nleads to a lower selected filtering level zFL, which results in lower filtering costs and higher hiring\ncosts. Figure 8 (i)(ii) corresponds to simpler settings where the total cost aligns with prediction\nmetrics. That is, when filtering costs or hiring costs dominate, the total cost is monotone with\nrespect to the filtering level and thus the precision level, as shown in Figure 8 (i)(ii). Therefore,\nwhen adopting the classical method, we can simply choose the precision level at the search boundary,\nwhich yields a filtering level near the search boundary that minimizes the total cost. In contrast,\nin Figure 8 (iii), where there is a trade-off between filtering and hiring costs, the total cost is\nnon-monotone and \u201cU\u201d-shaped with respect to the precision/filtering level. In this case, prediction\nmetrics fails to capture the total cost. While hyperparameter (precision) tuning based on total\ncosts is possible, the classical method merely shifts our search space to hyperparameters (precision\nlevels). In other words, hyperparameter tuning is equivalently to a naive line search for the decision\nvariable (filtering levelzFL) based on simulated total cost and the classical method does not serve as\neffective objectives/metrics. More importantly, without our Theorem 5, the total cost can only be\nestimtaed through multiple costly simulations of the entire triage system. Our method, in contrast,\neffectively identifies the correct objective and finds the best filtering level through cheap simulations\nof (reflected) Brownian motion.\nOur numerical experiments demonstrate the the effectiveness of our method and the importance\nof taking a holistic view of the entire content moderation system. We hope our method paves the\nway for more advanced system designs for complex AI-based triage systems in practical use.\n8 Discussion\nOur work builds on the large literature on queueing, as well as the more nascent study of decision-\nmaking problems with prediction models [4, 41, 57, 33, 12, 60]. Unlike previous works that study\nrelatively simple optimization problems (e.g., linear programming [19]) that take as input predic-\ntions, our scheduling setting requires modeling the endogenous impact of misclassifications.\n8.1 Related work\nHeavy traffic analysis allows circumventing the complexity of state/policy spaces via state-space\ncollapse, thereby identifying asymptotically optimal queueing decisions [28, 40, 50, 63, 68]. The\nc\u00b5-rule was shown to be optimal among priority rules in [15], and Van Mieghem [63] proved heavy\ntraffic optimality of the G c\u00b5-rule with convex delay costs in single-server systems with general\ndistributions of interarrival and service times. Under a heavy traffic regime defined with a complete\nresource pooling condition [27], Mandelbaum and Stolyar [40] extended the result to multi-server\nand multi-class queues. In the many server Halfin-Whitt heavy traffic regime (where the server\npool is also scaled [26]), Gurvich and Whitt [25] showed their state-dependent policy that minimizes\nthe holding cost reduces to a simple index-rule with linear holding costs, and to the G c\u00b5-rule with\nconvex costs. When customers in queues can abandon systems, a similar index rule that accounts\nfor the customer abandonment rate was shown to minimize the long-run average holding cost under\nthe many-server fluid limit [5].\nWe focus on the single-server model and relax a common assumption that the class of every job\nis known. We study the impact of AI models in queueing jobs, and use the heavy traffic limit to\nanalyze the downstream impacts of miclassifications. Our results provide a unified framework for\nevaluating and selecting AI models for optimal queueing. Along the way, we also provide rigorous\n24\n\nproofs for the classical setting with known classes by proving unjustified steps in Van Mieghem [63]\nand qualifying conditions under which they hold.\nThe challenge of unknown traffic parameters was identified as early as Cox [14]. Using an off-\npolicy ML model in queueing systems was also proposed for classifying jobs into different types\nor priority classes [57, 60] and predicting service times [12]. Argon and Ziya [4], Singh et al. [57]\nfocus on minimizing the mean stationary waiting time with Poisson arrivals, while we allow general\ndistributions of arrival and service times in our heavy traffic analysis. Although Argon and Ziya\n[4, Section 8] proposes a policy similar in form to the P c\u00b5-rule, their policy is compared to the\nFCFS policies in terms of the stationary waiting time, while our analysis shows the optimality of\nPc\u00b5-rule over all feasible policies in terms of cumulative cost. Sun et al. [60] consider a two-class\nsetting (triage or not) where classes can be inferred with additional time, and analyze when it is\noptimal to triage all (or no) jobs. Importantly, they assume service times follow predicted classes.\nChen and Dong [12] develop a two-class priority rule using predicted service times and show the\nconvergence of the queue length process to the same limit as in the perfect information case when\nestimation error is sufficiently small. In contrast, we characterize the optimal queueing cost given\na fixed classifier instead of aiming to match the performance of the perfect classifier. Our approach\nallows us to provide guidance on model selection for classifiers as we illustrate in Section 6.\nGoing beyond simple index policies, deep reinforcement learning (DRL) algorithms can be used\nfor queueing systems with unknown parameters. Dai and Gluzman [16] develop a policy optimiza-\ntion approach for multiclass Markovian queueing networks and proposes several variance reduction\ntechniques. Pavse et al. [47] combine proximal and trust region-based policy optimization algo-\nrithms [55] with a Lyapunov-inspired technique to ensure stability. Developing further approaches\nto overcome the challenges of applying RL algorithms in queueing (e.g., infinite state spaces, un-\nbounded costs) is a fertile direction of future research.\nThere is a growing body of work on learning in queueing systems that focus on online learning\nand analyze regret, the performance gap between the learning algorithm and the best policy in\nhindsight with the complete knowledge of system parameters [16, 21, 22, 23, 34, 35, 36, 56, 65, 66,\n70]. Inspired by the well-known static priority policies in queueing literature [5, 6, 40, 48, 49, 63],\nempirical versions of such policies were proposed where plug-in estimates of unknown parameters\nare used to compute static priorities. When service rates are unknown, Krishnasamy et al. [35]\npropose an empirical c\u00b5 rule for multi-server settings and show constant regret for linear cost\nfunctions, and Zhong et al. [70] develop an algorithm for learning service and abandonment rates\nin time-varying multiclass queues with many servers and show the empirical c\u00b5/\u03b8 rule achieves\noptimal regret. In the machine scheduling literature, where a finite set of jobs are given (with\nno external arrivals), Lee and Vojnovic [37] studies settings where delay costs are unknown, and\nshow that a plug-in version of the c\u00b5-rule can achieve near-optimal regret when coupled with an\nexploration strategy.\nFor more general queueing networks, Walton and Xu [66] present a connection between the\nMaxWeight policy [61] and Blackwell approachability [9], relating the waiting time regret to that\nof a policy for learning service rates. Borrowing insights from the stochastic multi-armed bandit\nliterature [58], a body of work [13, 34, 36, 59, 65] develops learning algorithms to minimize expected\nqueue length, addressing challenges in the queueing bandit model such as ensuring stability until\nthe parameters are sufficiently learned [36]. Freund et al. [22] propose a new performance measure\nof time-averaged queue length, and show near-optimality of the upper-confidence bound (UCB)\nalgorithm in a single-queue multi-server setting, as well as new UCB-type variants of MaxWeight\n25\n\nand BackPressure [61] in multi-queue systems and queueing networks, respectively. For queueing\nsystems with multi-server multiclass jobs, Yang et al. [69] recently developed another UCB-type\nvariant of the MaxWeight algorithm. Learning service rates has also been studied in decentralized\nqueueing systems, where classes of jobs are considered as strategic agents [21, 23, 56] and stability\nis a primary concern. Motivated by content moderation, a concurrent work [38] studies the joint\ndecision of content classification, and admission and scheduling for human review in an online\nlearning framework.\n8.2 Future directions\nWe discuss limitations of our framework and pose future directions of research. First, implementing\nthe Pc\u00b5-rule needs more information than the previous index-based policies. It necessitates arrival\ninformation, \u03bb and {pk}k\u2208[K], as well as the misclassification probabilities Qn = ( qn\nkl)k,l\u2208[K]. In\npractice, such parameters need to be estimated on a limited amount of data and estimation errors\nare unavoidable.\nExtension of the queueing model We identify conceptual and analytical challenges in ex-\ntending our framework to the multiserver setting. Modeling the extension after Mandelbaum and\nStolyar [40] who consider known true classes, we can posit the complete resource pooling (CRP)\ncondition. This condition requires the limit of the arrival rates to be located in the outer face of\nthe stability region, and to be uniquely represented as a maximal allocation of the servers\u2019 service\ncapacity. For our setting in Section 2, the main challenge is that the CRP condition will not neces-\nsarily hold on the arrival and service rates of the predicted classes. Because the service rate of each\npredicted class in prelimit will be a mixture of the original service rates as \u00b5n\nl in Definition 10, the\nCRP condition on true classes may not be preserved for predicted classes.\nUnderstanding of how prediction error interacts with queueing performance under general dy-\nnamics is an important direction of future research. For example, when jobs exhibit abandonment\nbehavior, a suitable adjustment to the c \u00b5-rule minimizes the long-run holding cost under many-\nserver fluid scaling [5]. Policies that simultaneously account for predictive error and job impatience\nmay yield fruit.\nDesign of queueing systems under class uncertainty While we focus on optimal scheduling,\nan even more important operational lever is thedesign of the queueing system [20, 30]. For example,\ndesigning priority classes that account for predictive error is a promising research direction [12]. In\nour model, if we keep the limiting distributions of the interarrival and service times the same, class\ndesigns satisfying the heavy traffic condition (2.2) should have an identical limiting total workload\n\u02dcW+ by Proposition 1, implying similar forms of the lower bound in (3.3). Given this observation,\nwe may investigate how class design interacts with the AI model\u2019s predictive performance.\nCombining the P c\u00b5-rule with AI-based approaches The performance of RL algorithms\ndegrade under distribution shift, and simple index-based policies may offer robustness benefits. The\ntwo approaches may provide synergies. For example, we can pre-train a policy to initially imitate\nan index-based policy, and then fine-tune it to maximize performance in specific environments.\nFor quadratic costs, we showed the effectiveness of using the relative regret \u02dcJ\u2217(\u00b7; Q) to select\nthe classification threshold. Alternatively, we could directly fine-tune the classifier to minimize\nthis metric, which may further enhance downstream queueing performance, albeit at the cost of\nincreased engineering complexity.\n26\n\nReferences\n[1] How facebook uses super-efficient ai models to detect hate speech. https://ai.meta.com/\nblog/how-facebook-uses-super-efficient-ai-models-to-detect-hate-speech , 2020.\n[2] Harmful content can evolve quickly. our new ai sys-\ntem adapts to tackle it. https://ai.meta.com/blog/\nharmful-content-can-evolve-quickly-our-new-ai-system-adapts-to-tackle-it ,\n2021.\n[3] A. Allouah, C. Kroer, X. Zhang, V. Avadhanula, N. Bohanon, A. Dania, C. Gocmen,\nS. Pupyrev, P. Shah, N. Stier-Moses, and K. R. Taarup. Fair allocation over time, with\napplications to content moderation. In Proceedings of the 29th ACM SIGKDD Conference on\nKnowledge Discovery and Data Mining (KDD) , pages 25\u2013\u201335, 2023.\n[4] N. T. Argon and S. Ziya. Priority assignment under imperfect information on customer type\nidentities. Manufacturing & Service Operations Management , 11(4):674\u2013693, 2009.\n[5] R. Atar, C. Giat, and N. Shimkin. The c\u00b5/\u03b8 rule for many-server queues with abandonment.\nOperations Research, 58(5):1427\u20131439, 2010.\n[6] R. Atar, C. Giat, and N. Shimkin. On the asymptotic optimality of the c\u00b5/\u03b8 rule under ergodic\ncost. Queueing Systems, 67:127\u2013144, 2011.\n[7] P. Billingsley. Convergence of Probability Measures. Wiley, Second edition, 1999.\n[8] E. Black, M. Raghavan, and S. Barocas. Model multiplicity: Opportunities, concerns, and\nsolutions. In Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Trans-\nparency, pages 850\u2013863, 2022.\n[9] D. Blackwell. An analog of the minimax theorem for vector payoffs. Pacific Journal of Math-\nematics, 6(1):1\u20138, Spring 1956.\n[10] D. Borkan, L. Dixon, J. Sorensen, N. Thain, and L. Vasserman. Nuanced metrics for measuring\nunintended bias with real data for text classification. In Proceedings of the 2019 World Wide\nWeb Conference, pages 491\u2013500, 2019.\n[11] A. Chandak. Augmenting our content moderation efforts through\nmachine learning and dynamic content prioritization, 2023. URL\nhttps://www.linkedin.com/blog/engineering/trust-and-safety/\naugmenting-our-content-moderation-efforts-through-machine-learni . Accessed\nMar 2024.\n[12] Y. Chen and J. Dong. Scheduling with service-time information: The power of two priority\nclasses. arXiv:2105.10499 [math.OC], 2021.\n[13] T. Choudhury, G. Joshi, W. Wang, and S. Shakkottai. Job dispatching policies for queueing\nsystems with unknown service rates. In 22nd International Symposium on Theory, Algorithmic\nFoundations, and Protocol Design for Mobile Networks and Mobile Computing , pages 181\u2014-\n190. Association for Computing Machinery, 2021.\n27\n\n[14] D. R. Cox. Some problems of statistical analysis connected with congestion (with discussion).\nIn Proceedings of the Symposium on Congestion Theory , pages 289\u2013316. Chapel Hill, North\nCarolina: University of North Carolina Press, 1966.\n[15] D. R. Cox and W. L. Smith. Queues, volume 2. Methuen, 1961.\n[16] J. G. Dai and M. Gluzman. Queueing network controls via deep reinforcement learning.\nStochastic Systems, pages 1\u201338, 2021.\n[17] A. D\u2019Amour, K. Heller, D. Moldovan, B. Adlam, B. Alipanahi, A. Beutel, C. Chen, J. Deaton,\nJ. Eisenstein, M. D. Hoffman, et al. Underspecification presents challenges for credibility in\nmodern machine learning. Journal of Machine Learning Research , 23(226):1\u201361, 2022.\n[18] R. Durrett. Probability: Theory and Examples . Cambridge University Press, 2010.\n[19] A. N. Elmachtoub and P. Grigas. Smart \u201dpredict, then optimize\u201d. Management Science, 2021.\n[20] Z. Feldman, A. Mandelbaum, W. A. Massey, and W. Whitt. Staffing of time-varying queues\nto achieve time-stable performance. Management Science, 54(2):324\u2013338, 2008.\n[21] D. Freund, T. Lykouris, and W. Weng. Efficient decentralized multi-agent learning in asym-\nmetric bipartite queueing systems. arXiv:2206.03324 [cs.LG], 2022.\n[22] D. Freund, T. Lykouris, and W. Weng. Quantifying the cost of learning in queueing systems.\narXiv:2308.07817 [cs.LG], 2023.\n[23] J. Gaitonde and \u00b4E. Tardos. The price of anarchy of strategic queuing systems. Journal of the\nACM, 70(20):1\u201363, May 2023.\n[24] P. W. Glynn. Chapter 4 diffusion approximations. In Stochastic Models, volume 2 of Handbooks\nin Operations Research and Management Science , pages 145\u2013198. Elsevier, 1990.\n[25] I. Gurvich and W. Whitt. Scheduling flexible servers with convex delay costs in many-server\nservice systems. Manufacturing & Service Operations Management , 11(2):237\u2013253, 2008.\n[26] S. Halfin and W. Whitt. Heavy-traffic limits for queues with many exponential servers. Oper-\nations Research, 29(3):567\u2013587, 1981.\n[27] J. M. Harrison and M. J. L\u00b4 opez. Heavy traffic resource pooling in parallel-server systems.\nQueueing Systems, 33:339\u2013368, 1999.\n[28] J. M. Harrison and A. Zeevi. Dynamic scheduling of a multiclass queue in the halfin-whitt\nheavy traffic regime. Operations Research, 52(2):243\u2013257, 2004.\n[29] P. Henderson, R. Islam, P. Bachman, J. Pineau, D. Precup, and D. Meger. Deep reinforcement\nlearning that matters. In Thirty-Second AAAI Conference on Artificial Intelligence . AAAI\nPress, 2018.\n[30] O. B. Jennings, A. Mandelbaum, W. A. Massey, and W. Whitt. Server staffing to meet\ntime-varying demand. Management Science, 42(10):1383\u20131394, 1996.\n[31] O. Kallenberg. Foundations of Modern Probability. Springer, 1997.\n28\n\n[32] P. W. Koh, S. Sagawa, H. Marklund, S. M. Xie, M. Zhang, A. Balsubramani, W. Hu, M. Ya-\nsunaga, R. L. Phillips, S. Beery, et al. Wilds: A benchmark of in-the-wild distribution shifts.\narXiv:2012.07421 [cs.LG], 2020.\n[33] J. Kotary, F. Fioretto, P. Van Hentenryck, and B. Wilder. End-to-end constrained optimization\nlearning: A survey. arXiv:2103.16378 [cs.LG], 2021.\n[34] S. Krishnasamy, R. Sen, R. Johari, and S. Shakkottai. Regret of queueing bandits. In Advances\nin Neural Information Processing Systems 16 , volume 29, 2016.\n[35] S. Krishnasamy, A. Arapostathis, R. Johari, and S. Shakkottai. On learning the c\u00b5 rule in\nsingle and parallel server networks. arXiv:1802.06723 [cs.PF], 2018.\n[36] S. Krishnasamy, R. Sen, R. Johari, and S. Shakkottai. Learning unknown service rates in\nqueues: A multiarmed bandit approach. Operations Research, 69(1):315\u2013330, 2021.\n[37] D. Lee and M. Vojnovic. Scheduling jobs with stochastic holding costs. In Advances in Neural\nInformation Processing Systems 21 , 2021.\n[38] T. Lykouris and W. Weng. Learning to defer in content moderation: The human-ai interplay.\narXiv:2402.12237 [cs.LG], 2024.\n[39] R. Makhijani, P. Shah, V. Avadhanula, C. Gocmen, N. E. Stier-Moses, and J. Mestre. Quest:\nQueue simulation for content moderation at scale. arXiv:2103.16816, 2021.\n[40] A. Mandelbaum and A. L. Stolyar. Scheduling flexible servers with convex delay costs: Heavy-\ntraffic optimality of the generalized c \u00b5-rule. Operations Research, 52(6):836\u2013855, 2004.\n[41] V. V. Mi\u02c7 si\u00b4 c and G. Perakis. Data analytics in operations management: A review. Manufac-\nturing & Service Operations Management , 22(1):158\u2013169, 2020.\n[42] V. Mnih, K. Kavukcuoglu, D. Silver, A. Graves, I. Antonoglou, D. Wierstra, and M. Riedmiller.\nPlaying Atari with deep reinforcement learning. arXiv:1312.5602 [cs.LG], 2013.\n[43] P. M\u00a8 orters and Y. Peres.Brownian Motion. Cambridge University Press, 2010.\n[44] H. Namkoong, Y. Ma, and P. W. Glynn. Minimax optimal estimation of stability under\ndistribution shift. arXiv:2212.06338 [stat.ML], 2022.\n[45] G. Pang, R. Talreja, and W. Whitt. Martingale proofs of many-server heavy-traffic limits for\nMarkovian queues. Probability Surveys, 4:193\u2013267, 2007.\n[46] C. H. Papadimitriou and J. N. Tsitsiklis. The complexity of optimal queueing network control.\nIn Proceedings of IEEE 9th Annual Conference on Structure in Complexity Theory, pages 318\u2013\n322. IEEE, 1994.\n[47] B. S. Pavse, Y. Chen, Q. Xie, and J. P. Hanna. Tackling unbounded state spaces in continuing\ntask reinforcement learning. arXiv:2306.01896 [cs.LG], 2023.\n[48] A. L. Puha and A. R. Ward. Scheduling an overloaded multiclass many-server queue with\nimpatient customers. INFORMS TutORials in Operations Research, pages 189\u2013217, 2019.\n[49] A. L. Puha and A. R. Ward. Fluid limits for multiclass many-server queues with general\n29\n\nreneging distributions and head-of-the-line scheduling. Mathematics of Operations Research ,\n47(2):1192\u20131228, 2021.\n[50] M. I. Reiman. Some diffusion approximations with state space collapse. In Modelling and\nPerformance Evaluation Methodology, pages 207\u2013240. Springer, 1984.\n[51] H. Royden. Real Analysis. Pearson, third edition, 1988.\n[52] S. Sagawa, P. W. Koh, T. B. Hashimoto, and P. Liang. Distributionally robust neural net-\nworks for group shifts: On the importance of regularization for worst-case generalization. In\nProceedings of the Seventh International Conference on Learning Representations , 2019.\n[53] V. Sanh, L. Debut, J. Chaumond, and T. Wolf. Distilbert, a distilled version of BERT: smaller,\nfaster, cheaper and lighter. arXiv:1910.01108 [cs.CL], 2019.\n[54] M. Schroepfer. Community standards report, 2019. URL https://ai.meta.com/blog/\ncommunity-standards-report. Accessed Apr 2024.\n[55] J. Schulman, S. Levine, P. Abbeel, M. Jordan, and P. Moritz. Trust region policy optimiza-\ntion. In Proceedings of the 32nd International Conference on Machine Learning , volume 37\nof Proceedings of Machine Learning Research, pages 1889\u20131897, Lille, France, 07\u201309 Jul 2015.\nPMLR.\n[56] F. Sentenac, E. Boursier, and V. Perchet. Decentralized learning in online queuing systems. In\nAdvances in Neural Information Processing Systems 34 , volume 34, pages 18501\u201318512, 2021.\n[57] S. Singh, I. Gurvich, and J. A. Van Mieghem. Feature-based design of priority queues: Digital\ntriage in healthcare. SSRN3731865, 2020. URL http://dx.doi.org/10.2139/ssrn.3731865.\n[58] A. Slivkins. Introduction to multi-armed bandits. arXiv:1904.07272 [cs.LG], 2019.\n[59] T. Stahlbuhk, B. Shrader, and E. Modiano. Learning algorithms for minimizing queue length\nregret. IEEE Transactions on Information Theory , 67(3):1759\u20131781, 2021.\n[60] Z. Sun, N. T. Argon, and S. Ziya. When to triage in service systems with hidden customer\nclass identities? Production and Operations Management, 31(1):172\u2013193, 2022.\n[61] L. Tassiulas and A. Ephremides. Stability properties of constrained queueing systems and\nscheduling policies for maximum throughput in multihop radio networks. IEEE Transactions\non Automatic Control, 37:1936\u20131948, 1992.\n[62] Tiktok Content Moderation. Our approach to content moderation. https://www.tiktok.\ncom/transparency/en/content-moderation/.\n[63] J. A. Van Mieghem. Dynamic scheduling with convex delay costs: The generalized c- \u00b5 rule.\nAnnals of Applied Probability, pages 809\u2013833, 1995.\n[64] J. Vincent. Facebook is now using ai to sort content for quicker moderation, 2020.\nURL https://www.theverge.com/2020/11/13/21562596/facebook-ai-moderation. Ac-\ncessed Apr 2024.\n[65] N. Walton. Two queues with non-stochastic arrivals. Operations Research Letters, 42(1):53\u201357,\n30\n\n2014.\n[66] N. Walton and K. Xu. Learning and information in stochastic networks and queues. In\nTutorials in Operations Research: Emerging Optimization Methods and Modeling Techniques\nwith Applications, pages 161\u2013198. INFORMS, 2021.\n[67] S. Wang, H. Fang, M. Khabsa, H. Mao, and H. Ma. Entailment as few-shot learner.\narXiv:2104.14690 [cs.CL], 2021.\n[68] W. Whitt. Stochastic Process Limits: An Introduction to Stochastic Process Limits and Their\nApplication to Queues . Springer Science & Business Media, 2002.\n[69] Z. Yang, R. Srikant, and L. Ying. Learning while scheduling in multi-server systems with\nunknown statistics: Maxweight with discounted ucb. In Proceedings of the 26 International\nConference on Artificial Intelligence and Statistics , volume 206 of Proceedings of Machine\nLearning Research, pages 4275\u20134312. PMLR, 2023.\n[70] Y. Zhong, J. R. Birge, and A. R. Ward. Learning the scheduling policy in time-varying\nmulticlass many server queues with abandonment. Available at SSRN , 2022. URL http:\n//dx.doi.org/10.2139/ssrn.4090021.\n31\n\nAppendices\nTable of Contents\nA Diffusion limits 31\nA.1 Review of basic results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32\nA.2 Proof of Lemma 3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34\nA.3 Proof of Lemma 4 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37\nB Proofs of results in Section 3.1 37\nB.1 Convergence of arrival and service processes of predicted classes . . . . . . . . . . . 38\nB.2 Dominance of p-FCFS and work-conserving policies . . . . . . . . . . . . . . . . . . 40\nB.3 Convergence of the endogenous processes of predicted classes . . . . . . . . . . . . 42\nB.4 Diffusion limits of the classical queueing model . . . . . . . . . . . . . . . . . . . . 45\nB.5 Proof of Lemma 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47\nC Proof of heavy traffic lower bound (Theorem 2) 47\nC.1 Overview . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47\nC.2 Detailed proof of heavy traffic lower bound (Theorem 2) . . . . . . . . . . . . . . . 49\nC.3 Proof of Lemma 15 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52\nC.4 Proof of Proposition 8 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52\nC.5 Proof of Proposition 7 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53\nC.6 Proof of Lemma 16 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55\nC.7 Complementary proof for Proposition 6 in Van Mieghem [63] . . . . . . . . . . . . 55\nD Proof of Proposition 13 56\nD.1 Preliminaries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 57\nD.2 Proof of Proposition 9 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59\nD.3 Proof of Proposition 10 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 60\nD.4 Proof of Proposition 11 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62\nE Proof of Theorem 3 62\nE.1 Overview of the proof . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62\nE.2 Comparison to the optimality result in Van Mieghem [63] . . . . . . . . . . . . . . 64\nE.3 Comparison to the optimality result in Mandelbaum and Stolyar [40] . . . . . . . . 64\nE.4 Detailed proof of Theorem 3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 65\nE.5 Proof of Lemma 26 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 65\nE.6 Proof of Proposition 12 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 66\nF Proofs for Section 6 67\nF.1 Proof for Proposition 4 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 67\nG Proof of results in Section 7 68\n32\n\nG.1 Joint convergence of the AI-based triage system . . . . . . . . . . . . . . . . . . . . 68\nG.2 Sample path analysis of each reviewer . . . . . . . . . . . . . . . . . . . . . . . . . 71\nG.3 Simulation of the total cost of the AI-based Triage System . . . . . . . . . . . . . . 73\nA Diffusion limits\nWe consider the following processes: partial sum process of interarrival time Un\n0 (t) that depends\nsolely on {un\ni : i \u2208 N}, partial sum process of service time V n\n0 and two other processes Zn :=\n(Zn\nkl)k,l\u2208[K], Rn := ( Rn\nl )l\u2208[K] that solely relies on {(Xn\ni , Yn\ni , vn\ni ) : i \u2208 N}. In particular, given\nsystem n, Zn\nkl(t) is the total number of jobs from real class k and predicted as class l and Rn\nl (t) is\nthe total service time requested by jobs predicted as class l, among the first \u230at\u230b jobs arriving in the\nsystem:\nZn\nkl(t) :=\n\u230at\u230bX\ni=1\nY n\nikY n\nil, R n\nl (t) :=\n\u230at\u230bX\ni=1\nY n\nilvn\ni , t \u2208 [0, n].\nFor any n \u2208 N and t \u2208 [0, 1], let \u02dcUn\n0 , \u02dcV n\n0 , \u02dcZ\nn\n:= ( \u02dcZ\nn\nkl)k,l\u2208[K], \u02dcR\nn\n:= ( \u02dcR\nn\nl )l\u2208[K] be the diffusion-\nscaled process, where\n\u02dcUn\n0 (t) = n\u22121/2[Un\n0 (nt) \u2212 (\u03bbn)\u22121 \u00b7 nt], \u02dcV n\n0 (t) = n\u22121/2[V n\n0 (nt) \u2212\nnX\nk=1\npn\nk\n\u00b5n\nk\n\u00b7 nt], t \u2208 [0, 1]; (A.1)\nand formal definitions of \u02dcZ\nn\nand \u02dcR\nn\nare deferred to Definition 8. In Assumption H to come, we\nstate basic moment conditions that allows the application of the martingale FCLT.\nLemma 3 (Joint weak convergence). Suppose that Assumptions A, B, and H hold. Then, there\nexist Brownian motions ( \u02dcU0, \u02dcZ, \u02dcR, \u02dcV0) such that\n( \u02dcUn\n0 , \u02dcZ\nn\n, \u02dcR\nn\n, \u02dcV n\n0 ) \u21d2 ( \u02dcU0, \u02dcZ, \u02dcR, \u02dcV0) in (DK(K+1)+2, W J1).\nDeferring a detailed proof to Section A.2, we highlight the main ingredients of the joint con-\nvergence result. Our main observation is that the diffusion-scaled processes admit a martingale\ncentral limit result when {(un\ni , vn\ni , Xn\ni , Yn\ni ) : i \u2208 N} are i.i.d. (Assumption A (i)) and vn\ni \u22a5 Xn\ni | Y n\ni\n(Assumption A (iii)). This allows us to show the weak convergence \u02dcUn\n0 \u21d2 \u02dcU0 in ( D, J1) and\n(\u02dcZ\nn\n, \u02dcR\nn\n, \u02dcV n\n0 ) \u21d2 (\u02dcZ, \u02dcR, \u02dcV0) in ( DK(K+1)+1, W J1). Since {un\ni } and {(vn\ni , Xn\ni , Yn\ni )} are independent\n(Assumption A (ii)), we can obtain the desired joint convergence (e.g., see Whitt [68, Theorem\n11.4.4] which we give as Lemma 9).\nBuilding off of our diffusion limit, we can strengthen the convergence to the uniform topology\nusing standard tools (e.g., see Lemma 6 and Lemma 7), and conduct a sample path analysis where\nwe construct copies of ( \u02dcUn\n0 , \u02dcZ\nn\n, \u02dcR\nn\n, \u02dcV n\n0 ) and ( \u02dcU0, \u02dcZ, \u02dcR, \u02dcV0) that are identical in distribution with\ntheir original counterparts and converge almost surely under a common probability space. Abusing\nnotation, we use the same notation for the newly construced processes.\nLemma 4 (Uniform convergence). Suppose that Assumptions A, B, and H hold. Then, there exist\nstochastic processes ( \u02dcUn\n0 , \u02dcZ\nn\n, \u02dcR\nn\n, \u02dcV n\n0 ), \u2200 n \u2265 1 and ( \u02dcU0, \u02dcZ, \u02dcR, \u02dcV0) defined on a common probability\nspace (\u2126copy, Fcopy, Pcopy) such that ( \u02dcUn\n0 , \u02dcZ\nn\n, \u02dcR\nn\n, \u02dcV n\n0 ), \u2200 n \u2265 1 and ( \u02dcU0, \u02dcZ, \u02dcR, \u02dcV0) are identical in\ndistribution with their original counterparts and\n( \u02dcUn\n0 , \u02dcZ\nn\n, \u02dcR\nn\n, \u02dcV n\n0 ) \u2192 ( \u02dcU0, \u02dcZ, \u02dcR, \u02dcV0) in (DK(K+1)+2, \u2225 \u00b7 \u2225), Pcopy-a.s.. (A.2)\n33\n\nWe defer a detailed proof to Section A.3 since it is a basic consequence of the Skorokhod repre-\nsentation theorem [7, Theorem 6.7]. Since the diffusion limits ( \u02dcU0, \u02dcZ, \u02dcR, \u02dcV 0) are multidimensional\nBrownian motions, the copied processes of ( \u02dcUn\n0 , \u02dcZ\nn\n, \u02dcR\nn\n, \u02dcV\nn\n0 ) jointly converge to a continuous limit\nalmost surely. We obtain the result by noting that convergence inJ1 to a deterministic and continu-\nous limit is equivalent to uniform convergence on compact intervals (e.g., see Glynn [24, Proposition\n4] stated in Lemma 7).\nSample path analysis allows us to leverage properties of uniform convergence and significantly\nsimplifies our analysis. All subsequent results and their proofs in the appendix, will be established\non the copied processes in the common probability space (\u2126 copy, Fcopy, Pcopy) with probability one,\ni.e., Pcopy-a.s., and all of the convergence results will be understood to hold in theuniform norm \u2225\u00b7\u2225.\nMoreover, since these newly constructed processes are identical in distribution with their original\ncounterparts, all subsequent results regarding almost sure convergence for the copied processes\ncan be converted into corresponding weak convergence results for the original processes; see more\ndiscussion in Theorems 2 and 3.\nTo show the above result, we first introduce a uniform integrability condition that allows us to\napply the martigale FCLT.\nAssumption H (Uniform integrability). For any system n \u2208 N, we assume that\n(i) En[(un\n1 )2] < \u221e, En[(vn\n1 )2] < \u221e, En[(Xn\n1 )2] < \u221e, and there exists fuctions gu and gv such that\ngu(x) \u2192 0, gv(x) \u2192 0 as x \u2192 \u221eand for any n \u2208 N and x \u2208 R,\nEn[(un\n1 )21 {un\n1 > x}] \u2264 gu(x), En[(vn\n1 )21 {vn\n1 > x}] \u2264 gv(x);\n(ii) There exist constants \u03b1u \u2208 (0, \u221e) and \u03b1v,k \u2208 (0, \u221e) for any k \u2208 [K] such that\n\u03b1n\nu := En[(un\n1 )2] \u2192 \u03b1u, \u03b1 n\nv,k := En[(vn\n1 )2|Y n\n1k = 1] \u2192 \u03b1v,k\nas n \u2192 \u221e.\nFor completeness, we review the martingale FCLT and Skorohod representation result before prov-\ning the main results of Section 2.\nA.1 Review of basic results\nWe review classical results on the martingale FCLT and the Skorohod construction.\nA.1.1 Martigale Functional Central Limit Theorem\nOur proof of Lemma 3 primarily relies on the martingale FCLT [45, Theorem 8.1]. We define the\nmaximum jump and the optional quadratic variation of processes and review the martingale FCLT\nin Lemma 5.\nLet D[0,\u221e) := D([0, \u221e), R) be the set of right-continuous with left limits (RCLL) functions\n[0, \u221e) \u2192 R, and Dk\n[0,\u221e) := D([0, \u221e), Rk) be the product space D[0,\u221e) \u00d7 \u00b7\u00b7\u00b7 \u00d7 D[0,\u221e) for k \u2208 N.\nWith a slight abuse of notations, we also use J1 to denote be the standard Skorohod J1 topology\non D[0,\u221e) and W J1 to denote the product J1 topology on Dk\n[0,\u221e).\nDefinition 5 (Maximum jump). For any function x \u2208 D[0,\u221e), the maximum jump of x up to time\nt is represented as\nJ(x, t) := sup{|x(s) \u2212 x(s\u2212)| : 0 < s\u2264 t}, t > 0. (A.3)\n34\n\nDefinition 6 (Optional quadratic variation) . Let M1 and M2 be two martingales in D[0,\u221e) with\nrespect to a filtration F \u2261 {Ft : t \u2265 0} satisfying M1(0) = M2(0) = 0 . The optional quadratic\nvariation between M1 and M2 is defined as\n[M1, M2](t) = lim\nm\u2192\u221e\n\u221eX\ni=1\n\u0000\nM1(tm,i) \u2212 M1(tm,i\u22121)\n\u0001\u0000\nM2(tm,i) \u2212 M2(tm,i\u22121)\n\u0001\n, t > 0, (A.4)\nwhere tm,i = min(t, i2\u2212m).\nPang et al. [45, Theorem 3.2] shows that [ M1, M2](t) is well-defined for any martingales pairs\n(M1, M2) satisfying conditions outlined in Definition 6.\nLemma 5 (Multidimensional martingale FCLT). For n \u2265 1, let Mn \u2261 (Mn\n1 , . . . , Mn\nk ) be a martin-\ngale in (Dk\n[0,\u221e), W J1) with respect to a filtration Fn \u2261 {Fn,t : t \u2265 0} satisfying Mn(0) = (0, . . . ,0).\nIf both of the following conditions hold\n(i) the expected maximum jump is asymptotically negligible: limn\u2192\u221e E[J(Mn\ni , T)] = 0 , \u2200 i \u2208\n[k], \u2200 T \u2265 0;\n(ii) there exists a positive semidefinite symmetric matrix A = {aij}i,j\u2208[k] \u2208 Rk\u00d7k such that for\nany 1 \u2264 i, j\u2264 k and t >0, [Mn\ni , Mn\nj ](t) \u21d2 aijt in R as n \u2192 \u221e,\nthen, we have that\nMn \u21d2 M in (Dk\n[0,\u221e), W J1) as n \u2192 \u221e,\nwhere M is a k-dimensional Brownian motion with mean vector and covariance matrix being\nE[M(t)] = (0, . . . ,0) and E[M(t)M\u22a4(t)] = At, t \u2265 0.\nA.1.2 Skorohod representation\nRecall the definition of random elements on a metric space ( S, m) [68, Page 78].\nDefinition 7 (Random Element). For a separable metric space (S, m), we say that X is a random\nelement of (S, m) if X is a measurable mapping from some underlying probability space (\u2126, F, P)\nto (S, B(S)), where B(s) is the Borel \u03c3-field induced by (S, m).\nThe well-known Skorohod representation theorem [7, Theorem 6.7] gives the following.\nLemma 6 (Skorohod representation) . Let {Xn}n\u22651 and X be random elements of a separable\nmetric space (S, m). If Xn \u21d2 X in (S, m), then there exists other random elements {Xn\ncopy}n\u22651 and\nXcopy of (S, m), defined on a common probability space (\u2126, F, P), such that (i) Xn\ncopy\nd= Xn, \u2200 n \u2265 1\nand Xcopy\nd= X; (ii) limn\u2192+\u221e m(Xn\ncopy, Xcopy) = 0 P-almost surely.\nLet dJ1(\u00b7, \u00b7) be the J1 metric (Skorohod metic) defined on D := D([0, 1], R), the set of RCLL\nfunctions [0, 1] \u2192 R [68, Page 79]. Moreover, for the product space Dk := D\u00d7\u00b7\u00b7\u00b7\u00d7D , let dp(\u00b7, \u00b7) be\nthe product metric defined by dp(x, y) := PK\ni=1 dJ1(xi, yi), \u2200 x, y \u2208 Dk [68, Page 83]. It is known\nthat both (D, dJ1(\u00b7, \u00b7)) and (Dk, dp(\u00b7, \u00b7)) are separable metric spaces withJ1 topology and W J1 (weak\nJ1) topology respectively [68, Sections 3.3, 11.4, and 11.5]. Then, according to Lemma 6, for weakly\nconverging random elements, we can obtain copies that converges almost surely. This enables us\nto conduct sample path analysis. Specifically, if the limiting random element is continuous almost\nsurely, we can utilize the following theorem from [24, Proposition 4] to conduct analysis under\nuniform norm convergence, which can streamline our analysis significantly.\n35\n\nLemma 7. For a sequence of functions Xn \u2208 D, convergence to a continuous function, say X \u2208 C,\nin the J1 metric dJ1(\u00b7, \u00b7) is equivalent to convergence in uniform norm \u2225 \u00b7 \u2225, i.e.,\nlim\nn\u2192\u221e\ndJ1(Xn, X) = 0 \u21d4 lim\nn\u2192\u221e\n\u2225Xn \u2212 X\u2225 = 0.\nA.2 Proof of Lemma 3\nFirst, we define arrival and service processes of predicted classes on which we apply the martigale\nFCLT to establish their weak convergence.\nDefinition 8 (Arrival and service processes of predicted classes I) . Given a classifier f\u03b8 and a\nsequence of queueing systems, we define the following for a given system n and time t \u2208 [0, n]:\n(i) (Counting process) for any real class k \u2208 [K] and predicted class l \u2208 [K], let Zn\nkl(t) be the total\nnumber of jobs from real class k and predicted as class l, among the first \u230at\u230b jobs arriving in\nthe system, i.e.,\nZn\nkl(t) :=\n\u230at\u230bX\ni=1\nY n\nikY n\nil, \u2200 t \u2208 [0, n];\nMoreover, let \u02dcZ\nn\n= { \u02dcZ\nn\nkl}k,l\u2208[K] be the corresponding diffusion-scaled process, defined as\n\u02dcZ\nn\nkl(t) = n\u22121\n2\nh\u230ant\u230bX\ni=1\nY n\nikY n\nil \u2212 pn\nkqn\nkl \u00b7 nt\ni\n, \u2200 t \u2208 [0, 1];\n(ii) (Cumulative service time) for any predicted class l \u2208 [K], let Rn\nl be the total service time\nrequested by jobs predicted as class l, among the first \u230at\u230b jobs arriving in the system, i.e.,\nRn\nl (t) :=\n\u230at\u230bX\ni=1\nY n\nilvn\ni , \u2200 t \u2208 [0, n].\nMoreover, let \u02dcR = { \u02dcRl}l\u2208[K] be the corresponding diffusion-scaled process, defined as\n\u02dcR\nn\nl (t) = n\u22121\n2\nh\u230ant\u230bX\ni=1\nY n\nilvn\ni \u2212\nKX\nk=1\npn\nk\n\u00b5n\nk\nqn\nkl \u00b7 nt\ni\n, \u2200 t \u2208 [0, 1].\nWe define Zn\nkl and Rn\nl on [0 , n], and \u02dcZ\nn\nkl and \u02dcR\nn\nl on [0 , 1] for analysis simplicity, and these\nprocesses can be naturally extended to [0 , +\u221e) to apply the martingale FCLT in Lemma 5. In\naddition, we introduce the following rescaled and centered processes \u02d8Un\n0 (t) and ( \u02d8Z\nn\n, \u02d8R\nn\n, \u02d8V n\n0 ) for\nanalysis purposes.\nDefinition 9 (Arrival and service processes of predicted classes II) . Given a classifier f\u03b8 and a\nsequence of queueing systems, we define the rescaled and centered processes for a given system n\nand time t \u2208 [0, 1] as followings:\n\u02d8Un\n0 (t) = n\u22121\n2\n\u230ant\u230bX\ni=1\n(un\ni \u2212 (\u03bbn)\u22121), \u02d8V n\n0 (t) = n\u22121\n2\n\u230ant\u230bX\ni=1\nh\nvn\ni \u2212\nKX\nk=1\npn\nk\n\u00b5n\nk\ni\n,\n\u02d8Z\nn\nkl(t) = n\u22121\n2\n\u230ant\u230bX\ni=1\n[Y n\nikY n\nil \u2212 pn\nkqn\nkl], \u2200 k, l\u2208 [K], \u02d8R\nn\nl (t) = n\u22121\n2\n\u230ant\u230bX\ni=1\nh\nY n\nilvn\ni \u2212\nKX\nk=1\npn\nk\n\u00b5n\nk\nqn\nkl\ni\n, \u2200 l \u2208 [K].\n36\n\nOne can check that \u02d8Un\n0 , \u02d8V n\n0 , \u02d8Z\nn\n, \u02d8R\nn\nare closely related to \u02dcUn\n0 , \u02dcV n\n0 , \u02dcZ\nn\n, \u02dcR\nn\nby noting that for any\nt \u2208 [0, 1],\n\u02dcUn\n0 (t) = \u02d8Un\n0 (t) + n\u22121\n2 (\u03bbn)\u22121(\u230ant\u230b \u2212nt), \u02dcV n\n0 (t) = \u02d8V n\n0 (t) + n\u22121\n2\nKX\nk=1\npn\nk\n\u00b5n\nk\n(\u230ant\u230b \u2212nt),\n\u02dcZ\nn\nkl(t) = \u02d8Z\nn\nkl(t) + n\u22121\n2 pn\nkqn\nkl(\u230ant\u230b \u2212nt), \u02dcR\nn\nl (t) = \u02d8R\nn\nl (t) + n\u22121\n2\nKX\nk=1\npn\nk\n\u00b5n\nk\nqn\nkl(\u230ant\u230b \u2212nt).\nUnder Assumptions A and H, we establish the weak convergence of \u02d8Un\n0 (t) and ( \u02d8Z\nn\n, \u02d8R\nn\n, \u02d8V n\n0 )\nusing the martingale FCLT in Lemma 5.\nLemma 8 (Individual weak convergence). Suppose that Assumptions A, B, and H hold. Then, there\nexist Brownian motions \u02d8U0 and (\u02d8Z, \u02d8R, \u02d8V0) such that (i) \u02d8Un\n0 \u21d2 \u02d8U0 in (D, J1); (ii) (\u02d8Z\nn\n, \u02d8R\nn\n, \u02d8V n\n0 ) \u21d2\n(\u02d8Z, \u02d8R, \u02d8V0) in (DK(K+1)+1, W J1).\nWe defer a detailed proof of the lemma to Section A.2.1.\nThe following processes are all well-defined deterministic functions on [0 , 1]\nn\u22121\n2 (\u03bbn)\u22121(\u230ant\u230b \u2212nt), n \u22121\n2\nKX\nk=1\npn\nk\n\u00b5n\nk\n(\u230ant\u230b \u2212nt), n \u22121\n2 pn\nkqn\nkl(\u230ant\u230b \u2212nt), n \u22121\n2\nKX\nk=1\npn\nk\n\u00b5n\nk\nqn\nkl(\u230ant\u230b \u2212nt).\nAssumption B and n\u22121/2 supt\u2208[0,1](\u230ant\u230b \u2212nt) \u2192 0 imply that all of them converge to 0 in ( D, J1).\nUsing the jointly weak convergence with a deterministic limit [68, Theorem 11.4.5], continuity of\naddition [68, Theorem 4.1] by almost-sure continuity of all limits, and the continuous mapping\ntheorem, it follows that there exist Brownian motions \u02dcU0 and ( \u02dcZ, \u02dcR, \u02dcV0) such that (i) \u02dcUn\n0 \u21d2 \u02dcU0 in\n(D, J1); (ii) ( \u02dcZ\nn\n, \u02dcR\nn\n, \u02dcV n\n0 ) \u21d2 (\u02dcZ, \u02dcR, \u02dcV0) in (DK(K+1)+1, W J1).\nSince {un\ni } and {(vn\ni , Xn\ni , Yn\ni )} are independent (Assumption A (ii)), we can use the following\nresult [68, Theorem 11.4.4] to obtain our desired jointly weak convergence in Lemma 3.\nLemma 9 (Joint weak convergence for independent random elements) . Let Xn and Yn be inde-\npendent random elements of separable metric spaces (S\u2032, m\u2032) and (S\u2032\u2032, m\u2032\u2032) for each n \u2265 1. Then,\nthere is joint convergence in distribution\n(Xn, Yn) \u21d2 (X, Y) in S\u2032 \u00d7 S\u2032\u2032\nif and only if Xn \u21d2 X in S\u2032 and Yn \u21d2 Y in S\u2032\u2032.\nA.2.1 Proof of Lemma 8\nTo utilize the martingale FCLT (Lemma 5), we extend\u02d8Un\n0 and (\u02d8Z\nn\n, \u02d8R\nn\n, \u02d8V n\n0 ) to D[0,\u221e) and DK(K+1)+1\n[0,\u221e) ,\nrespectively, and establish individual weak convergence for these extended stochastic processes. We\ncan get the desired result by restricting the extended stochastic processes to the time interval [0, 1].\nWe establish weak convergence of the extended \u02d8Un\n0 and ( \u02d8Z\nn\n, \u02d8R\nn\n, \u02d8V n\n0 ) separately. To show the\nformer, note that {un\ni : i \u2265 1} are i.i.d. random variables with mean ( \u03bbn)\u22121 by Assumptions A.\nEvidently,{\u02d8Un\n0 : n \u2208 N} is a martingale with respect to the natural filtration and satisfies\u02d8Un\n0 (0) = 0.\nIt thus suffices to validate the conditions (i) and (ii) of Lemma 5. To verify condition (i), use the\nshorthand \u2206n\ni := |un\ni \u2212 (\u03bbn)\u22121| to write\nEn[J( \u02d8Un\n0 , t)2] = n\u22121En\u0002\nmax\n1\u2264i\u2264\u230ant\u230b\n(\u2206n\ni )2\u0003\n\u2264 En\u0002\nmax\n1\u2264i\u2264\u230ant\u230b\n(\u2206n\ni )21\n\b\n(\u2206n\ni )2 \u2265 \u221an\n\t\u0003\n+ 1\u221an.\n37\n\nFrom uniform integrability (Assumption H), we have En[J( \u02d8Un\n0 , t)] \u2264\n\u0000\nEn\u0002\n|J( \u02d8Un\n0 , t)|2\u0003\u00011/2 \u2192 0. To\nverify condition (ii), first truncate the triangular array {|un\ni \u2212 (\u03bbn)\u22121|2 : i \u2208 N, n\u2208 N} uniformly\nwith a constant using the uniform integrability (Assumption H), and apply the triangular weak law\nof large numbers (WLLN) [18, Theorem 2.2.6] on the truncated array, with a choice of bn := n in\nthat theorem, to obtain\n[ \u02d8Un\n0 , \u02d8Un\n0 ](t) = n\u22121\n\u230ant\u230bX\ni=1\n(un\ni \u2212 \u03bb\u22121\nn )2 p\n\u2192 cut where cu := lim\nn\u2192\u221e\nVar(un\n1 ) = \u03b1u \u2212 (\u03bb)\u22122.\nWe now show the weak convergnece of Gn := ( \u02d8Z\nn\n, \u02d8R\nn\n, \u02d8V n\n0 ). We have Gn(0) = 0 and by\nAssumption A, {(Y n\ni , Xn\ni , vn\ni ) : i \u2208 N} are i.i.d. and Xn\ni is independent of vn\ni given Y n\ni . Therefore,\nby conditioning on Y n\ni , we have that for all i \u2265 1,\nEn[Y n\nikY n\nil] = pn\nkqn\nkl, En[Y n\nilvn\ni ] =\nKX\nk=1\npn\nk\n\u00b5n\nk\nqn\nkl, En[vn\ni ] =\nKX\nk=1\npn\nk\n\u00b5n\nk\n,\nwhich indicates that Gn is a martingale with respect to the natural filtration. To apply Lemma 5\ntowards Gn, we now validate its conditions (i) and (ii). Using a similar argument as above, uniform\nintegrability yields condition (i) of Lemma 5\nEn[|J( \u02d8V n\n0 , t)|] \u2192 0, En[J( \u02d8Z\nn\nkl, t)] \u2192 0, En[J( \u02d8R\nn\nl , t)] \u2192 0 (A.5)\nfor all k, l\u2208 [K]. Similarly, the triangular WLLN gives condition (ii)\n[ \u02d8V n\n0 , \u02d8V n\n0 ](t) \u21d2 cvt, [ \u02d8Zn\nkl, \u02d8Zn\nrs](t) \u21d2 c(k,l),(r,s)t, [ \u02d8Rn\nl , \u02d8Rn\ns ](t) \u21d2 cl,st,\n[ \u02d8V n\n0 , \u02d8Zn\nkl](t) \u21d2 c0,k,lt, [ \u02d8V n\n0 , \u02d8Rn\nl ](t) \u21d2 c0,lt, [ \u02d8Zn\nkl, \u02d8Rn\ns ](t) \u21d2 ck,l,st,\nwhere\ncv :=\nKX\nk=1\npk\u03b1v,k \u2212 (\nKX\nk=1\npk/\u00b5k)2 c(k,l),(r,s) :=\nn pkqkl(1 \u2212 pkqkl) if ( k, l) = (r, s)\n\u2212pkqklprqrs if (k, l) \u0338= (r, s)\ncl,s :=\n\uf8f1\n\uf8f4\uf8f4\uf8f2\n\uf8f4\uf8f4\uf8f3\nKP\nk=1\npkqkl\u03b1v,k \u2212\n\u0000 KP\nk=1\npkqkl\n\u00b5k\n\u00012 if l = s\n\u2212\n\u0000 KP\nk=1\npkqkl\n\u00b5k\n\u0001\n(\nKP\nk=1\npkqks\n\u00b5k\n\u0001\nif l \u0338= s\nc0,k,l :=\nKX\nk=1\npkqkl\n\u00b5k\n\u2212\n\u0010 KX\nk=1\npk\n\u00b5k\n\u0011\u0010 KX\nk=1\npkqkl\n\u0011\nc0,l :=\nKX\nk=1\npkqkl\u03b1v,k \u2212\n\u0010 KX\nk=1\npk\n\u00b5k\n\u0011\u0010 KX\nk=1\npkqkl\n\u00b5k\n\u0011\nck,l,s :=\n\uf8f1\n\uf8f4\uf8f4\uf8f2\n\uf8f4\uf8f4\uf8f3\nKP\nk=1\npkqkl\n\u00b5k\n\u2212\n\u0000 KP\nk=1\npkqkl\n\u0001\n(\nKP\nk=1\npkqkl\n\u00b5k\n\u0001\nif l = s\n\u2212\n\u0000 KP\nk=1\npkqkl\n\u0001\n(\nKP\nk=1\npkqks\n\u00b5k\n\u0001\nif l \u0338= s\nA.3 Proof of Lemma 4\nFrom the Skorohod representation (Lemma 6), there exist stochastic processes defined on some com-\nmon probability space (\u2126copy, Fcopy, Pcopy), ( \u02dcUn\n0 , \u02dcZ\nn\n, \u02dcR\nn\n, \u02dcV\nn\n0 ), \u2200 n \u2265 1 and (\u02dcU0, \u02dcZ, \u02dcR, \u02dcV 0), such that\n( \u02dcUn\n0 , \u02dcZ\nn\n, \u02dcR\nn\n, \u02dcV\nn\n0 ) and ( \u02dcU0, \u02dcZ, \u02dcR, \u02dcV 0) are identical in distribution with their original counterparts\nand\n( \u02dcUn\n0 , \u02dcZ\nn\n, \u02dcR\nn\n, \u02dcV\nn\n0 ) \u2192 ( \u02dcU0, \u02dcZ, \u02dcR, \u02dcV 0) in ( DK(K+1)+2, W J1), Pcopy-a.s..\n38\n\nOr equivalently, with probability one\ndp\n\u0000\n( \u02dcUn\n0 , \u02dcZ\nn\n, \u02dcR\nn\n, \u02dcV\nn\n0 ), ( \u02dcU0, \u02dcZ, \u02dcR, \u02dcV 0)\n\u0001\n\u2192 0,\nwhere dp(\u00b7, \u00b7) is the product J1 metric. By definition of dp(\u00b7, \u00b7), each coordinate of ( \u02dcUn\n0 , \u02dcZ\nn\n, \u02dcR\nn\n, \u02dcV\nn\n0 )\nconverges to the limiting process in ( D, J1) Pcopy-a.s.. Since ( \u02dcU0, \u02dcZ, \u02dcR, \u02dcV 0) is a multidimensional\nBrownian motion, ( \u02dcU0, \u02dcZ, \u02dcR, \u02dcV 0) is continuous Pcopy-a.s.. By Lemma 7, Pcopy-almost surely, every\ncoordinate of ( \u02dcU0, \u02dcZ, \u02dcR, \u02dcV 0) converges to the limiting process in (D, \u2225\u00b7\u2225 ). This completes our proof.\nB Proofs of results in Section 3.1\nWe show convergence diffusion-scaled versions of the exogenous processes associated with predicted\nclasses in Section B.1. Then, we provide a sequence of interim results required for us to prove\nProposition 1 in Section B.3.1.\nWe begin by extending Lemma 4 to include the arrival process. For any system n, let An\n0 (t) :=\nmax{m : Un\n0 (m) \u2264 t}, \u2200 t \u2208 [0, n] be the total number of jobs that arrive in the system up to time\nt, and\n\u02dcAn\n0 (t) = n\u22121/2\u0002\nAn\n0 (nt) \u2212 \u03bbnnt\n\u0003\n, t\u2208 [0, 1]. (B.1)\nBy definition, An\n0 (t) = max {j \u2208 N : Un\n0 (j) \u2264 t}. By Lemma 4, \u02dcU\nn\n0 \u2192 \u02dcU0 \u2208 C; since the limiting\nfunction is continuous, convergence in weak M2 topology is equivalent to convergence in uniform\nmetric [68, Corollary 12.11.1]. Using the asymptotic equivalence between counting and inverse\nprocesses with centering [68, Corollary 13.8.1], convergence of \u02dcA\nn\n0 follows from convergence of \u02dcU\nn\n0 .\nLemma 10 (Uniform convergence II). Suppose that Assumptions A, B, and H hold. Then, there\nexists a multidimensional Brownian motion ( \u02dcA0, \u02dcU0, \u02dcZ, \u02dcR, \u02dcV 0) such that\n( \u02dcAn\n0 , \u02dcUn\n0 , \u02dcZ\nn\n, \u02dcR\nn\n, \u02dcV\nn\n0 ) \u2192 ( \u02dcA0, \u02dcU0, \u02dcZ, \u02dcR, \u02dcV 0) in (DK(K+1)+3, \u2225 \u00b7 \u2225), Pcopy-a.s. (B.2)\nB.1 Convergence of arrival and service processes of predicted classes\nWe formally define the arrival and service processes associated predicted classes, and provide corre-\nsponding diffusion limits in Proposition 6. Given a classifier f\u03b8, suppose that Assumption B holds\nand consider system n operating in t \u2208 [0, n]. Recall un\nl,j and vn\nl,j are the interarrival and service\ntimes of the jth arriving job in predicted class l.\nDefinition 10 (Arrival and service processes of predicted classes II) .\n(i) (Arrival Process) Let An\nkl(t) := PAn\n0 (t)\ni=1 Y n\nikY n\nil be the number of jobs from real class k pre-\ndicted as class l among jobs arriving up to time t \u2208 [0, n], \u00afAn\nkl(t) := \u03bbnpn\nkqn\nklt and \u00afAkl(t) :=\n\u03bbpkqklt, t \u2208 [0, 1] be the first-order approximation processes, and \u02dcA\nn\nkl(t) = n\u22121/2[An\nkl(nt) \u2212\nn \u00afAn\nkl(t)] t \u2208 [0, 1] be the diffusion-scaled process. LetAn\nl (t) := PK\nk=1 An\nkl(t) = PAn\n0 (t)\ni=1 Y n\nil be the\nnumber of jobs predicted as class l among jobs arriving up to time t \u2208 [0, n], \u00afAn\nl (t) := \u03bbnpn\nl t\nand \u00afAl(t) := \u03bbplt, t \u2208 [0, 1] be first-order approximations, and \u02dcA\nn\nl (t) := PK\nk=1 \u02dcA\nn\nkl(t) =\nn\u22121/2\nh\nAn\nl (nt) \u2212n \u00afAn\nl (t)\ni\nwith t \u2208 [0, 1] be the diffusion-scaled process. Here, the occurrence of\npredicted class l is denoted by pn\nl := PK\nk=1 pn\nkqn\nkl and pl := PK\nk=1 pkqkl.\n39\n\n(ii) (Sum of Interarrival Time) Let Un\nl (t) := P\u230at\u230b\nj=1 un\nl,j, t \u2208 [0, n] be the sum of interarrival\ntimes among the first \u230at\u230b jobs predicted as class l, \u00afUl(t) := ( \u03bbpl)\u22121t, t \u2208 [0, 1] be the first-\norder approximation, and \u02dcU\nn\nl (t) = n\u22121/2\u0002\nUn\nl (nt) \u2212 n \u00afUn\nl (t)\n\u0003\n, t \u2208 [0, 1] be the corresponding\ndiffusion-scaled process where \u00afUn\nl (t) := (\u03bbnpn\nl )\u22121t.\n(iii) (Sum of Service Time) Let V n\nl (t) := P\u230at\u230b\nj=1 vn\nl,j, t\u2208 [0, n] be the sum of service times among the\nfirst \u230at\u230b jobs predicted as class l, \u00afV n\nl (t) := (\u00b5n\nl )\u22121t and \u00afV l(t) := (\u00b5l)\u22121t, t\u2208 [0, 1] be the first-\norder approximation and \u02dcV\nn\nl (t) = n\u22121/2\nh\nV n\nl (nt) \u2212 n \u00afV n\nl (t)\ni\n, t \u2208 [0, 1], be the corresponding\ndiffusion-sclaed process. Here, (\u00b5l)\u22121 := PK\nk=1\npkqkl\npl\n1\n\u00b5k\nand (\u00b5n\nl )\u22121 := PK\nk=1\npn\nk qn\nkl\npn\nl\n1\n\u00b5n\nk\nare the\nexpected service times of an arbitrary job predicted as class l.\n(iv) (Service Process) Let Sn\nl (t) := max{j \u2208 N : V n\nl (j) \u2264 t}, t \u2208 [0, n] be the number of predicted\nclass l jobs served during [0, t] time units, \u00afSn\nl (t) := \u00b5n\nl t and \u00afSl(t) := \u00b5lt, t \u2208 [0, 1] be the\nfirst-order approximation, and \u02dcS\nn\nl := n\u22121/2[Sn\nl (nt) \u2212 n \u00afSn\nl (t)], t \u2208 [0, 1] be the corresponding\ndiffusion-scaled process.\nFor simplicity, we also use the vector processes \u02dcA\nn\n= ( \u02dcA\nn\nl )l, \u02dcU\nn\n= ( \u02dcU\nn\nl )l, \u02dcS\nn\n= ( \u02dcS\nn\nl )l, and \u02dcV\nn\n=\n( \u02dcV\nn\nl )l to denote the second-order/diffusion-scaled processes.\nProposition 6 plays a major role in our analysis of the endogenous processes in Section B.3. We\nuse the little-o notation on(1) to denote uniform convergence over t \u2208 [0, 1] as n \u2192 +\u221e.\nProposition 6 (Convergence of exogenous processes of predicted classes) . Given a classifier f\u03b8,\nsuppose Assumptions A, B and H hold. There is a Brownian motion ( \u02dcA, \u02dcU, \u02dcS, \u02dcV) such that\n( \u02dcA\nn\n, \u02dcU\nn\n, \u02dcS\nn\n, \u02dcV\nn\n) \u2192 ( \u02dcA, \u02dcU, \u02dcS, \u02dcV), (B.3)\nand for any predicted class l \u2208 [K]\nAn\nl (nt) = n \u00afAn\nl (t) + n1/2 \u02dcA\nn\nl (t) + on(n1/2),\nUn\nl (nt) = n \u00afUn\nl (t) + n1/2 \u02dcU\nn\nl (t) + on(n1/2),\nSn\nl (nt) = n \u00afSn\nl (t) + n1/2 \u02dcS\nn\nl (t) + on(n1/2),\nV n\nl (nt) = n \u00afV n\nl (t) + n1/2 \u02dcV\nn\nl (t) + on(n1/2),\n(B.4)\nn\u22121/2 sup\n1\u2264j\u2264An\nl (n)\nun\nl,j \u2192 0, n \u22121/2 sup\n1\u2264j\u2264An\nl (n)\nvn\nl,j \u2192 0. (B.5)\nProof Recalling that \u02dcA0, \u02dcZkl are Brownian motions (B.2), we begin by showing the limit\n\u02dcA\nn\nkl \u2192 \u02dcAkl := \u02dcZkl \u25e6 \u03bbe + pkqkl\n\u02dcA0, \u02dcA\nn\nl \u2192 \u02dcAl :=\nKX\nk=1\n\u02dcAkl =\nKX\nk=1\n\u02dcZkl \u25e6 \u03bbe + pl\n\u02dcA0,\n\u02dcU\nn\nl \u2192 \u02dcUl := \u2212\n\u0010\n\u03bb\nKX\nk=1\npkqkl\n\u0011\u22121\n\u02dcAl\n\u0010\u0000\n\u03bb\nKX\nk=1\npkqkl\n\u0001\u22121e\n\u0011\n.\nRecall from Definition 8 and Definition 10 that An\nkl = Zn\nkl \u25e6 An\n0 and\n\u02dcA\nn\nkl(t) = n\u22121/2[An\nkl(nt) \u2212 \u03bbnpn\nkqn\nklnt] = \u02dcZ\nn\nkl(n\u22121An\n0 (nt)) + pn\nkqn\nkl\n\u02dcAn\n0 (t).\n40\n\nSince n\u22121An\n0 (n\u00b7) \u2192 \u03bbe, continuity of the composition function [68, Theorem 13.2.1] and the con-\ntinuous mapping theorem yields\n\u02dcA\nn\nkl \u2192 \u02dcZkl \u25e6 \u03bbe + pkqkl\n\u02dcA0 and \u02dcA\nn\nl \u2192 \u02dcAl.\nSince all limit have continuous sample paths, convergence in weakM2 topology is equivalent to uni-\nform convergence [68, Corollary 12.11.1]. Asymptotic equivalence of counting and inverse processes\n(with centering) gives convergence of \u02dcU\nn\nl [68, Corollary 13.8.1].\nUsing a nearly identical argument, we show convergence of \u02dcS\nn\nl and \u02dcV\nn\nl\n\u02dcV\nn\nl \u2192 \u02dcV l := \u02dcRl \u25e6 (pl)\u22121e + pl(\u00b5l)\u22121 \u02dcMl,\n\u02dcS\nn\nl \u2192 \u02dcSl := \u2212\u00b5l\n\u02dcV l \u25e6 \u00b5le = \u2212\u00b5l\n\u02dcRl \u25e6 (pl)\u22121\u00b5le \u2212 pl\n\u02dcMl \u25e6 \u00b5le,\nwhere Mn\nl (t) is the total number of job arriving in the system until arrival of \u230at\u230b jobs predicted as\nl \u2208 [K] and \u02dcM\nn\nl (t) is the corresponding diffusion-scaled process,\nMn\nl (t) := max\nn\nm \u2265 0 :\nmX\ni=1\nY n\nil \u2264 t\no\n= max\nn\nm \u2265 0 :\nKX\nk=1\nZn\nkl(m) \u2264 t\no\n, \u2200 t \u2208 [0, n],\n\u02dcM\nn\nl := n\u22121/2[Mn\nl (nt) \u2212 (pn\nl )\u22121nt], \u2200 t \u2208 [0, 1].\n(B.6)\n(Recall pn\nl = PK\nk=1 pn\nkqn\nkl.) Mn\nl is closely related to PK\nk=1 \u02dcZkl and can be understood as a counting\nprocess with \u201cinterarrival times\u201d being {Y n\nil : i \u2265 1}.\nRepresent the service partial sum V n\nl as a composition of Rn\nl with the counting process Mn\nl\nV n\nl (t) = Rn\nl (Mn\nl (t)) =\nMn\nl (t)X\ni=1\nY n\nilvn\ni , \u2200 t \u2208 [0, n] (Definitions 8 and 10) .\nSince \u02dcZ\nn\nkl \u2192 \u02dcZkl \u2208 C, a similar argument as before gives\n\u02dcM\nn\nl \u2192 \u02dcMl := \u2212p\u22121\nl\n\u0010 KX\nk=1\n\u02dcZkl\n\u0011\n\u25e6 p\u22121\nl e \u2208 C.\nFrom the continuous mapping theorem, we have the convergence of \u02dcV\nn\nl and \u02dcS\nn\nl .\nB.2 Dominance of p-FCFS and work-conserving policies\nThe results on the endogenous processes in Proposition 1 and the lower bound in Theorem 2 will be\nobtained assuming p-FCFS and work-conserving policies. We justify focusing on the set of p-FCFS\nand work-conserving policies.\np-FCFS Given a queueing system n and a feasible policy, we can derive an associated feasible\np-FCFS policy by swapping the service orders within each predicted class when the class has no\npreviously preempted job. We show that the latter policy has stochastically smaller cumulative\ncost function \u02dcJn(t) for all t \u2208 [0, 1]. To do so, we analyze the distribution of the cost function\nunder a modified data generating process governed by a new probability measure Qn such that\n41\n\nthe distribution of \u02dcJn\n\u03c0n remains the same as the original one under Pn. The idea is to define the\nclasses of jobs that govern the cost functions and service time distributions to be invariant under\npermutation within each predicted class, and use the convexity argument on the cost functions.\nWe assume that under Qn, {(un\ni , Xn\ni , Yn\ni , Yn\ni ) : i \u2208 N} are generated in the same way as in\nSection 2, but service times are generated differently. We introduce {( \u02c6Yn\njl, vn\njl) : j \u2208 N} that\nare indexed according to the order of being served rather than the order of arrivals within each\npredicted class l \u2208 [K]. For any job that is served as the jth distinct job within predicted class l\nin system n, the service time is realized as vn\njl in a tuple ( \u02c6Yn\njl, vn\njl), where \u02c6Yn\njl := ( \u02c6Y n\njl,1, . . . ,\u02c6Y n\njl,K )\ndenotes the one-hot encoding that determines the distribution of vn\njl as well as the cost function.\nIn the sequel, we employ the subscripts i and j to signify indexing according to the arrival and\nservice order within each predicted class, respectively.\nWe assume that for any queueing system n and predicted class l \u2208 [K],\n(i) { \u02c6Yn\njl, vn\njl : j \u2208 N} are i.i.d. random variables;\n(ii) { \u02c6Yn\njl, vn\njl : j \u2208 N} are independent of {(un\ni , Xn\ni , Yn\ni , Yn\ni ) : i \u2208 N}.\nNote that when swapping service orders between jobs within each predicted class, (\u02c6Yn\njl, vn\njl) remains\nunchanged in each sample path in Qn\u2014a key property to be utilized in our proof. To connect with\nthe original data generating process under Pn, we define the distribution of ( \u02c6Yn\n1l, vn\n1l) as\nQn[ \u02c6Y n\n1l,k = 1, vn\n1l \u2264 x] := Pn[Y n\n1k = 1, vn\n1 \u2264 x | Y n\n1l = 1], (B.7)\nfor any k \u2208 [K], x\u2208 R, where Pn[Y n\n1k = 1 , vn\n1 \u2264 x | Y n\n1l = 1] =\npn\nk qn\nklPK\nr=1 pnr qn\nrl\nPn[vn\n1 \u2264 x|Y n\n1k = 1]\nby conditional independence between vn\n1 and Y n\n1l given Y n\n1k in Assumption A. Moreover, we use a\nmodified cumulative cost function \u02c6Jn\n\u03c0n(t; Qn), where for any job that is served as the jth distinct\njob within predicted class l, the cost is incurred according to its \u201canalytical class label\u201d \u02c6Yn\njl and\ndefined by Cn\nk: \u02c6Y n\njl,k=1(\u00b7).\nLemma 11 (p-FCFS). Given a classifier f\u03b8 and a sequence of feasible policies {\u03c0n}, suppose that\nAssumptions A B, H, and C hold. Then, for any queueing system n, there exists a feasible p-FCFS\npolicy \u03c0n,p-FCFS such that \u02dcJn\n\u03c0n,p-FCFS(t; Qn) \u2264st \u02dcJn\n\u03c0n(t; Qn), \u2200 t \u2208 [0, 1].\nProof Our proof uses a similar idea alluded in the proof of [40, Theorem 2] and provides a\nrigorous justification. Given a feasible policy \u03c0n in system n \u2208 N, we can define an associated\np-FCFS policy, say \u03c0\u2032\nn, by applying the following basic operation: if there exists the jth arriving\njob in predicted class l \u2208 [K] that starts to be served by \u03c0n before the ith arriving job in the\nsame predicted class with Un\nl (i) < Un\nk(j) and i being the smallest such index, then we swap service\norders of the two jobs. It suffices to show that Pn[ \u02dcJn\n\u03c0\u2032n\n(t; Qn) > x] \u2264 Pn[ \u02dcJn\n\u03c0n(t; Qn) > x] for all\nt \u2208 [0, 1], x\u2208 R.\nWe first claim that for all t \u2208 [0, 1], \u02dcJn\n\u03c0n(t; Qn) under Pn has the same marginal distribution as\nthat of \u02c6Jn\n\u03c0n(t; Qn) under Qn. That is,\nPn[ \u02dcJn\n\u03c0n(t; Qn) > x] = Qn[ \u02c6J\u03c0n(t; Qn) > x], \u2200 x \u2208 R. (B.8)\nThe reason is that under Pn and Qn, the actual service time and the true/analytical class label\nof a job that determines the cost function to be applied are not known until the job starts to be\n42\n\nserved. Moreover, given arrival times {Un\nl (i) : i \u2208 N} in predicted class l \u2208 [K], service times and\ntrue/analytical class labels of waiting jobs are i.i.d. as (B.7) under the two probability measures.\nThe latter implies that given the same realization of {Un\nl (i) : i \u2208 N, l\u2208 [K]}, the conditional\ndistributions of \u02dcJ\u03c0n(\u00b7; Qn) and \u02c6J\u03c0n(\u00b7; Qn) are identical.\nBy (B.8), it suffices to show that \u03c0\u2032\nn induced from \u03c0n by the basic operation satisfies\nQn\u0002 \u02c6Jn\n\u03c0\u2032n\n(t; Qn) \u2264 \u02c6Jn\n\u03c0n(t; Qn), \u2200 t \u2208 [0, 1]\n\u0003\n= 1. (B.9)\nTo prove (B.9), fix a sample path under Qn in system n. Suppose that at some time nt\u2032 \u2208 [0, n],\nthere exist two jobs, i1 and i2, that arrived as the i1th and i2th job in predicted class l \u2208 [K],\nrespectively, with Un\nl (i1) < Un\nl (i2), and have not been served at all. Suppose that \u03c0n chooses to\nserve i2 at time nt as the j2th distinct job served in predicted class l, and starts to serve i1 later as\nthe j1th distinct job in that class with j1 > j2. Let \u2206 vn\nl (j2, j1) := Pj1\u22121\nr=j2+1 vn\nrl be the summation\nof service times for jobs in predicted class l that are served between i1 and i2. Also, suppose\n\u02c6Y n\nj1,l,k1 = \u02c6Y n\nj2,l,k2 = 1 for some k1, k2 \u2208 [K]. Note that \u2206 vn\nl (j2, j1), vn\nj2,l, vn\nj1,l, \u02c6Y n\nj1,l, and \u02c6Y n\nj2,l are\nidentical regardless of which job is chosen for service at time nt\u2032. Similarly, under the conditions\non preemption in Section 3.1, waiting times of jobs incurred by preemption during their service also\nremain the same independently of the job chosen for service at time nt\u2032. Let \u2206 wn\nl (j2, j1) be the\nsummation of waiting times incurred by preemption on jobs served between i1 and i2 in predicted\nclass l, and let wn\nj1,l and wn\nj2,l be the waiting times by preemption on i1 and i2, respectively.\nNow we are ready to show (B.9). We first show that changing service orders of j1 and j2\nimproves the cumulative cost at t = 1. Specifically, the change \u02c6Jn\n\u03c0\u2032n\n(1; Qn) \u2212 \u02c6Jn\n\u03c0n(1; Qn) would be\nh\nCn\nk2\n\u0000\nt\u2032 \u2212 Un\nl (i1) + wn\nj2,l + vn\nj2,l\n\u0001\n\u2212 Cn\nk2\n\u0000\nt\u2032 \u2212 Un\nl (i2) + wn\nj2,l + vn\nj2,l\n\u0001i\n\u2212\nh\nCn\nk1\n\u0000\nt\u2032 \u2212 Un\nl (i1) + wn\nj2,l + vn\nj2,l + \u2206wn\nl (j2, j1) + \u2206vn\nl (j2, j1) + wn\nj1,l + vn\nj1,l\n\u0001\n\u2212 Cn\nk1\n\u0000\nt\u2032 \u2212 Un\nl (i2) + wn\nj2,l + vn\nj2,l + \u2206wn\nl (j2, j1) + \u2206vn\nl (j2, j1) + wn\nj1,l + vn\nj1,l\n\u0001i\n\u2264 0,\nwhere the inequality follows from convexity of Cn\nk1, Cn\nk2 and Un\nl (i1) < Un\nl (i2), similarly to the\nproof [63, Proposition 1]. In fact, one can observe that the cost reduction holds true for all t \u2208 [0, 1]\nsuch that both jobs i1 and i2 are present in the system at time nt, and thus (B.9) follows. This\ncompletes our proof.\nWork-Conserving For all system n and any feasible policy \u03c0n, we can always create a work-\nconserving counterpart policy by having the server during an idle time to serve any waiting job,\nif available. Since preemption is allowed without incurring additional costs, the server can pause\nservice and come back to the preempted job later, ensuring that the cumulative cost does not\nincrease as stated in the following lemma; see further discussion in [63, Section 2].\nLemma 12 (Work-Conserving). Given a classifier f\u03b8 and a sequence of feasible policy {\u03c0n}, sup-\npose that Assumptions A and C hold. Then, for any queueing system n, there exists a feasible\nwork-conserving policy \u03c0n,work-conserving such that\n\u02dcJn\n\u03c0n,work-conserving(t; Qn) \u2264 \u02dcJn\n\u03c0n(t; Qn), \u2200 t \u2208 [0, 1], Pn-a.s..\n43\n\nB.3 Convergence of the endogenous processes of predicted classes\nTo prove Proposition 1, we formally define processes that are endogenous to scheduling policies for\npredicted classes.\nDefinition 11 (Endogenous processes). (i) (Total workload process) Let Ln\nl (t) be the total ser-\nvice time requested by all jobs predicted as class l and arriving by time t \u2208 [0, n], and \u02dcL\nn\nl (t)\nbe the corresponding diffusion-scaled process\nLn\nl (t) =\nAn\n0 (t)X\ni=1\nY n\nilvn\ni , t \u2208 [0, n], \u02dcL\nn\nl (t) = n\u22121/2\nh\nLn\nl (nt) \u2212 \u03bbn\nKX\nk=1\npn\nk\n\u00b5n\nk\nqn\nkl \u00b7 nt\ni\n, t \u2208 [0, 1].\n(ii) (Cumulative total input process) Let Ln\n+(t) = P\nl Ln\nl (t), t\u2208 [0, n] be the cumulative total input\nprocess and \u02dcLn\n+(t) := PK\nl=1 \u02dcL\nn\nl (t), t \u2208 [0, 1] be the corresponding diffusion-scaled process, i.e.,\n\u02dcLn\n+(t) = n\u22121/2\nh\nLn\n+(nt) \u2212 \u03bbn\nKX\nk=1\npn\nk\n\u00b5n\nk\n\u00b7 nt\ni\n, \u2200 t \u2208 [0, 1].\n(iii) (Policy process) Let Tn\nl (t) be total amount of time during [0, t] that the server allocates to jobs\nfrom predicted class l, and \u02dcT\nn\nl (t) be the corresponding diffusion-scaled process\n\u02dcT\nn\nl (t) = n\u22121/2\nh\nTn\nl (nt) \u2212 \u03bbn\nKX\nk=1\npn\nk\n\u00b5n\nk\nqn\nkl \u00b7 nt\ni\n, t \u2208 [0, 1].\n(iv) (Remaining workload process) Let Wn\nl (t) be the remaining service time requested by jobs pre-\ndicted as class l and present\u2014waiting for service or being served\u2014in the system at time\nt \u2208 [0, n]\nWn\nl (t) = Ln\nl (t) \u2212 Tn\nl (t), t \u2208 [0, n]. (B.10)\nand \u02dcW\nn\nl (t) := n\u22121/2Wn\nl (nt), \u2200 t \u2208 [0, 1] be the corresponding diffusion scaled process.\n(v) (Total remaining workload process) Let Wn\n+(t) = P\nl Wn\nl (t) be the total remaining workload\nprocess and \u02dcWn\n+(t) := n\u22121/2 PK\nl=1 Wn\nl (nt), \u2200 t \u2208 [0, 1] be the corresponding diffusion scaled\nprocess.\n(vi) (Queue length process) Let Nn\nl (t) be the total number of jobs that are predicted as class l and\npresent\u2014waiting for service or being served\u2014in the system at time t \u2208 [0, n], and Nn\nkl(t) be\nthe total number of true class k jobs that are predicted as class l and present in the system\nat time t \u2208 [0, n]. Let \u02dcN\nn\nl (t) := n\u22121/2Nn\nl (nt), \u02dcN\nn\nkl(t) := n\u22121/2Nn\nkl(nt), \u2200 t \u2208 [0, 1] be the\ncorresponding scaled processes.\n(vii) (Sojourn time process) Let \u03c4n\nlj be the sojourn time\u2014the time span between arrival and service\ncompletion\u2013of the jth job of predicted class l. Let \u03c4n\nl (t) = \u03c4n\nl,An\nl (t), \u2200 t \u2208 [0, n] be the sojourn\ntime process where \u03c4n\nl (t) denotes the sojourn time of the latest job predicted as class l and\narriving by time t and \u02dc\u03c4n\nl (t) := n\u22121/2\u03c4n\nl (nt), \u2200 t \u2208 [0, 1] be the corresponding scaled process.\nNote that \u03c4n\nl (Un\nl (i)) = \u03c4n\nl,i and \u03c4n\nl only exhibits jumps at arrival times {Un\nl (i)}\u221e\ni=1 of jobs\npredicted as class l. By definition, \u03c4n\nl is also RCLL. Since Ln\nl is an exogenous process, according to\n44\n\nEq. (B.10), we can also characterize the policy process Tn\nl , or equivalently, the scheduling policies,\nby the remaining workload process Wn\nl . The following results hold under p-FCFS feasible policies:\nNn\nl (t) = An\nl (t) \u2212 Sn\nl (Tn\nl (t)), \u2200 t \u2208 [0, n];\n\u03c4n\nl (t) = inf{s \u2265 0 : Wn\nl (t) \u2264 Tn\nl (t + s) \u2212 Tn\nl (t)}, \u2200 t \u2208 [0, n];\nWn\nl (t) = Tn\nl (t + \u03c4n\nl (t)) \u2212 Tn\nl (t), \u2200 t \u2208 [0, n].\n(B.11)\nWe show the convergence of the scaled input process\u02dcL\nn\nl , which will be used to prove convergence\nof the workload Wn\n+ in Section B.3.1.\nLemma 13 (Convergence of \u02dcL\nn\nl and \u02dcLn\n+). Given a classifier f\u03b8, a sequence of queueing systems,\nand a sequence of feasible policies {\u03c0n}, suppose that Assumptions A, B and H hold. Then, for any\npredicted class l \u2208 [K], we have that\n\u02dcL\nn\nl \u2192 \u02dcLl := \u02dcRl \u25e6 \u03bbe +\nKX\nk=1\npk\n\u00b5k\nqkl\n\u02dcA0, \u02dcLn\n+ \u2192 \u02dcL+ := \u02dcV0 \u25e6 \u03bbe +\nKX\nk=1\npk\n\u00b5k\n\u02dcA0\nas n \u2192 \u221e, where e is the identity function on [0, 1]. Also, for any system n and time t \u2208 [0, 1],\nLn\nl (nt) = \u03bbn\nKX\nk=1\npn\nk\n\u00b5n\nk\nqn\nkl \u00b7 nt + n1/2 \u02dcL\nn\nl (t) + o(n1/2); Ln\n+(nt) = \u03bbn\nKX\nk=1\npn\nk\n\u00b5n\nk\n\u00b7 nt + n1/2 \u02dcLn\n+(t) + o(n1/2).\nProof Note that Ln\nl = Rn\nl \u25e6 An\n0 by Definition 11. Therefore, we have\n\u02dcL\nn\nl (t) = n\u22121/2\nh\nRn\nl (An\n0 (nt)) \u2212\nKX\nk=1\npn\nk\n\u00b5n\nk\nqn\nkl \u00b7 An\n0 (nt)\ni\n+\nKX\nk=1\npn\nk\n\u00b5n\nk\nqn\nkl \u00b7 n\u22121/2\nh\nAn\n0 (nt) \u2212 \u03bbn \u00b7 nt\ni\n= \u02dcR\nn\nl (n\u22121An\n0 (nt)) +\nKX\nk=1\npn\nk\n\u00b5n\nk\nqn\nkl \u00b7 \u02dcAn\n0 (t).\nRecall \u02dcAn\n0 (t) \u2192 \u02dcA0(t) by Lemma 10 and n\u22121An\n0 (n\u00b7) \u2192 \u03bbe by Proposition 6. Since \u03bbe is continuous,\ncontinuity of the composition mapping [68, Theorem 13.2.1] and the continuous mapping theorem\nyields \u02dcL\nn\nl (t) \u2192 \u02dcRl \u25e6 \u03bbe + pl(\u00b5l)\u22121 \u02dcA0. Convergence of \u02dcLn\n+ is a direct consequence of continuous\nmapping theorem and \u02dcLn\n+ = PK\nl=1 \u02dcL\nn\nl by Definition 11.\nB.3.1 Proof of Proposition 1\nWe establish Proposition 1 based on Proposition 6 and Lemma 13. Our approach is similar to\nthe proof of [63, Proposition 2], and we complement the latter with additional details in the\nproof. Since {\u03c0n} is work-conserving, the remaining workload process Wn\n+ can be written as\nWn\n+ = \u03d5(Ln\n+ \u2212e) [68], where \u03d5 is the one-sided reflection mapping. By Lemma 13 and heavy-traffic\n45\n\nconditions (Assumption B), for any t \u2208 [0, 1]\n(Ln\n+ \u2212 e)(nt) =\n\u0010\n\u03bbn\nKX\nk=1\npn\nk\n\u00b5n\nk\n\u2212 1\n\u0011\n\u00b7 nt + n1/2 \u02dcL\nn\n+(t) + o(n1/2)\n= n1/2\nh\n\u02dcLn\n+(t) + n1/2\u0000\n\u03bbn\nKX\nk=1\npn\nk\n\u00b5n\nk\n\u2212 1\n\u0001\nt\ni\n+ o(n1/2)\n= n1/2 \u02dcLn\n+(t) + o(n1/2),\nwhere we used n1/2\u0000\n\u03bbn PK\nk=1\npn\nk\n\u00b5n\nk\n\u2212 1\n\u0001\n= on(1) in the final line. Combining with the relation\nWn\n+ = \u03d5(Ln\n+ \u2212 e), we get\nn\u22121/2Wn\n+(nt) = n\u22121/2\u03d5(Ln\n+ \u2212 e)(nt) = \u03d5(n\u22121/2(Ln\n+ \u2212 e)(nt))\n= \u03d5(\u02dcLn\n+(t) + on(1)) = \u03d5(\u02dcLn\n+(t)) + on(1),\nwhere the first line follows from definition of \u03d5, and the last line results from Lipschitz property of\n\u03d5 with the uniform metric [68, Lemma 13.5.1]. Since \u02dcWn\n+(t) := n\u22121/2Wn\n+(nt) in Definition 11, the\nconvergence \u02dcWn\n+ \u2192 \u03d5(\u02dcL+) follows from analysis above and Lemma 13.\nNext, we consider \u02dcW\nn\nl , \u02dcN\nn\nl , and \u02dc\u03c4n\nl . Notice that \u02dcW\nn\nl \u2265 0, PK\nl=1 \u02dcW\nn\nl \u2192 \u03d5(\u02dcL+), and \u03d5(\u02dcL+) is a\ncontinous function on [0 , 1]. Therefore, it is clear that lim sup n \u2225 \u02dcW\nn\nl \u2225 < +\u221e, \u2200 l \u2208 [K]. For \u02dcT\nn\nl ,\nby Definition 11 and Lemma 13, we have that\n\u02dcT\nn\nl (t) = n\u22121/2\nh\nTn\nl (nt) \u2212 \u03bbn\nKX\nk=1\npn\nk\n\u00b5n\nk\n\u00b7 nt\ni\n= n\u22121/2\nh\nLn\nl (nt) \u2212 \u03bbn\nKX\nk=1\npn\nk\n\u00b5n\nk\n\u00b7 nt\ni\n\u2212 n\u22121/2Wn\nl (nt) = \u02dcL\nn\nl (t) + \u02dcW\nn\nl (t),\n(B.12)\nwhere the second line follows from Tn\nl (nt) = Ln\nl (nt) \u2212 Wn\nl (nt) by Definition 11. Since \u02dcL\nn\nl \u2192 \u02dcLl by\nLemma 13, one can check that for any l \u2208 [K], \u02dcT\nn\nl converges if and only if \u02dcW\nn\nl converges. Also,\nlim supn \u2225 \u02dcT\nn\nl \u2225 < +\u221e, \u2200 l \u2208 [K].\nRecalling the relation (B.11), we have Nn\nl (nt) = An\nl (nt) \u2212Sn\nl (Tn\nl (nt)). Using Proposition 6, we\ncan rewrite \u02dcN\nn\nl (t)\n\u02dcN\nn\nl (t) = n\u22121/2[An\nl (nt) \u2212 Sn\nl (Tn\nl (nt))]\n= n1/2 \u00afAn\nl (t) + \u02dcA\nn\nl (t) \u2212 n1/2 \u00afSn\nl (n\u22121Tn\nl (nt)) \u2212 \u02dcS\nn\nl (n\u22121Tn\nl (nt)) + o(1)\nNote that \u00afAn\nl (t) = \u03bbnpn\nl t, \u00afSn\nl (t) = \u00b5n\nl t, and\nn\u22121Tn\nl (nt) = \u03bbn\nKX\nk=1\npn\nkqn\nkl\n\u00b5n\nk\n\u00b7 t + n\u22121/2 \u02dcT\nn\nl (t) + o(n\u22121/2), (B.13)\nwhere n\u22121/2 \u02dcT\nn\nl (t) = o(1) as lim supn \u2225 \u02dcT\nn\nl \u2225 < +\u221e. Therefore, \u02dcN\nn\nl (t) can be rewritten as\n\u02dcN\nn\nl (t) = n1/2\nh\n\u03bbnpn\nl \u00b7 t \u2212 \u00b5n\nl \u03bbn\nKX\nk=1\npn\nkqn\nkl\n\u00b5n\nk\n\u00b7 t\ni\n\u2212 \u00b5n\nl\n\u02dcT\nn\nl (t) + \u02dcA\nn\nl (t) \u2212 \u02dcS\nn\nl\n\u0010\n\u03bbn\nKX\nk=1\npn\nkqn\nkl\n\u00b5n\nk\n\u00b7 t + o(1)\n\u0011\n+ o(1)\n= \u2212 \u00b5n\nl\n\u02dcT\nn\nl (t) + \u02dcA\nn\nl (t) \u2212 \u02dcS\nn\nl\n\u0010\n\u03bbn\nKX\nk=1\npn\nkqn\nkl\n\u00b5n\nk\n\u00b7 t + o(1)\n\u0011\n+ o(1) (B.14)\n46\n\nby definition of pn\nl and \u00b5n\nl . Since \u03bbn PK\nk=1\npn\nk qn\nkl\n\u00b5n\nk\n\u00b7 t \u2192 \u03bb PK\nk=1\npkqkl\n\u00b5k\n\u00b7 t \u2208 C, by continuity of\ncomposition [68, Theorem 13.2.1] and continuous mapping theorem, for any l \u2208 [K], \u02dcT\nn\nl converges\nif and only if \u02dcN\nn\nl converges, and lim supn \u2225 \u02dcN\nn\nl \u2225 < +\u221e, \u2200 l \u2208 [K].\nFinally, for \u02dc\u03c4n\nl , once again by (B.11), we have that\n\u02dcW\nn\nl (t) = n\u22121/2[Tn\nl (nt + \u03c4n\nl (nt)) \u2212 Tn\nl (nt)], \u2200 t \u2208 [0, n].\nAccording to the previous result (B.13), we have\n\u02dcW\nn\nl (t) = \u03bbn\nKX\nk=1\npn\nkqn\nkl\n\u00b5n\nk\n\u00b7 \u02dc\u03c4n\nl (t) + \u02dcT\nn\nl (t + n\u22121\u03c4n\nl (nt)) \u2212 \u02dcT\nn\nl (t) + o(n1/2). (B.15)\nFor any predicted classl \u2208 [K], lim supn \u2225 \u02dcW\nn\nl \u2225 < +\u221e and lim supn \u2225 \u02dcT\nn\nl \u2225 < +\u221e, so that lim supn \u2225\u02dc\u03c4n\nl \u2225 <\n+\u221e and n\u22121\u02dc\u03c4n\nl = o(1). Moreover, for any predicted class l \u2208 [K], \u02dc\u03c4n\nl converges if and only if \u02dcW\nn\nl\nconverges.\nB.4 Diffusion limits of the classical queueing model\nWe extend the classical queueing model in Van Mieghem [63] and Mandelbaum and Stolyar [40] in\nthe presence of misclassification errors. Key convergence results analogous to Lemma 4, Proposi-\ntion 6, and Proposition 1 can be shown similarly to our proofs. However, Pc\u00b5-rule in this framework\nbecomes optimal only among p-FCFS policies, leading to a weaker result than Theorem 3 wherein\nthe optimality was established over all feasible policies.\nB.4.1 Diffusion limit in the classical framework\nWe explain a new data generating process given external arrivals from K real classes as in [63, 40].\nFor k \u2208 [K] and n \u2208 N, i.i.d random vectors {(un\nki, Xn\nki, vn\nki) : i \u2208 N} are generated where un\nki be\nan i.i.d interarrival time of the ith arriving job of real class k in system n with a constant arrival\nrate \u03bbn\nk := En[un\nk1] > 0. The tuple ( Xn\nki, vn\nki) is generated independently of un\nki where Xn\nki \u2208 Rd\nrepresents the feature vector of the job, and vn\nki indicates the time required to serve the job. Let\n(\u00b5n\nk)\u22121 := En[vn\nk1] be the expected service time of a class- k job. Let An\nk(t) = max {m : Un\nk (m) \u2264\nt}, t\u2208 [0, n] be the arrival counting process of real class k.\nFor each k \u2208 [K], the predicted class of a real class k job is defined by the one-hot vector Y n\nki :=\nf\u03b8(Xn\nki) = (Y n\nki(1), ..., Yn\nki(K)). The classification probabilities are defined as qn\nkl := Pn[Y n\nk1(l) = 1]\nfor k, l\u2208 [K]. We assume that vn\nki is independent of Xn\nki, implying vn\nki \u22a5 Y n\nki. The data generating\nprocesses and the corresponding heavy traffic conditions are summarized as the following.\nAssumption I (Alternative data generating processes) . For any system n \u2208 N,\n(i) the sequences of random vectors {(un\nki, vn\nki, Xn\nki) : i \u2208 N} are independent over k \u2208 [K];\n(ii) {(un\nki, vn\nki, Xn\nki) : i \u2208 N} is a sequence of i.i.d random vectors for each class k \u2208 [K];\n(iii) {un\nki : i \u2208 N}, {vn\nki : i \u2208 N}, and {Xn\nki : i \u2208 N} are independent for each class k \u2208 [K].\n47\n\nAssumption J (Heavy traffic condition). Given a classifier f\u03b8 and a sequence of queueing systems,\nthere exist \u03bbk, \u00b5k \u2208 (0, \u221e) and qkl \u2208 [0, 1] for k, l\u2208 [K] such that PK\nk=1 qkl > 0, \u2200 l \u2208 [K],PK\nk=1\n\u03bbk\n\u00b5k\n= 1, and as n \u2192 \u221e, for all k, l\u2208 [K]\nn1/2\u0000\n\u03bbn\nk \u2212 \u03bbk\n\u0001\n\u2192 0, n 1/2\u0000\n\u00b5n\nk \u2212 \u00b5k\n\u0001\n\u2192 0, n 1/2\u0000\nqn\nkl \u2212 qkl\n\u0001\n\u2192 0. (B.16)\nDiffusion limit To derive the diffusion limit in the classical model, the key processes in Defini-\ntion 8 are modified to\nZn\nkl(t) :=\n\u230at\u230bX\ni=1\nY n\nki(l), R n\nkl(t) :=\n\u230at\u230bX\ni=1\nY n\nki(l)vn\nki, t \u2208 [0, n], \u2200k, l\u2208 [K].\nNote that Rn\nkl is now defined for each pair of k, l\u2208 [K]. Then, using Assumptions H, I, J, the\nconvergence results analogous to Lemma 3 and Lemma 4 can be obtained using the martingale\nFCLT (Lemma 5) as in Section A.2 and Section A.3. Building off of the initial diffusion limit, we\ncan show convergence of the processes of predicted classes as in Proposition 6 and Proposition 1\nusing similar techniques. Specifically, let arrival processes associated with predicted classes be\nAn\nkl(t) := PAn\nk (t)\ni=1 Y n\nki(l), An\nl (t) := PK\nk=1 An\nkl(t), t \u2208 [0, n] for k, l\u2208 [K], and adapt the definitions\nof the other processes (Definition 10, Definition 11) and their characterizations analogously. For\nexample, similarly to the proof of Proposition 6, V n\nl will have to be represented as a composition\nto apply the random time change technique:\nV n\nl (t) =\nKX\nk=1\nRn\nkl\n\u0000\n(An\nk \u25e6 Un\nl )(t)\n\u0001\n=\nKX\nk=1\nAn\nk (Un\nl (t))X\ni=1\nY n\nki(l)vn\nki, t\u2208 [0, n].\nB.4.2 Stochastic dominance of the P c\u00b5-rule under the classical queueing model\nWe demonstrate that the stochastic dominance of p-FCFS policies in Lemma 11 doesnot hold in the\nclassical queueing model. The idea is that service times of waiting jobs in a predicted class are not\ngenerally i.i.d with respect to the usual filtration [63, 40] that policies are adapted to (Definition 1),\nexcept for a special case of independent Poisson arrivals, and thus our proof of Lemma 11 is not\napplicable. Consequently, the distributional lower bound of P c\u00b5-rule in (3.5) and the optimality in\nTheorem 3 would only hold over p-FCFS policies rather than all feasible policies.\nTo be concrete, consider a two-class system n where {un\n1i} and {un\n2i} take values of either 100\nor 150 and 1 or 3, respectively. Let service times {vn\n1i} and {vn\n2i} be either 2 or 6 and 1\n2 or 3\n2,\nrespectively, and qn\nkl = 1\n2 for all k, l= 1, 2. Suppose predicted class 1 has two waiting jobs with the\narrival time of the jth arriving job Un\n1,j, j= 1, 2. First, consider Un\n1,1 = 100, Un\n1,2 = 103. Given the\nknowledge of the arrival rates andUn\n1,1, Un\n1,2, service times of the jobs are not identically distributed\nbecause the first job has positive probabilities to be either of real class 1 or 2 but the second job\ncan only be from class 2. Next, consider Un\n1,1 = 100, Un\n1,2 = 150. If service time of the first job is\nobserved to be 2 or 6, the first and second job must be of real class 1 and 2, respectively. If service\ntime of the first job turns out to be 1\n2 or 3\n2, the second job can be of real class 1 with positive\nprobability. Thus, the service times of the jobs in predicted class 1 are not independent.\n48\n\nB.5 Proof of Lemma 1\nUsing the shorthand fn\nkl(s) := Cn\nk (\u03c4n\nl (ns)) = Cn\nk (n1/2\u02dc\u03c4n\nl (ns)), fkl(s) := Ck(\u02dc\u03c4l(s)) d \u03ben\nkl(\u00b7) :=\nd\n\u0000\nn\u22121An\nkl(n\u00b7)\n\u0001\n(\u00b7), and d\u03bekl(\u00b7) := d \u00afAkl(\u00b7), triangle inequalities gives\nsup\nt\u2208[0,1]\n| \u02dcJn\n\u03c0n(t; Qn) \u2212 \u02dcJ\u03c0(t; Q)| = sup\nt\u2208[0,1]\n\f\f\f\nKX\nk=1\nKX\nl=1\nZ t\n0\nfn\nkl(s)d\u03ben\nkl(s) \u2212\nX\nk\nX\nl\nZ t\n0\nfkl(s)d\u03bekl(s)\n\f\f\f\n\u2264\nKX\nk=1\nKX\nl=1\nsup\nt\u2208[0,1]\nZ t\n0\n\f\ffn\nkl(s) \u2212 fkl(s)\n\f\fd\u03ben\nkl(s) + sup\nt\u2208[0,1]\n\f\f\f\nZ t\n0\nfkl(s)d\u03ben\nkl(s) \u2212\nZ t\n0\nfkl(s)d\u03bekl(s)\n\f\f\f.\n(B.17)\nThe first term of (B.17) \u2192 0 since fn\nkl(s) \u2192 fkl(s) by Assumption C and lim sup n,t \u03ben\nkl([0, t]) =\n\u03bekl([0, 1]) < +\u221e by Proposition 6. For the second term of (B.17), by Proposition 6 and generalized\nLebesgue convergence theorem [51, Page 270], it is clear that\nRt\u2032\n0 fkl(s)d\u03ben\nkl(s)\u2212\nRt\u2032\n0 fkl(s)d\u03bekl(s) \u2192 0\nas n \u2192 +\u221e for any fixed t\u2032 \u2208 [0, 1]. To achieve uniform convergence, we partition [0 , 1] into\nM intervals 0 = a0 < a1 < \u00b7\u00b7\u00b7 < aM = 1 with ai \u2212 ai\u22121 = 1 /M. Then, for any fixed M,\nmax1\u2264i\u2264M |\nRai\n0 fkl(s)d\u03ben\nkl(s) \u2212\nRai\n0 fkl(s)d\u03bekl(s)| \u21920 as n \u2192 +\u221e. Using \u2225fkl(s)\u2225 < +\u221e and\nsup\n|t1\u2212t2|\u22641/M\n\f\f\f\nZ t2\nt1\nfkl(s)d\u03ben\nkl(s)\u2212\nZ t2\nt1\nfkl(s)d\u03bekl(s)\n\f\f\f \u2264 \u2225fkl\u2225 sup\n|t1\u2212t2|\u22641/M\n\f\f\f\nZ t2\nt1\nd\u03ben\nkl(s)\n\f\f\f+\n\f\f\f\nZ t2\nt1\nd\u03bekl(s)\n\f\f\f \u2192 0\nas M, n\u2192 +\u221e by Proposition 6, we can show the second term of (B.17) also \u2192 0 as n \u2192 +\u221e.\nThis completes our proof.\nC Proof of heavy traffic lower bound (Theorem 2)\nIn addition to the proof of Theorem 2, we provide rigorous justifications for Van Mieghem [63,\nProposition 6] in Section C.7 in the case when \u02dcW+ is a reflected Brownian motion.\nC.1 Overview\nSince the queue based on the predicted classes contains a mixture of true classes due to misclassi-\nfication, we must characterize its asymptotic compositions in order to analyze the queueing cost.\nFor k, l\u2208 [K], let Nn\nkl(t), t \u2208 [0, n] be the number of true class k jobs that are predicted as class\nl and remain in system n at time t, and let \u02dcN\nn\nkl(t) := n\u22121/2Nn\nkl(t) denote its the diffusion-scaled\nversion. (See Section B.3 for the formal definition.)\nProposition 7 (Proportion of true class labels) . Given a classifier f\u03b8 and a sequence of queueing\nsystems, suppose that Assumptions A, B and H hold. Under any work-conserving p-FCFS policy,\nwe have that for any k, l\u2208 [K] and t \u2208 [0, 1],\n\u02dcN\nn\nkl(t) =\npn\nkqn\nklPK\nr=1 pnr qn\nrl\n\u02dcN\nn\nl (t) + on(1). (C.1)\nFor any predicted class l \u2208 [K], Proposition 7 states the unobservable (scaled) queue length of\ntrue class k jobs, \u02dcN\nn\nkl, is proportional to the overall queue length \u02dcN\nn\nl . Moreover, the proportion is\nasymptotically \u201cstable\u201d in the sense that\npn\nk qn\nklPK\nr=1 pnr qn\nrl\nconverges to a constant under Assumption B.\n49\n\nSince the actual cost incurred by a job is governed by the job\u2019s true class label, the decomposi-\ntion (C.1) enables to approximate the aggregated cost incurred by jobs in predicted class l \u2208 [K]\naccording to their true class labels (see Eq. (C.10) to come for details).\nNext, we use Proposition 1 to reveal asymptotic relationships between endogenous processes\nsuch as \u02dcW\nn\nl and \u02dcN\nn\nl (e.g., see Lemma 16 in Section C). Combining this with the decomposi-\ntion (C.1), we establish a link between the actual cost incurred in the presence of misclassification\nerrors and the exogenous component \u02dcW\nn\n+ (see Eq. (C.11) to come). Our analysis allows us to\nidenfify a lower bound as a workload allocation over the predicted classes as we characterize in\nProposition 2.\nDiscussion of proof The proof of Proposition 7 is nontrivial, but once we arrive at the decompo-\nsition (C.1), it sheds light on the construction of the Pc\u00b5 rule (1.4). The main challenge in deriving\nthe cost functions (1.3) used in the P c\u00b5 rule (1.4) is the proof of Proposition 7. We decompose\nthe stochastic fluctuation \u02dcN\nn\nkl into fluctuations of other processes, including the service process \u02dcS\nn\nl\nand the classification partial sum process, \u02dcZ\nn\nkl. Since service times and the true/predicted class\nlabels are correlated in our model, it is not a priori clear how the corresponding fluctuations in \u02dcS\nn\nl\nand \u02dcZ\nn\nkl jointly influence that of \u02dcN\nn\nkl. The derivation of (C.1) requires articulating the stochastic\nfluctuation of \u02dcN\nn\nkl. Toward this goal, we provide a novel characterization of the service completion\nin the predicted classes from the perspective of the common stream of arrivals in Eq. (C.18). The\nproof of the proposition is provided in Section C.5.\nThe o(n\u22121/2) rates in Assumption B are the exact rate required to prove Theorem 2. Proposi-\ntion 7 relies on Proposition 1, which builds on the convergence rate in Assumption B. Importantly,\nthe same rate is necessary for a key relationship between \u02dcW\nn\nl and \u02dcN\nn\nl in Lemma 16. In Section E.1,\nwe explain how this rate condition also leads to a crucial equivalence between the age and sojourn\ntime processes, laying the foundation of the optimality of the P c\u00b5-rule in Theorem 3 to come.\nComparision to the analysis of Van Mieghem [63] Plugging Qn = I into Theorem 2, we\nrecover the classical result under perfect classification in Van Mieghem [63, Proposition 6]. In\naddition to its generality discussed above, our proof corrects an important and missing condition\nin Van Mieghem [63, Proposition 6] even in the classical setting when all true classes are known.\nAs we noted above, the o(n\u22121/2) rates for \u00b5n\nk, pn\nk, qn\nkl \u2200 k, l\u2208 [K] in our Assumption B are\nessential for proving Theorem 2. We found that the same convergence rate is also required for the\ncounterparts in Van Mieghem [63] (e.g., \u00afV n\nk in their notation), but was omitted in the result.\nIn the classical setting and beyond, we need the optimal workload allocation h that solves (3.4)\nto be continuous with respect to the total workload \u02dcW+(t), t\u2208 [0, 1]. As this argument was omitted\nin Van Mieghem [63], we give it in Proposition 15.\nIn the proof of Theorem 2, we partition the time interval [0 , 1] to bound the accrued cost\nover each small subinterval, and the approximation errors due to the finite partitioning is handled\naccordingly (see Eq. (C.5)). In the proof of Van Mieghem [63, Proposition 6], however, the partition\nis chosen by a different method than ours, and the author claims that the partition size, hence the\napproximation error, can be arbitrarily small without justification. When the workload is a general\nreflected process as in Van Mieghem [63]\u2019s setting, we found this claim to be challenging to prove.\nAs a result, we provide a rigorous justification for their claim with respect to the reflected Brownian\nmotion \u02dcW+ in Section C.7.\n50\n\nC.2 Detailed proof of heavy traffic lower bound (Theorem 2)\nWe begin by proving (3.3). We analyze \u02dcJn\n\u03c0n(t; Qn) for a fixed t \u2208 [0, 1]. By definition,\n\u02dcJn\n\u03c0n(t; Qn) = n\u22121\nKX\nl=1\nKX\nk=1\nZ nt\n0\nCn\nk (\u03c4n\nl (s)) dAn\nkl(s).\nFor a fixed \u03b5 >0, partition [0 , 1] into 0 = t0 < t1 < . . . < tM = 1 such that sup i(ti+1 \u2212 ti) = \u03b5,\nwhere M is a constant dependent on \u03b5. Let d \u03ben\nkl,i := dAn\nkl\nAn\nkl(nti+1)\u2212An\nkl(nti) be a probability measure\nover [nti, nti+1], convexity of Cn\nk and Jensen\u2019s inequality yields\n\u02dcJn\n\u03c0n(t; Qn) = n\u22121\nKX\nl=1\nKX\nk=1\nX\ni\nZ nti+1\nnti\nCn\nk (\u03c4n\nl (s))dAn\nkl(s)\n= n\u22121 X\nk\nX\nl\nX\ni\n[An\nkl(nti+1) \u2212 An\nkl(nti)]E\u03ben\nkl,i[Cn\nk (\u03c4n\nl )]\n\u2265 n\u22121 X\nk\nX\nl\nX\ni\n[An\nkl(nti+1) \u2212 An\nkl(nti)]Cn\nk (E\u03ben\nkl,i[\u03c4n\nl ]).\n(C.2)\nBy connecting E\u03ben\nkl,i[\u03c4n\nl ] with the workload process, we can show the following claim. Recallon(1) \u2192\n0 uniformly over t \u2208 [0, 1].\nClaim 14.\n\u02dcJn\n\u03c0n(t; Qn) \u2265 n\u22121 X\nk\nX\nl\nX\ni\n[An\nkl(nti+1) \u2212 An\nkl(nti)]Cn\nk (E\u03ben\nkl,i[\u03c4n\nl ]) (C.3)\n=\nX\nk\nX\nl\nX\ni\n[\u03bbpkqkl(ti+1 \u2212 ti) + on(1)] \u00b7 Cn\nk\n\u0010\nn1/2\nh\n[\u03c1l(ti+1 \u2212 ti)]\u22121\nZ ti+1\nti\n\u02dcW\nn\nl (s)ds + on(1)\ni\u0011\n.\nSince Cn\nk (n1/2\u00b7) \u2192 Ck(\u00b7) and C\u2032\nk is bounded on the compact set [0, 2 lim sup\u2225 \u02dcW+\u2225/\u03c1l], the right\nhand side of inequality (C.3) can be rewritten\nX\ni\n(ti+1 \u2212 ti)\nX\nk\nX\nl\n\u03bbpkqklCk\n\u0010 1\nti+1 \u2212 ti\nZ ti+1\nti\n\u02dcW\nn\nl (s)/\u03c1l ds\n\u0011\n+ on(1)\n\u2265\nX\ni\n(ti+1 \u2212 ti)\nX\nk\nX\nl\n\u03bbpkqklCk\n\u0010\n[h(yn\ni )]l/\u03c1l\n\u0011\n+ on(1)\n(C.4)\nwhere h(\u00b7) is the solution to Opt( r) (3.4) and\nyn\ni :=\nX\nl\n1\nti+1 \u2212 ti\nZ ti+1\nti\n\u02dcW\nn\nl (s) ds = 1\nti+1 \u2212 ti\nZ ti+1\nti\n\u02dcWn\n+(s)ds.\nBy \u02dcWn\n+ \u2192 \u02dcW+ and the continuity of \u02dcW+ in Proposition 1, applying the mean value theorem for\nintegrals yields the existence of \u03bei \u2208 [ti, ti+1] such that\nyn\ni = 1\nti+1 \u2212 ti\nZ ti+1\nti\n\u02dcW\nn\n+(s)ds = 1\nti+1 \u2212 ti\nZ ti+1\nti\n\u02dcW+(s)ds + on(1) = \u02dcW+(\u03bei) + on(1). (C.5)\nWe use continuity of h(\u00b7) to complete the proof of (3.3). For any r \u2265 0, although Opt( r) can\npotentially have multiple optimal solutions, it suffices to study properties of one specific optimal\nsolution.\n51\n\nLemma 15 (Properties of the optimal allocation). Given a classifier f\u03b8, suppose Assumptions A, B, C,\nand H hold. Let h(0) = 0 and for any r >0, let h(r) be the solution to the following equations\n\u00b5lC\u2032\nl\n\u0010xl\n\u03c1l\n\u0011\n= \u00b5mC\u2032\nm\n\u0010xm\n\u03c1m\n\u0011\n, \u2200 l, m\u2208 [K];\nKX\nl=1\nxl = r; xl \u2265 0, \u2200 l \u2208 [K]. (C.6)\nThen, i) for any r >0, there exists a unique solution, ii) h : [0, \u221e) \u2192 RK is continuous, iii) for\nany r \u2265 0, h(r) is an optimal solution to Opt (r) (3.4).\nSee Section C.3 for the proof.\nBy Lemma 15 and uniform continuity of h and Ck on compact sets (Assumption C),\nlim inf\nn\n\u02dcJn\n\u03c0n(t; Qn) \u2265 lim inf\nn\nX\ni\n(ti+1 \u2212 ti)\nX\nk\nX\nl\n\u03bbpkqklCk\n\u0010\n[h(yn\ni )]l/\u03c1l\n\u0011\n=\nX\ni\n(ti+1 \u2212 ti)\nX\nk\nX\nl\n\u03bbpkqklCk\n\u0010\u0002\nh\n\u0000 \u02dcW+(\u03bei)\n\u0001\u0003\nl/\u03c1l\n\u0011\n.\nNote that the function\u03bbpkqklCk([h( \u02dcW+(\u00b7))]l/\u03c1l) is continuous and thus Riemann integrable. Letting\n\u03b5 \u2192 0 results in (3.3):\nlim inf\nn\n\u02dcJn\n\u03c0n(t; Qn) \u2265\nKX\nk=1\nKX\nl=1\nZ t\n0\n\u03bbpkqklCk\n\u0010\u0002\nh\n\u0000 \u02dcW+(s)\n\u0001\n]l\n\u03c1l\n\u0011\nds.\nTo show (3.5), consider feasible p-FCFS policies{\u03c0\u2032\nn}. For all n \u2208 N, the original processes under Pn\nsatisfy Pn[ \u02dcJn\n\u03c0\u2032n\n(t; Qn) > x] = Pcopy[ \u02dcJn\n\u03c0\u2032n\n(t; Qn) > x], \u2200 x \u2208 R, t \u2208 [0, 1], according to the Skorohod\nrepresentation. By Fatou\u2019s lemma, for any x \u2208 R, t\u2208 [0, 1], we have that\nlim inf\nn\nPn[ \u02dcJn\n\u03c0\u2032n\n(t; Qn) > x] = lim inf\nn\nPcopy[ \u02dcJn\n\u03c0\u2032n\n(t; Qn) > x] \u2265 EPcopy[lim inf\nn\nI{ \u02dcJn\n\u03c0\u2032n\n(t; Qn) > x}].\nAs lim infn\u2192\u221e \u02dcJn\n\u03c0\u2032n\n(t; Qn) \u2265 \u02dcJ\u2217(t; Q) Pcopy-a.s. by (3.3), we have that\nEPcopy[lim inf\nn\nI{ \u02dcJn\n\u03c0\u2032n\n(t; Qn) > x}] \u2265 EPcopy[I{lim inf\nn\n\u02dcJn\n\u03c0\u2032n\n(t; Qn) > x}] \u2265 Pcopy[ \u02dcJ\u2217(t; Q) > x].\nCombining equations above yields (3.5) for any feasible p-FCFS policies. We can further ex-\ntend (3.5) to any feasible policies using Lemma 11. This completes our proof.\nProof of Claim 14 Since n\u22121An\nkl(n\u00b7) \u2192 \u00afAkl by Proposition 6,\nn\u22121[An\nkl(nti+1) \u2212 An\nkl(nti)] = \u00afAkl(ti+1) \u2212 \u00afAkl(ti) + on(1) = \u03bbpkqkl(ti+1 \u2212 ti) + on(1). (C.7)\nApply the convergence (C.7) to rewrite E\u03ben\nkl,i[\u03c4n\nl ]\nE\u03ben\nkl,i[\u03c4n\nl ] = n\u22121\u0000\nn\u22121[An\nkl(nti+1) \u2212 An\nkl(nti)]\n\u0001\u22121\nZ nti+1\nnti\n\u03c4n\nl dAn\nkl,\n= n\u22121\u0002\n[\u03bbpkqkl(ti+1 \u2212 ti)]\u22121 + on(1)\n\u0003Z nti+1\nnti\n\u03c4n\nl dAn\nkl,\n(C.8)\nwhere the last line holds since ( x + \u2206x)\u22121 = x\u22121 \u2212 \u2206x + o(\u2206x).\nWe approximate\nRnb\nna \u03c4n\nl dAn\nkl using a variant of Little\u2019s Law that we prove in Section C.4.\n52\n\nProposition 8 (Little\u2019s law). Given a classifier f\u03b8, suppose Assumptions A, B, and H hold. Then,\nfor any 0 \u2264 a < b\u2264 1\nn\u22123/2\n\u00afAn\nkl(b) \u2212 \u00afAn\nkl(a)\nZ nb\nna\n\u03c4n\nl dAn\nkl \u2212 1\n\u00afAn\nkl(b) \u2212 \u00afAn\nkl(a)\nZ b\na\n\u02dcN\nn\nkl(t)dt = o(1), \u2200 k, l\u2208 [K], (C.9a)\nn\u22123/2\n\u00afAn\nl (b) \u2212 \u00afAn\nl (a)\nZ nb\nna\n\u03c4n\nl dAn\nl \u2212 1\n\u00afAn\nl (b) \u2212 \u00afAn\nl (a)\nZ b\na\n\u02dcN\nn\nl (t)dt = o(1), \u2200 l \u2208 [K]. (C.9b)\nIf there further exist limits \u02dc\u03c4n\nl \u2192 \u02dc\u03c4l \u2208 Cand \u02dcN\nn\nl \u2192 \u02dcNl \u2208 C, then \u03bbpl\u02dc\u03c4l = \u02dcNl.\nApplying the proposition n\u22123/2 Rnb\nna \u03c4n\nl dAn\nkl \u2212\nRb\na\n\u02dcN\nn\nkl(t)dt = on(1)O(|b \u2212 a|) to Eq. (C.8),\nE\u03ben\nkl,i[\u03c4n\nl ] = n1/2\u0002\n[\u03bbpkqkl(ti+1 \u2212 ti)]\u22121 + on(1)\n\u0003\u0010Z ti+1\nti\n\u02dcN\nn\nkl(s)ds + on(1)O(ti+1 \u2212 ti)\n\u0011\n= n1/2\nh\n[\u03bbkpkqkl(ti+1 \u2212 ti)]\u22121\nZ ti+1\nti\n\u02dcN\nn\nkl(s)ds + on(1) + on(1)O(\u03b5)\ni\n,\n(C.10)\nsince supi(ti+1 \u2212 ti) = O(\u03b5) and lim supn \u2225 \u02dcNkl\u2225 \u2264lim supn \u2225 \u02dcNl\u2225 < \u221e by Proposition 1.\nTo rewrite\nRb\na\n\u02dcN\nn\nkl(s)ds in terms of the workload, recall the key relation \u02dcN\nn\nkl =\npn\nk qn\nklP\nr pnr qn\nrl\n\u02dcN\nn\nl +on(1)\ngiven in Proposition 7 (see Section C.5 for its proof). We can further approximate the queue length\nprocess \u02dcN\nn\nl using the service rate \u00b5l and the remaining workload process \u02dcW\nn\nl .\nLemma 16 (Relation between \u02dcW\nn\nl and \u02dcN\nn\nl ). Given a classifier f\u03b8, suppose Assumptions A, B,\nand H hold. Then, for p-FCFS policies \u00b5l\n\u02dcW\nn\nl \u2212 \u02dcN\nn\nl \u2192 0 for all l \u2208 [K].\nSee Section C.6 for the proof. Applying Proposition 7 and Lemma 16,\nZ b\na\n\u02dcN\nn\nkl(s)ds =\nZ b\na\n\u00b5l\npkqklP\nr prqrl\n\u02dcW\nn\nl (s)ds + on(1)O(|b \u2212 a|).\nPlugging this into the expression (C.10) for E\u00b5n\nkl,i[\u03c4n\nl ]\nE\u03ben\nkl,i[\u03c4n\nl ] = n1/2\nh\n[\u03bbkpkqkl(ti+1 \u2212 ti)]\u22121\n\u0010Z ti+1\nti\n\u00b5l\npkqklP\nr prqrl\n\u02dcW\nn\nl (s)ds + on(1)O(ti+1 \u2212 ti)\n\u0011\n+ on(1)\ni\n= n1/2\nh\n[\u03c1l(ti+1 \u2212 ti)]\u22121\nZ ti+1\nti\n\u02dcW\nn\nl (s)ds + on(1)\ni\n,\n(C.11)\nwhere we use the shorthands pl = P\nr prqrl and \u03c1l =\n\u03bbpl\n\u00b5l\nin the final line.\nC.3 Proof of Lemma 15\nFor any l \u2208 [K], Assumption C implies C\u2032\nl is continuous and strictly increasing. Hence,\ng(x) := x +\nKX\nl=2\n\u03c1l \u00b7 (C\u2032\nl)\u22121\n\u0010\u00b51\n\u00b5l\nC\u2032\n1(\u03c1\u22121\n1 x)\n\u0011\n(C.12)\nis continuous and strictly increasing with g(0) = 0, g(r) \u2265 r. Let x1(r) be a unique solution to\ng(x) = r and\nxl(r) := \u03c1l \u00b7 (C\u2032\nl)\u22121\n\u0010\u00b51\n\u00b5l\nC\u2032\n1(\u03c1\u22121\n1 x1)\n\u0011\n, \u2200 l \u2265 2.\n53\n\nEvidently, h(r) = (x1(r), . . . , xK(r)) is a unique solution to Eq. (C.6). To see (ii), note that x1(r)\nis continuous with x1(r) = 0 since g\u22121 is continuous. For (iii), for r = 0, h(0) = 0 is clearly an\noptimal solution to Opt(0). When r >0, we verify h(r) satisfies the KKT conditions for Opt( r).\nThis is evident from the fact that C\u2032\nl(0) = (C\u2032\nl)\u22121(0) = 0 and C\u2032\nl and (C\u2032\nl)\u22121 are strictly increasing\n(Assumption C).\nC.4 Proof of Proposition 8\nOur proof for Eqs. (C.9a) and (C.9b) is similar to the proof for Van Mieghem [63, Proposition 4].\nTo show Eqs. (C.9a), consider the cumulative cost during t \u2208 [a, b] where each job incurs a unit\ncost per unit time spent in the system. We study three different cost charging schemes\nCostn\n1 (a, b) = 1\n\u00afAn\nkl(b) \u2212 \u00afAn\nkl(a)\nAn\nkl(nb)X\ni=An\nkl(na)\n\u03c4n\nli,\nCostn\n2 (a, b) = 1\n\u00afAn\nkl(b) \u2212 \u00afAn\nkl(a)\nZ nb\nna\nNn\nkl(t)dt,\nCostn\n3 (a, b) = 1\n\u00afAn\nkl(b) \u2212 \u00afAn\nkl(a)\nAn\nkl(nb)\u2212Nn\nkl(nb)X\ni=An\nkl(na)\n\u03c4n\nli.\nCostn\n1 (a, b) charges the entire cost at the job\u2019s arrival, Cost n\n3 (a, b) at the job\u2019s departure, and\nCostn\n2 (a, b) continuously. It is easy to verify\nCostn\n3 (a, b) \u2264 Costn\n2 (a, b) \u2264 Costn\n1 (a, b),\nand\nn\u22123/2(Costn\n1 (a, b) \u2212 Costn\n3 (a, b)) = n\u22123/2\n\u00afAn\nkl(b) \u2212 \u00afAn\nkl(a)\nAn\nkl(nb)X\ni=An\nkl(nb)\u2212Nn\nkl(nb)+1\n\u03c4n\nli\n\u2264 n\u22121/2\n\u00afAn\nkl(b) \u2212 \u00afAn\nkl(a)\u2225 \u02dcN\nn\nkl\u2225\u2225\u02dc\u03c4n\nl \u2225 \u21920,\nsince \u00afAn\nkl \u2192 \u00afAkl by Assumption B, and \u2225 \u02dcN\nn\nkl\u2225 and \u2225\u02dc\u03c4n\nl \u2225 are bounded (Proposition 1). Conclude\non(1) = n\u22123/2\n\u00afAn\nkl(b) \u2212 \u00afAn\nkl(a)\nZ nb\nna\n\u03c4n\nl dAn\nkl \u2212 n\u22123/2\n\u00afAn\nkl(b) \u2212 \u00afAn\nkl(a)\nZ nb\nna\nNn\nkl(t)dt\n= n\u22123/2\n\u00afAn\nkl(b) \u2212 \u00afAn\nkl(a)\nZ nb\nna\n\u03c4n\nl dAn\nkl \u2212 1\n\u00afAn\nkl(b) \u2212 \u00afAn\nkl(a)\nZ b\na\n\u02dcN\nn\nkl(t)dt.\nThe proof for Eq. (C.9b) can be established similarly and we omit the details.\nFor the second result, further assume \u02dc\u03c4n\nl \u2192 \u02dc\u03c4l for all l \u2208 [K]. To see \u03bbpl\u02dc\u03c4l = \u02dcNl, it suffices to\nshow \u03bbpl\u02dc\u03c4l(t) = \u02dcNl(t). Recall that by Eq. (C.9b),\nn\u22123/2\n\u00afAn\nl (b) \u2212 \u00afAn\nl (a)\nZ nb\nna\n\u03c4n\nl dAn\nl \u2212 1\n\u00afAn\nl (b) \u2212 \u00afAn\nl (a)\nZ b\na\n\u02dcN\nn\nl (t)dt = on(1), \u2200 l \u2208 [K].\nFor simplicity, for fixed [a, b], let \u03ben\nl be the Lebesgue-Stieltjes measure on [0, 1] induced byn\u22121An\nl (n\u00b7)\n54\n\nand \u03bel be the Lebesgue-Stieltjes measure on [0 , 1] induced by \u00afAl(\u00b7). It is easy to verify\nn\u22123/2\nZ nb\nna\n\u03c4n\nl (t)dAn\nl (t) =\nZ b\na\n\u02dc\u03c4n\nl d\u03ben\nl .\nSince \u03ben\nl \u2192 \u03bel and \u2225\u02dc\u03c4n\nl \u2225 \u2264lim supn \u2225\u02dc\u03c4n\nl \u2225 < +\u221e eventually (Proposition 1), generalized Lebesgue\nconvergence [51, Page 270] implies\nn\u22123/2\nZ nb\nna\n\u03c4n\nl (t)dAn\nl (t) \u2192\nZ b\na\n\u02dc\u03c4l(t)d \u00afAl(t) =\nZ b\na\n\u03bbpl\u02dc\u03c4l(t)dt. (C.13)\nNext, we analyze the second term of Eq. (C.9b). Dominated convergence gives\n1\n\u00afAn\nl (nb) \u2212 \u00afAn\nl (na)\nZ b\na\n\u02dcN\nn\nl (t)dt \u2192 1\n\u00afAl(b) \u2212 \u00afAl(a)\nZ b\na\n\u02dcNl(t)dt. (C.14)\nCombining Eqs. (C.9b), (C.13), and (C.14) yields that for all [ a, b] \u2282 [0, 1],\n1\n\u00afAl(b) \u2212 \u00afAl(a)\nZ b\na\n\u03bbpl\u02dc\u03c4l(t)dt = 1\n\u00afAl(b) \u2212 \u00afAl(a)\nZ b\na\n\u02dcNl(t)dt. (C.15)\nNote that \u00afAl(t) = \u03bbplt. Hence, for fixed t \u2208 [0, 1], inserting a = t, b= t + \u2206t into Eq. (C.15) gives\n1\n\u00afAl(t + \u2206t) \u2212 \u00afAl(t)\nZ t+\u2206t\nt\n\u02dcNl(s)ds = 1\n\u03bbpl\n\u00b7 1\n\u2206t\nZ t+\u2206t\nt\n\u02dcNl(s)ds \u2192 1\n\u03bbpl\n\u02dcNl(t), (C.16)\nas \u2206t \u2192 0, where the convergence follows from continuity of \u02dcNl and the mean value theorem for\ndefinite integrals. Similarly, one can show as \u2206 t \u2192 0,\n1\n\u00afAl(t + \u2206t) \u2212 \u00afAl(t)\nZ t+\u2206t\nt\n\u03bbpl\u02dc\u03c4l(s)ds \u2192 \u02dc\u03c4l(t). (C.17)\nCombining Eqs. (C.15), (C.16), and (C.17) yields the desired result \u03bbpl\u02dc\u03c4l = \u02dcNl, \u2200 l \u2208 [K].\nC.5 Proof of Proposition 7\nRecalling the definition (B.6), for any nt \u2208 [0, n]\nNn\nkl(nt) = An\nkl(nt) \u2212\n(Mn\nl \u25e6Sn\nl \u25e6Tn\nl )(nt)X\ni=1\nY n\nikY n\nil = An\nkl(nt) \u2212 Zn\nkl\n\u0010\n(Mn\nl \u25e6 Sn\nl \u25e6 Tn\nl )(nt)\n\u0011\n.\nBy Lemma 4, Proposition 6, and Eq. (B.13),\nZn\nkl(nt) = npn\nkqn\nklt + n1/2 \u02dcZ\nn\nkl(t) + o(n1/2),\nSn\nl (nt) = n\u00b5n\nl t + n1/2 \u02dcS\nn\nl (t) + o(n1/2),\nTn\nl (nt) = n\u03bbnpn\nl (\u00b5n\nl )\u22121t + n1/2 \u02dcT\nn\nl (t) + o(n1/2).\nRecalling \u2225 \u02dcT\nn\nl \u2225 < +\u221e by Proposition 1, ( Sn\nl \u25e6 Tn\nl )(nt) can be reformulated as\n(Sn\nl \u25e6 Tn\nl )(nt) = \u00b5n\nl Tn\nl (nt) + n1/2 \u02dcS\nn\nl (n\u22121Tn\nl (nt)) + o(n1/2)\n= n\u03bbnpn\nl t + n1/2\u00b5n\nl\n\u02dcT\nn\nl (t) + n1/2 \u02dcS\nn\nl (\u03bbnpn\nl (\u00b5n\nl )\u22121t + n\u22121/2 \u02dcT\nn\nl (t) + o(n\u22121/2)) + o(n1/2)\n=n\u03bbnpn\nl t + n1/2\u00b5n\nl\n\u02dcT\nn\nl (t) + n1/2 \u02dcS\nn\nl (\u03bbnpn\nl (\u00b5n\nl )\u22121t + o(1)) + o(n1/2).\n55\n\nTherefore, we can rewrite ( Mn\nl \u25e6 Sn\nl \u25e6 Tn\nl )(nt) as\n(Mn\nl \u25e6 Sn\nl \u25e6 Tn\nl )(nt) = n\u03bbnt + n1/2(pn\nl )\u22121\u00b5n\nl\n\u02dcT\nn\nl (t) + n1/2(pn\nl )\u22121 \u02dcS\nn\nl (\u03bbnpn\nl (\u00b5n\nl )\u22121t + o(1))\n+ n1/2 \u02dcM\nn\nl (\u03bbnpn\nl t + o(1)) + o(n1/2).\n(C.18)\nSince An\nkl(nt) = \u03bbnpn\nkqn\nklnt + n1/2 \u02dcA\nn\nkl(t) according to the proof of Proposition 6 and Zn\nkl(nt) =\npn\nkqn\nklnt + n1/2 \u02dcZ\nn\nkl(t) by Definition 10, combining equations above yields\n\u02dcN\nn\nkl(t) = \u02dcA\nn\nkl(t) \u2212\npn\nkqn\nkl\npn\nl\nh\n\u00b5n\nl\n\u02dcT\nn\nl (t) + \u02dcS\nn\nl (\u03bbnpn\nl (\u00b5n\nl )\u22121t + o(1))\ni\n\u2212 pn\nkqn\nkl\n\u02dcM\nn\nl (\u03bbnpn\nl t + o(1)) \u2212 \u02dcZ\nn\nkl(\u03bbnt + o(1)) + o(1).\nMoreover, the proof of Proposition 6 implies\n\u02dcS\nn\nl \u2192 \u02dcSl, \u02dcA\nn\nkl \u2192 \u02dcAkl := \u02dcZkl \u25e6 \u03bbe + pkqkl\n\u02dcA0, \u02dcM\nn\nl \u2192 \u02dcMl := \u2212p\u22121\nl\n\u0010 KX\nk=1\n\u02dcZkl\n\u0011\n\u25e6 p\u22121\nl e.\nSince the limiting process is continuous, by continuity of composition [68, Theorem 13.2.1] and\ncontinuous mapping theorem, we have that\n\u02dcS\nn\nl (\u03bbnpn\nl (\u00b5n\nl )\u22121t + o(1)) = \u02dcS\nn\nl (\u03bbnpn\nl (\u00b5n\nl )\u22121t) + o(1), \u02dcA\nn\nkl \u2212 \u02dcZ\nn\nkl(\u03bbn \u00b7 +o(1)) = pn\nkqn\nkl\n\u02dcA\nn\n0 + o(1),\n\u02dcM\nn\nl (\u03bbnpn\nl \u00b7 +o(1)) = \u2212(pn\nl )\u22121\n\u0010 KX\nk=1\n\u02dcZ\nn\nkl(\u03bbn\u00b7)\n\u0011\n+ o(1).\nThus, we can further rewrite \u02dcN\nn\nkl(t) as\npn\nkqn\nkl\n\u02dcA\nn\n0 (t) \u2212\npn\nkqn\nkl\npn\nl\nh\n\u00b5n\nl\n\u02dcT\nn\nl (t) + \u02dcS\nn\nl (\u03bbnpn\nl (\u00b5n\nl )\u22121t)\ni\n+\npn\nkqn\nkl\npn\nl\nKX\nk=1\n\u02dcZ\nn\nkl(\u03bbnt) + o(1)\n=\n\u02dcA\nn\nl (t) \u2212 PK\nk=1 \u02dcZ\nn\nkl(\u03bbnt)\npn\nl\npn\nkqn\nkl \u2212\npn\nkqn\nkl\npn\nl\nh\n\u00b5n\nl\n\u02dcT\nn\nl (t) + \u02dcS\nn\nl (\u03bbnpn\nl (\u00b5n\nl )\u22121t)\ni\n+\npn\nkqn\nkl\npn\nl\nKX\nk=1\n\u02dcZ\nn\nkl(\u03bbnt) + o(1)\n=\npn\nkqn\nkl\npn\nl\nh\n\u02dcA\nn\nl (t) \u2212 \u00b5n\nl\n\u02dcT\nn\nl (t) \u2212 \u02dcS\nn\nl (\u03bbnpn\nl (\u00b5n\nl )\u22121t)\ni\n+ o(1),\nwhere the second line follows from the identity \u02dcA\nn\nl (t) =\nKP\nk=1\n\u02dcZ\nn\nkl(\u03bbnt)+ pn\nl\n\u02dcAn\n0 (t)+ on(1) we derived in\nthe proof of Proposition 6. Then, by (B.14), we have the desired result \u02dcN\nn\nkl(t) =\npn\nk qn\nkl\npn\nl\n\u02dcN\nn\nl (t) +o(1).\nC.6 Proof of Lemma 16\nFor any nt \u2208 [0, n], let vn\nl (nt) be the amount of service, if any, already given to the oldest predicted\nclass l job present in the system at time nt. By definition, t \u2208 [0, 1],\n\u02dcW\nn\nl (t) = n\u22121/2\u0002\nV n\nl (An\nl (nt)) \u2212 V n\nl\n\u0000\nAn\nl (nt) \u2212 Nn\nl (nt)\n\u0001\n\u2212 vn\nl (nt)\n\u0003\n= n1/2\u0002\u00afV n\nl (n\u22121An\nl (nt)) \u2212 \u00afV n\nl\n\u0000\nn\u22121An\nl (nt) \u2212 n\u22121Nn\nl (nt)\n\u0001\u0003\n+\n\u0002\u02dcV\nn\nl (n\u22121An\nl (nt)) \u2212 \u02dcV\nn\nl\n\u0000\nn\u22121An\nl (nt) \u2212 n\u22121Nn\nl (nt)\n\u0001\u0003\n+ o(1) \u2212 n\u22121/2vn\nl (nt),\n(C.19)\n56\n\nwhere the second equality follows from Proposition 6, and o(\u00b7) is uniform over t \u2208 [0, 1]. We can\nrewrite the first term by noting \u00afV n\nl (t) = (\u00b5n\nl )\u22121t and n1/2(\u00b5n\nl \u2212 \u00b5l) = on(1) by Assumption B\nn1/2[ \u00afV n\nl (n\u22121An\nl (nt)) \u2212 \u00afV n\nl (n\u22121An\nl (nt) \u2212 n\u22121Nn\nl (nt))]\n= n1/2[ \u00afV l(n\u22121An\nl (nt)) \u2212 \u00afV l(n\u22121An\nl (nt) \u2212 n\u22121Nn\nl (nt))] + on(1)\n= n\u22121/2\u00b5\u22121\nl Nn\nl (nt) + on(1) = \u00b5\u22121\nl \u02dcN\nn\nl (t) + on(1).\nIt remains to bound the second term in Eq. (C.19). Notice that since \u02dcV\nn\nl = \u02dcV l + on(1) where\n\u02dcV l is uniformly continuous on compact intervals by Proposition 6 and lim sup n \u2225 \u02dcN\nn\nl \u2225 < +\u221e by\nProposition 1,\n\u02dcV\nn\nl (n\u22121An\nl (nt)) \u2212 \u02dcV\nn\nl (n\u22121An\nl (nt) \u2212 n\u22121Nn\nl (nt))\n= \u02dcV l(n\u22121An\nl (nt)) \u2212 \u02dcV l(n\u22121An\nl (nt) \u2212 n\u22121Nn\nl (nt)) + on(1) = on(1).\nC.7 Complementary proof for Proposition 6 in Van Mieghem [63]\nCompared to the proof of Van Mieghem [63, Proposition 6], we adopt a different partition of the time\ninterval [0, 1] to derive Eq. (C.5) using the mean-value theorem. To show the analogous result [63,\nEq. (94)], Van Mieghem picks a partition using stopping times of \u02dcW+ to ensure sufficiently small\nvariation of \u02dcW+ over each subinterval. Without justification, Van Mieghem [63] claims the partition\nsize is small enough ( O(\u03b5)).\nDespite best efforts, we found proving this claim difficult when the workload \u02dcW+ is a general\nreflected process. When \u02dcW+ is a relection Brownian motion, we give a proof that the partition size\nis still supi(ti+1 \u2212ti) = O(\u03b5) in Lemma 17 below; hence (C.5) would follow even if {ti} is chosen as\nthe stopping times as by Van Mieghem [63]. Our proof exploits the almost sure non-differentiablity\nof sample paths of reflected Brownian motions. (Alternatively, our previous proof provides a simple\njustification for [63, Eq. (94)] using our mean value theorem result (C.5).)\nLemma 17 (Stopping times of \u02dcW+). Given \u03b5 >0, consider the sequence of stopping times {ti(\u03b5) :\ni \u2208 N} of \u02dcW+\nt1(\u03b5) = min{1, inf{0 < t\u2264 1 : | \u02dcW+(t) \u2212 \u230a\u02dcW+(0)/\u03b5\u230b\u03b5| \u2265\u03b5}},\nti+1(\u03b5) = min{1, inf{ti(\u03b5) < t\u2264 1 : | \u02dcW+(t) \u2212 \u02dcW+(ti(\u03b5))| \u2265\u03b5}}.\nThen, we have that\nlim\n\u03b5\u21920\nsup\ni\n(ti+1(\u03b5) \u2212 ti(\u03b5)) = 0\nProof We prove by contradiction and will show that if Lemma 17 does not hold, then there\nexists [a, b] \u2282 [0, 1] such that b \u2212 a >0 and \u02dcW+ is a constant on [ a, b]. We argue that the latter\nleads to a contraction using that \u02dcW+ is a reflected Brownian motion as shown in Proposition 1. If\n\u02dcW+(t) = 0 for t \u2208 [a, b], then the associated Brownian motion must be monotonically decreasing on\n[a, b] because of the definition of the reflection mapping [68], but this is a zero probability event [43].\nIf \u02dcW+(t) = c for some positive constant c and t \u2208 [a, b], it is contradictory to the nondifferentiability\nof Brownian motion [43].\nSuppose for the purpose of contradiction that there exists some \u03b4 >0, a sequence of \u03b5k \u2192 0,\nand a sequence of {ik}\u221e\nk=1 satisfying\ntik+1(\u03b5k) \u2212 tik(\u03b5k) \u2265 \u03b4, and | \u02dcW+(t) \u2212 \u02dcW+(tik(\u03b5k))| \u2264\u03b5k, \u2200 t \u2208 [tik(\u03b5k), tik(\u03b5k) + \u03b4] \u2282 [0, 1].\n57\n\nLet I(k) = [tik(\u03b5k), tik(\u03b5k) +\u03b4] \u2282 [0, 1] for all k \u2265 1. We claim that there exists b \u2212 a \u2265 \u03b40 > 0 and\na subsequence {kl}\u221e\nl=1 such that [a, b] \u2282 I(kl) for all l \u2265 1. Let M = \u23082/\u03b4\u2309 . Partition [0 , 1] into\n0 = a0 < a1 < \u00b7\u00b7\u00b7 < aM = 1\nwith ar+1 \u2212 ar = \u03b4/2 > 0, possibly except the last interval. Evidently, there exists some r0 \u2208\n{0, 1, ..., M\u2212 1} such that [ ar0, ar0+1] \u2229 I(k) \u0338= \u2205, for infinitely many k\u2019s; otherwise PM\u22121\nm=0 #{k :\n[am, am+1] \u2229 I(k) \u0338= \u2205, k\u2208 N} < +\u221e, so that PM\u22121\nm=0 #{k : [am, am+1] \u2229 I(k) \u0338= \u2205, k\u2208 N} \u2265#{k :\nk \u2208 N+} = \u221e gives a contradiction.\nWe next construct the aforementioned interval [a, b] and subsequence {kl}\u221e\nl=1. Since [ar0, ar0+1]\u2229\nI(k) \u0338= \u2205 for infinitely many k, at least one of the following statement hold:\n(i) there exists a subsequence {kl}\u221e\nl=1 such that tikl\n(\u03b5kl) > ar0 for all l;\n(ii) there exists a subsequence {kl}\u221e\nl=1 such that tikl\n(\u03b5kl) + \u03b4 < ar0+1 for all l;\n(iii) there exists a subsequence {kl}\u221e\nl=1 such that tikl\n(\u03b5kl) \u2264 ar0 < ar0+1 \u2264 tikl\n(\u03b5kl) + \u03b4 for all l.\nFor the case of (i), by definition we have that for all l, ar0 < tikl\n(\u03b5kl) \u2264 ar0+1 since I(kl) \u2229\n[ar0, ar0+1] \u0338= \u2205. Therefore, for all l, we have that ar0 +\u03b4 < tikl\n(\u03b5kl)+ \u03b4 \u2264 ar0+1 +\u03b4. In other words,\n[ar0+1, ar0 + \u03b4] \u2282 Ikl, \u2200 l \u2265 1. Hence, we can set a = ar0+1, b= ar0 + \u03b4, where b \u2212 a \u2265 \u03b4/2. For (ii)\nand (iii), we can construct a and b similarly and we skip the details here.\nThen, by [a, b] \u2282 I(kl), we have that supa\u2264t,t\u2032\u2264b | \u02dcW+(t) \u2212 \u02dcW+(t\u2032)| \u22642\u03b5kl, \u2200 l \u2265 1, which implies\nthat \u02dcW+(t) is a constant on [ a, b]. This completes our proof.\nD Proof of Proposition 13\nRecalling the strong convexity of Cl,\nCl(y) \u2265 Cl(x) + C\u2032\nl(x)(y \u2212 x) + m\n2 (y \u2212 x)2, \u2200 x, y,\u2200 l \u2208 [K].\nfor some m >0, we use the following constants\n\u00b5min = min\nl\u2208[K]\n\u00b5l, \u00b5 max = max\nl\u2208[K]\n\u00b5l, \u03c1 min = min\nl\u2208[K]\n\u03c1l, \u03c1 max = max\nl\u2208[K]\n\u03c1l,\n\u03b10 :=\n\u03c1min\n3(K \u2212 1)\u03c1max\n, \u03b2 0 :=\n\u00b5min\u03b10\n2 , \u03b3 0 := \u03b10\n1 \u2212 \u03c1min\n.\n(D.1)\nSince C\u2032\nl is uniformly continuous on the compact set [0 , lim supn \u2225\u02dcan\nl \u2225] where lim supn \u2225\u02dcan\nl \u2225 < +\u221e\naccording to Proposition 12, we have the following result.\nLemma 18 (Continuity of C\u2032\nl). Given a classifier f\u03b8, suppose that Assumption C holds. For any\n\u03b5 >0, there exists \u03b41(\u03b5), \u03b42(\u03b5) > 0 such that for any a1, a2 \u2208 [0, lim supn \u2225\u02dcan\nl \u2225],\n(i) if |a2 \u2212 a1| \u2264\u03b41(\u03b5), then |C\u2032\nl(a2) \u2212 C\u2032\nl(a1)| < \u03b5\n8\u00b5max\n, \u2200 l \u2208 [K];\n(ii) if |a2 \u2212 a1| \u2264\u03b42(\u03b5), then |C\u2032\nl(a2) \u2212 C\u2032\nl(a1)| < m\u03b20\n2\u00b5max\n\u03b41(\u03b5), \u2200 l \u2208 [K].\n58\n\nOur proof is separated into three propositions. Below, we suppose Assumptions A, B, C, D,\nand H hold. For any \u03b5 >0, let \u03b41(\u03b5), \u03b42(\u03b5) be constants defined in Lemma 18 and define \u03b4n\n1 (\u03b5) :=\nn\u22121/2\u03b41(\u03b5), \u03b4n\n2 (\u03b5) := n\u22121/2\u03b42(\u03b5). Partition the time interval [0 , n] into subintervals of length no\nmore than n\u03b4n\n1 (\u03b5). Letting N(\u03b5) be large enough so the below propositions hold for n \u2265 N(\u03b5), our\ndesired result follows by using an inductive argument over these subintervals.\nSee Section D.2 for the proof of the first proposition.\nProposition 9 (Max difference of the P c\u00b5 indices at endpoints: Case I) . Let t1 \u2208 [0, 1 \u2212 \u03b4n\n1 (\u03b5)] be\nsuch that maxl,m\u2208[K] |In\nl (t1) \u2212 In\nm(t1)| < \u03b5and all predicted classes are selected by the P c\u00b5-rule in\n[nt1, n(t1 + \u03b4n\n1 (\u03b5))]. Then, there exists N(\u03b5) > 0 such that for any n > N(\u03b5)\nmax\nl1,l2\u2208[K]\n|In\nl1(t1 + \u03b4n\n1 (\u03b5)) \u2212 In\nl2(t1 + \u03b4n\n1 (\u03b5))| < \u03b5.\nWe prove the second proposition in Section D.3.\nProposition 10 (Max difference of the P c\u00b5-rule indices at endpoints: Case II) . Let t1 \u2208 [0, 1 \u2212\n\u03b4n\n1 (\u03b5)] be such that maxl,m\u2208[K] |In\nl (t1) \u2212 In\nm(t1)| < \u03b5and some predicted class is NOT selected for\nservice under the P c\u00b5-rule in [nt1, n(t1 + \u03b4n\n1 (\u03b5))]. Then, there exists N(\u03b5) > 0 such that for any\nn > N(\u03b5)\n(i) (No Idling) if there is no server idle time in [nt1, n(t1 + \u03b4n\n1 (\u03b5))], then there exists sn\n1 \u2208 [t1 +\n\u03b30\u03b4n\n1 (\u03b5), t1 + \u03b4n\n1 (\u03b5)] such that maxl1,l2\u2208[K] |In\nl1(sn\n1 ) \u2212 In\nl2(sn\n1 )| < \u03b5;\n(ii) (Idling) if server idling occurs in [nt1, n(t1 +\u03b4n\n1 (\u03b5))], then maxl1,l2\u2208[K] |In\nl1(t1 +\u03b4n\n1 (\u03b5))\u2212In\nl2(t1 +\n\u03b4n\n1 (\u03b5))| < \u03b5.\nFinally, see Section D.4 for the proof of the third proposition.\nProposition 11 (Max difference of the P c\u00b5-rule indices within intervals) . Let t1 \u2208 [0, 1] be such\nthat maxl,m\u2208[K]\n\f\fIn\nl (t1) \u2212 In\nm(t1)\n\f\f < \u03b5. Then, there exists N(\u03b5) > 0 such that for any n > N(\u03b5)\nmax\nl1,l2\u2208[K]\nsup\nt\u2208[t1,(t1+\u03b4n\n1 (\u03b5))\u22271]\n\f\fIn\nl1(t) \u2212 In\nl2(t)\n\f\f < 3\u03b5/2.\nD.1 Preliminaries\nFacts about limiting diffusion processes We use the following basic facts to analyze the\ndynamics of \u02dcan.\nLemma 19 (Continuity of \u02dcAl and \u02dcSl). There exists N(\u03b5) such that for n > N(\u03b5) and t1, t2 \u2208 [0, 1],\n(i) if |t2 \u2212 t1| < \u03b4n\n1 (\u03b5), then | \u02dcAl(t2) \u2212 \u02dcAl(t1)| < \u03b10\u03b41(\u03b5)/3, \u2200 l \u2208 [K];\n(ii) if |t2 \u2212 t1| < \u03b4n\n1 (\u03b5), then |\u02dcSl(n\u22121Tn\nl (nt2)) \u2212 \u02dcSl(n\u22121Tn\nl (nt1))| < \u03b10\u03b41(\u03b5)/3, \u2200 l \u2208 [K].\nProof By Proposition 6, we have supt\u2208[0,1] | \u02dcAl(t+on(1))\u2212 \u02dcAl(t)| = on(1) by uniform continuity of\n\u02dcAl over a closed interval of which [0, 1] is a proper subset for all l \u2208 [K]. (i) is a direct consequence\nof |t2 \u2212 t1| = on(1). To see (ii), we have sup t\u2208[0,1] |\u02dcSl(t + on(1)) \u2212 \u02dcSl(t)| = on(1) similarly, and\nsupt\u2208[0,1] |n\u22121Tl(n(t + on(1))) \u2212 n\u22121Tl(nt)| = on(1) by (B.13).\n59\n\nLemma 20 (Relation between \u02dcan\nl and \u02dcT\nn\nl ). Given a classifier f\u03b8, suppose Assumptions A, B,\nand H hold. Under p-FCFS feasible policies,\n\u02dcan\nl (t) = n1/2t \u2212 n\u22121/2\u03c1\u22121\nl Tn\nl (nt) + \u03bb\u22121\nl \u02dcAl(t) \u2212 \u03bb\u22121\nl \u02dcSl(n\u22121Tn\nl (nt)) + on(1). (D.2)\nProof Recalling An\nl (nt) = n \u00afAn\nl (t)+ n1/2 \u02dcA\nn\nl (t)+ on(n1/2), Sn\nl (nt) = n \u00afSn\nl (t)+ n1/2 \u02dcS\nn\nl (t)+ on(n1/2)\n(Proposition 6),\n\u02dcN\nn\nl (t) = n1/2 \u00afAn\nl (t) + \u02dcA\nn\nl (t) \u2212 n1/2 \u00afSn\nl (n\u22121Tn\nl (nt)) \u2212 \u02dcS\nn\nl (n\u22121Tn\nl (nt)) + on(1)\n= n1/2 \u00afAl(t) + \u02dcAl(t) \u2212 n1/2 \u00afSl(n\u22121Tn\nl (nt)) \u2212 \u02dcSl(n\u22121Tn\nl (nt)) + on(1)\n= n1/2\u03bblt \u2212 n\u22121/2\u00b5lTn\nl (nt) + \u02dcAl(t) \u2212 \u02dcSl(n\u22121Tn\nl (nt)) + on(1),\n(D.3)\nwhere we used Nn\nl (nt) = An\nl (nt) \u2212 Sn\nl (Tn\nl (nt)), n1/2( \u00afAn\nl \u2212 \u00afAl) = on(1), n1/2( \u00afSn\nl \u2212 \u00afSl) = on(1)\nfrom Assumption B, and boundedness of n\u22121Tn\nl (n\u00b7) (B.13). Noting \u02dcan\nl (t) = \u03bb\u22121\nl \u02dcN\nn\nl (t) + on(1) by\nProposition 12, we have the desired result.\nAsymptotic Pc\u00b5 index For any predicted class l \u2208 [K] and t \u2208 [0, 1], the P c\u00b5 index and its\nasymptotic counterpart is\nIn\nl (t) := \u00b5n\nl \u00b7 n1/2(Cn\nl )\u2032(an\nl (nt)), \u00afIn\nl (t) := \u00b5l \u00b7 C\u2032\nl(\u02dcan\nl (t)) (D.4)\nTheir difference can be bounded by\n|\u00afIn\nl (t) \u2212 In\nl (t)| \u2264C\u2032\nl(\u02dcan\nl (t)) \u00b7 |\u00b5n\nl \u2212 \u00b5l| + \u00b5n\nl \u00b7 |n1/2(Cn\nl )\u2032(n1/2\u02dcan\nl (t)) \u2212 C\u2032\nl(\u02dcan\nl (t))|.\nNote that lim supn \u00b5n\nl < +\u221e from n1/2(\u00b5n\nl \u2212 \u00b5l) \u2192 0 (Assumption B), lim supn \u2225C\u2032\nl(\u02dcan\nl (\u00b7))\u2225 < +\u221e\nsince C\u2032\nl is continuous, and lim supn \u2225\u02dcan\nl \u2225 < +\u221e by Proposition 12. Since n1/2(Cn\nl )\u2032(n1/2\u00b7) \u2192 C\u2032\nl\nby Assumption C, we can conclude sup t\u2208[0,1] |\u00afIn\nl (t) \u2212 In\nl (t)| = on(1).\nLemma 21. There exists N(\u03b5) > 0 such that for any n \u2265 N(\u03b5),\nmax\nl\u2208[K]\nsup\nt\u2208[0,1]\n\f\f\u00afIn\nl (t) \u2212 In\nl (t)\n\f\f \u2264 min\nn \u03b5\n16, m\u03b20\n4 \u03b41(\u03b5)\no\n.\nBounding the difference between Pc\u00b5 indices When the difference of the scaled ages{\u02dcan\nl }l\u2208[K]\nis bounded, we demonstrate bounded differences of the indices over sufficiently small intervals.\nLemma 22 (Pc\u00b5 index: Continuity I). There exists N(\u03b5) > 0 such that for any n \u2265 N(\u03b5), l \u2208 [K],\nand 0 \u2264 t1 < t2 \u2264 1,\n(i) if \u02dcan\nl (t2) \u2212 \u02dcan\nl (t1) \u2264 \u03b41(\u03b5), then In\nl (t2) \u2212 In\nl (t1) \u2264 \u03b5\n4;\n(ii) if \u02dcan\nl (t2) \u2212 \u02dcan\nl (t1) \u2265 0, then In\nl (t2) \u2212 In\nl (t1) \u2265 max{\u2212\u03b5\n4, \u2212m\u03b20\u03b41(\u03b5)}.\nProof By Lemma 21, it suffices to show \u00afIn\nl (t2) \u2212 \u00afIn\nl (t1) \u2264 \u03b5/8 for (i) and \u00afIn\nl (t2) \u2212 \u00afIn\nl (t1) \u2265 0\nfor (ii). Noting C\u2032\nl is non-decreasing, we have\n\u00afIn\nl (t2) \u2212 \u00afIn\nl (t1) = \u00b5l[C\u2032\nl(\u02dcan\nl (t2)) \u2212 C\u2032\nl(\u02dcan\nl (t1))] \u2264 \u00b5l[C\u2032\nl(\u02dcan\nl (t1) + \u03b41(\u03b5)) \u2212 C\u2032\nl(\u02dcan\nl (t1))]\n60\n\nwhich yields (i) by continuity of C\u2032\nl from Lemma 18. For (ii), non-decreasing C\u2032\nl again implies\n\u00afIn\nl (t2) \u2212 \u00afIn\nl (t1) = \u00b5l[C\u2032\nl(\u02dcan\nl (t2)) \u2212 C\u2032\nl(\u02dcan\nl (t1))] \u2265 0.\nNext, we bound the differences when the age process has a negative jump due to a job\u2019s departure\nfollowing service completion.\nLemma 23 (Size of a negative jump of P c\u00b5 index). There exists N(\u03b5) > 0 such that for n \u2265 N(\u03b5)\nsup\nt\u2208[0,1]\n|In\nl (t\u2212) \u2212 In\nl (t)| \u2264min\nn\u03b5\n4, m\u03b20\u03b41(\u03b5)\no\n.\nProof By Lemma 21, it suffices to show \u00afIn\nl (t\u2212)\u2212 \u00afIn\nl (t) \u2264 min{\u03b5\n8, m\u03b20\n2 \u03b41(\u03b5)}. \u02dcan\nl (t) \u0338= \u02dcan\nl (t\u2212) only\narises when a job from the predicted class l completes service and leaves the system at time t. By\ndefinition, the age process will incur a negative jump that corresponds to the interarrival time of\ntwo consecutive jobs. It follows from Proposition 6 that\n|\u02dcan\nl (t) \u2212 \u02dcan\nl (t\u2212)| \u2264n\u22121/2 sup\n1\u2264i\u2264An\nl (n)\nun\nli \u2264 min{\u03b41(\u03b5), \u03b42(\u03b5)}.\nfor all sufficently large n. Combining the above and continuity of C\u2032\nl from Lemma 18,\n|\u00afIn\nl (t) \u2212 \u00afIn\nl (t\u2212)| = \u00b5l|C\u2032\nl(\u02dcan\nl (t)) \u2212 C\u2032\nl(\u02dcan\nl (t\u2212))| \u2264min\nn\u03b5\n8, m\u03b20\n2 \u03b41(\u03b5)\no\n.\nD.2 Proof of Proposition 9\nWithout loss of generality, we fix \u03b5 > 0, n > N(\u03b5), and t1 \u2208 [0, 1 \u2212 \u03b4n\n1 (\u03b5)]. For simplicity, let\nt2 = t1 + \u03b4n\n1 (\u03b5). Choose any l1, l2 \u2208 [K]. By symmetry, it suffices to show that In\nl1(t2) \u2212I n\nl2(t2) < \u03b5.\nLet sn\n0 denote the largest (scaled) time point in [ t1, t2] at which the predicted class l2 is selected by\nPc\u00b5-rule\nsn\n0 := sup\n\u001a\nt | t \u2208 [t1, t2], In\nl2(t) = max\nl\u2208[K]\nIn\nl (t)\n\u001b\n.\nWe can obtain from the definition of P c\u00b5-rule that\nIn\nl1(t2) \u2212 In\nl2(t2) = [ In\nl1(t2) \u2212 In\nl1(sn\n0 )]| {z }\nby Lemmas 22 and 23, \u2264\u03b5/2\n+ [In\nl1(sn\n0 ) \u2212 In\nl2(sn\n0 )]| {z }\nby Pc\u00b5-rule, \u22640\n+ [In\nl2(sn\n0 ) \u2212 In\nl2(t2)]| {z }\nby Lemmas 22, \u2264\u03b5/2\n.\nThe second term satisfies In\nl1(sn\n0 ) \u2212 In\nl2(sn\n0 ) \u2264 0 since predicted class l2 is selected for service\nby Pc\u00b5-rule at time sn\n0 . The other two terms can be bounded by \u03b5/2 due to our selection of t2\nand continuity of P c\u00b5 index, as show in Lemmas 22 and 23. In particular, the first term can be\nbounded by\nIn\nl1(t2) \u2212 In\nl1(sn\n0 ) = [In\nl1(t2) \u2212 In\nl1((sn\n0 )\u2212)]| {z }\nby Lemma 22, \u2264\u03b5/4\n+ [In\nl1((sn\n0 )\u2212) \u2212 In\nl1(sn\n0 )]| {z }\nby Lemma 23, \u2264\u03b5/4\n\u2264 \u03b5/2,\nsince \u02dcan\nl1(t2) \u2212 \u02dcan\nl1(sn\n0 ) \u2264 n1/2(t2 \u2212 sn\n0 ) \u2264 \u03b41(\u03b5). Similarly, the third term satisfies\nIn\nl2(sn\n0 ) \u2212 In\nl2(t2) \u2264 \u03b5/2,\nby Lemma 23, since l2 is not served on the scaled interval [ sn\n0 , t2], and thus \u02dcan\nl2(t2) \u2212 \u02dcan\nl2(sn\n0 ) \u2265 0.\n61\n\nD.3 Proof of Proposition 10\nLet t2 = t1 + \u03b4n\n1 (\u03b5). By symmetry, it suffices to show In\nl1(sn\n1 ) \u2212 In\nl2(sn\n1 ) < \u03b5for l1, l2 \u2208 [K]. First,\nconsider the scenario (ii) where idling occurs in [ nt1, nt2], i.e., P\nl Tn\nl (nt2) \u2212 P\nl Tn\nl (nt1) < n\u03b4n\n1 (\u03b5).\nSince we only consider work conserving policies, idling implies that there is no job in queue at some\ntime nsn\n2 \u2208 [nt1, nt2]. Consequently, the age of all predicted classes is zero \u02dc an\nl (sn\n2 ) = 0, \u2200 l \u2208 [K].\nThen,\nIn\nl1(t2) \u2212 In\nl2(t2) = [In\nl1(t2) \u2212 In\nl1(sn\n2 )]| {z }\nby Lemma 22, \u2264\u03b5/2\n+ [In\nl1(sn\n2 ) \u2212 In\nl2(sn\n2 )]| {z }\nby definition, =0\n+ [In\nl2(sn\n2 ) \u2212 In\nl2(t2)]| {z }\nby \u02dcan\nl2 (sn\n2 ) = 0, \u22640\n\u2264 \u03b5,\nsince In\nl2(t2) \u2265 0.\nThe case (i) where no idling occurs is more complicated. We begin by showing that the age and\nthe Pc\u00b5 index decrease sufficiently. See Section D.3.1 for the proof of the following result.\nLemma 24 (Sufficient descent in age process) . For all t1 \u2208 [0, 1 \u2212 \u03b4n\n1 (\u03b5)], assume\n(i) (Non-Selected Class) at least one predicted class, say ln\n0 , is not selected by P c\u00b5-rule in time\ninterval [nt1, n(t1 + \u03b4n\n1 (\u03b5))];\n(ii) (No Idling) P\nl Tn\nl (n(t1 + \u03b4n\n1 (\u03b5))) \u2212 P\nl Tn\nl (nt1) = n\u03b4n\n1 (\u03b5).\nThere exists N(\u03b5) such that for all n > N(\u03b5), there is a predicted class kn\n0 whose age process\ndecreases sufficiently: \u02dcan\nkn\n0\n(t1 + \u03b4n\n1 (\u03b5)) \u2212 \u02dcan\nkn\n0\n(t1) \u2264 \u22122\u03b10\u03b41(\u03b5).\nLet kn\n0 be the predicted class with \u02dcan\nkn\n0\n(t2) \u2212\u02dcan\nkn\n0\n(t1) \u2264 \u22122\u03b10\u03b41(\u03b5). Let sn\n1 denote the smallest scaled\ntime in [t1, t2] at which \u02dcan\nkn\n0\nexperience such decrease\nsn\n1 := inf{t | t \u2208 [t1, t2], \u02dcan\nkn\n0\n(t) \u2212 \u02dcan\nkn\n0\n(t1) \u2264 \u22122\u03b10\u03b41(\u03b5)}.\nIf predicted class l2 is selected for service by P c\u00b5-rule in [ nt1, nsn\n1 ], we can show In\nl1(sn\n1 ) \u2212\nIn\nl2(sn\n1 ) \u2264 \u03b5 by a similar analysis as the proof of Proposition 9. The crux of our proof lies in\nthe scenario where l2 is not selected in [ nt1, nsn\n1 ]. At sn\n1 , \u02dcan\nkn\n0\nhas a negative jump by a service\ncompletion in predicted class kn\n0 and the Pc\u00b5 index decreases sufficiently.\nLemma 25 (Sufficient descent in P c\u00b5 index). For any 0 \u2264 t1 < t2 \u2264 1, assume there exists some\npredicted class kn\n0 satisfying \u02dcan\nkn\n0\n(t2) \u2212 \u02dcan\nkn\n0\n(t1) \u2264 \u22122\u03b10\u03b41(\u03b5). There exists N(\u03b5) > 0 such that for\nany n \u2265 N(\u03b5), the P c\u00b5 index for this predicted class decreases sufficiently\nIn\nkn\n0\n(t2) \u2212 In\nkn\n0\n(t1) \u2264 \u22123m\u03b20\u03b41(\u03b5).\nProof By Lemma 21, it suffices to show\n\u00afIn\nkn\n0\n(t2) \u2212 \u00afIn\nkn\n0\n(t1) = \u00b5kn\n0\n\u0010\nC\u2032\nkn\n0\n(\u02dcan\nkn\n0\n(t2)) \u2212 C\u2032\nkn\n0\n(\u02dcan\nkn\n0\n(t1))\n\u0011\n\u2264 \u22124m\u03b20\u03b41(\u03b5).\nSince Ckn\n0\nis strongly convex,\n[C\u2032\nkn\n0\n(\u02dcan\nkn\n0\n(t2)) \u2212 C\u2032\nkn\n0\n(\u02dcan\nkn\n0\n(t1))][\u02dcan\nkn\n0\n(t2) \u2212 \u02dcan\nkn\n0\n(t1)] \u2265 m[\u02dcan\nkn\n0\n(t2) \u2212 \u02dcan\nkn\n0\n(t1)]2.\nThen, \u02dcan\nkn\n0\n(t2) \u2212 \u02dcan\nkn\n0\n(t1) \u2264 \u22122\u03b10\u03b41(\u03b5) yields\nC\u2032\nkn\n0\n(\u02dcan\nl (t2)) \u2212 C\u2032\nkn\n0\n(\u02dcan\nl (t1)) \u2264 m[\u02dcan\nkn\n0\n(t2) \u2212 \u02dcan\nkn\n0\n(t1)] \u2264 \u22122m\u03b10\u03b41(\u03b5),\n62\n\nand\n\u00afIn\nkn\n0\n(t2) \u2212 \u00afIn\nkn\n0\n(t1) = \u00b5kn\n0\n[C\u2032\nkn\n0\n(\u02dcan\nkn\n0\n(t2)) \u2212 C\u2032\nkn\n0\n(\u02dcan\nkn\n0\n(t1))] \u2264 \u22122\u00b5minm\u03b10\u03b41(\u03b5) = \u22124m\u03b20\u03b41(\u03b5).\nBy Lemma 25, we have In\nkn\n0\n(sn\n1 ) \u2212 In\nkn\n0\n(t1) \u2264 \u22123m\u03b20\u03b41(\u03b5). Also, In\nl1((sn\n1 )\u2212) = In\nl1(sn\n1 ) because\npredicted class l1 is not served at sn\n1 . Consequently, there is no negative jump of the index and\nIn\nl1(sn\n1 ) = [ In\nl1(sn\n1 ) \u2212 In\nl1((sn\n1 )\u2212)]| {z }\nno negative jump at sn\n1 , =0\n+ [In\nl1((sn\n1 )\u2212) \u2212 In\nkn\n0\n((sn\n1 )\u2212)]\n| {z }\nby Pc\u00b5-rule, \u22640\n+ [In\nkn\n0\n((sn\n1 )\u2212) \u2212 In\nkn\n0\n(sn\n1 )]\n| {z }\nby Lemma 23, \u2264m\u03b20\u03b41(\u03b5)\n+ [In\nkn\n0\n(sn\n1 ) \u2212 In\nkn\n0\n(t1)]\n| {z }\n\u2264\u22123m\u03b20\u03b41(\u03b5)\n+In\nkn\n0\n(t1)\n\u2264 In\nkn\n0\n(t1) \u2212 m\u03b20\u03b41(\u03b5).\n(D.5)\nFor In\nl2(sn\n1 ), since l2 is NOT selected by the Pc\u00b5-rule in [nt1, nsn\n1 ], \u02dcan\nl2(sn\n1 )\u2212\u02dcan\nl2(t1) \u2265 0, which yields\nIn\nl2(sn\n1 ) \u2265 In\nl2(t1) \u2212 m\u03b20\u03b41(\u03b5) (D.6)\nby Lemma 22. By the condition in the proposition, subtracting (D.6) from (D.5) yields\nIn\nl1(sn\n1 ) \u2212 In\nl2(t2) \u2264 In\nkn\n0\n(t1) \u2212 In\nl2(t1) \u2264 \u03b5.\nTo show sn\n1 \u2265 t1 + \u03b30\u03b4n\n1 (\u03b5), recall from the choice of sn\n1 that\n\u02dcan\nkn\n0\n(sn\n1 ) \u2212 \u02dcan\nkn\n0\n(t1) \u2264 \u22122\u03b10\u03b41(\u03b5).\nThen, by Lemmas 19, 20, it is easy to verify that for sufficiently large n\nn(sn\n1 \u2212 t1) \u2265 Tn\nkn\n0\n(nsn\n1 ) \u2212 Tn\nkn\n0\n(nt1) \u2265 n1/2 \u00b7 \u03c1kn\n0\n[n1/2(sn\n1 \u2212 t1) + 2\u03b10\u03b41(\u03b5) \u2212 \u03b10\u03b41(\u03b5)]\n\u2265 n1/2 \u00b7 \u03c1min[n1/2(sn\n1 \u2212 t1) + \u03b10\u03b41(\u03b5)],\nwhere Tn\nkn\n0\n(nsn\n1 ) \u2212Tn\nkn\n0\n(nt1) \u2264 n(sn\n1 \u2212t1) follows from the definition of the policy process Tn\nkn\n0\n. This\nyields the desired result that sn\n1 \u2212 t1 \u2265 \u03b10\n1\u2212\u03c1min\n\u03b4n\n1 (\u03b5). Note that \u03b30 \u2208 (0, 1) because the critical load\ncondition P\nk \u03c1k = 1 in Assumption B implies that \u03c1min \u2264 1\nK and \u03c1max \u2265 1\nK .\nD.3.1 Proof of Lemma 24\nBy condition (i), it is clear that Tn\nln\n0\n(nt1 + n\u03b4n\n1 (\u03b5)) \u2212 Tn\nln\n0\n(nt1) = 0, since the predicted class ln\n0\nis not selected by P c\u00b5-rule in [ nt1, n(t1 + \u03b4n\n1 (\u03b5))]. Intuitively, the server is busy for serving other\npredicted classes, implying positive stochastic fluctuations of the policy processes dedicated to the\nother predicted classes, and there must be at least one predicted classes that absorbs the additional\nservice. In particular, we claim that there exists some predicted class kn\n0 such that\nTn\nkn\n0\n(n(t1 + n\u03b4n\n1 (\u03b5))) \u2212 Tn\nkn\n0\n(nt1) \u2265\n\u0010 \u03c1min\nK \u2212 1 + \u03c1kn\n0\n\u0011\n\u00b7 n\u03b4n\n1 (\u03b5). (D.7)\nFor simplicity, for all l \u2208 [K], let\n\u2206Tn\nl (nt1) := Tn\nl (n(t1 + n\u03b4n\n1 (\u03b5))) \u2212 Tn\nl (nt1), w n\nl := \u2206Tn\nl (nt1)/(n\u03b4n\n1 (\u03b5)),\n63\n\nwhere \u2206Tn\nl (nt1) represents the service time allocated to predicted class l during [nt1, n(t1 +\u03b4n\n1 (\u03b5))],\nand wn\nl denotes its proportion in the time interval. According to conditions (i) and (ii) and\nAssumption B, it is easy to verify that\nX\nl\u0338=ln\n0\nwn\nl = 1,\nX\nl\u0338=ln\n0\n\u03c1l = 1 \u2212 \u03c1ln\n0\n\u2264 1 \u2212 \u03c1min.\nRearranging the terms, we can claim that there exists some predicted classkn\n0 satisfying wn\nkn\n0\n\u2212\u03c1kn\n0\n\u2265\n\u03c1min\nK\u22121, which is equivalent to (D.7).\nCombining (D.7) and Lemmas 19, 20, for sufficient large n\n\u02dcan\nkn\n0\n(t1 + \u03b4n\n1 (\u03b5)) \u2212 \u02dcan\nkn\n0\n(t1) = n1/2\u03b4n\n1 (\u03b5) \u2212 n\u22121/2\u03c1\u22121\nkn\n0\n\u2206Tn\nkn\n0\n(nt) + \u03b10\u03b41(\u03b5)\n\u2264 \u03b41(\u03b5) \u2212 \u03c1\u22121\nkn\n0\n\u0010 \u03c1min\nK \u2212 1 + \u03c1kn\n0\n\u0011\n\u00b7 \u03b41(\u03b5) + \u03b10\u03b41(\u03b5)\n\u2264 \u22123\u03b10\u03b41(\u03b5) + \u03b10\u03b41(\u03b5) = \u22122\u03b10\u03b41(\u03b5).\nD.4 Proof of Proposition 11\nFix t2 \u2208 [t1, (t1 + \u03b4n\n1 (\u03b5)) \u2227 1]. By symmetry, it suffices to show In\nl1(t2) \u2212 In\nl2(t2) < 3\u03b5/2 for any\nl1, l2 \u2208 [K]. When l2 is selected for service by Pc\u00b5-rule in [nt1, nt2], we can employ a similar analysis\nas in the proof of Proposition 9 to show In\nl1(t2) \u2212 In\nl2(t2) < \u03b5. For the other case, we have from\nLemma 22 that In\nl2(t2)\u2212I n\nl2(t1) \u2265 \u2212\u03b5/4, since \u02dcan\nl2(t2)\u2212\u02dcan\nl2(t1) \u2265 0. Also, once again by Lemma 22,\none can check In\nl1(t2) \u2212 In\nl1(t1) \u2264 \u03b5/4 since t2 \u2212 t1 \u2264 \u03b4n\n1 (\u03b5). Combining equations above yields the\ndesired result.\nE Proof of Theorem 3\nE.1 Overview of the proof\nOur goal is to show condition (4.3), from which Lemma 1 will imply Theorem 3.\nRelationships between (\u02dc\u03c4n\nl , \u02dcN\nn\nl , \u02dcT\nn\nl , \u02dcW\nn\nl ) and \u02dcan\nl Since the P c\u00b5-rule uses observable ages, we\nneed to connect \u02dcan\nl and the endogenous processes (\u02dc \u03c4n\nl , \u02dcN\nn\nl , \u02dcT\nn\nl , \u02dcW\nn\nl ), \u2200 l \u2208 [K]. We prove the\nequivalence between the original KKT conditions (4.3) and the modified version for age (4.4),\nprovided that either \u02dc\u03c4n\nl \u2192 \u02dc\u03c4l or \u02dcan\nl \u2192 \u02dcal. For predicted class l \u2208 [K], \u03bbl is the limiting arrival rate\n(see Definition 10).\nProposition 12 (Relationship between \u02dcan\nl and \u02dc\u03c4n\nl ). Given a classifier f\u03b8 and a sequence of queueing\nsystems, suppose that Assumptions A, B, and H hold. Under p-FCFS feasible policies, for any\npredicted class l \u2208 [K], (i) \u03bbl\u02dcan\nl \u2212 \u02dcN\nn\nl \u2192 0, (ii) maxl\u2208[K] lim supn \u2225\u02dcan\nl \u2225 < \u221e; (iii) {\u02dcan\nl }n converges iff\n{\u02dc\u03c4n\nl }n converges; (iv) their limits coincide: if there exist \u02dcal, \u02dc\u03c4l \u2208 Csuch that \u02dcan\nl \u2192 \u02dcal and \u02dc\u03c4n\nl \u2192 \u02dc\u03c4l,\nthen \u02dcal = \u02dc\u03c4l.\nThe proof of Proposition 12 requires the arrival rates of the predicted classes to converge to{\u03bbl}l\u2208[K]\nat rate o(n\u22121/2), for which the conditions in Assumption B are essential. We also characterize\nthe relationship between \u02dcan\nl and the policy process \u02dcT\nn\nl in Corollary 20, which allows for directly\nanalyzing the dynamics of the age process \u02dcan\nl .\n64\n\nConvergence of the P c\u00b5 indices and the scaled age processes Since the P c\u00b5-rule serves\nthe job that has the highest index value, the gap between the class indices becomes small and the\nconvergence (4.4) holds.\nProposition 13 (Convergence of max difference of the Pc\u00b5 indices). Given a classifier f\u03b8, suppose\nthat Assumptions A, B, C, D, and H hold. Under the P c\u00b5-rule,\nsup\nt\u2208[0,1]\nmax\nl,m\u2208[K]\n\f\fIn\nl (t) \u2212 In\nm(t)\n\f\f \u2192 0. (E.1)\nBy the continuity of the inverse cost function (C\u2032\nl)\u22121, convergence of {\u02dcan\nl }l\u2208[K] follows (Lemma 26)\nand we have the desired final result.\nWe prove Proposition 13 in Section D. Specifically, we partition [0 , 1], the domain of the\ndiffusion-scaled processes, into intervals of size O(n\u22121/2) and show that max l,m\u2208[K] |In\nl (t) \u2212 In\nm(t)|\ndo not exhibit substantial growth within each interval if its size is chosen carefully. The main\ntechnical challenge is to demonstrate that such growth do not accumulate over time. Since\nmaxl,m\u2208[K] |In\nl (0) \u2212 In\nm(0)| = 0, we proceed via induction: for a fixed \u03b5 >0, we show that\n(i) at each endpoint t of every interval, maxl,m\u2208[K] |In\nl (t) \u2212 In\nm(t)| \u2264\u03b5 (Propositions 9 and 10);\n(ii) within each interval I, supt\u2208I maxl,m\u2208[K] |In\nl (t) \u2212 In\nm(t)| \u22643\u03b5/2 (Proposition 11).\nWe outline the proof for part (i) (part (ii) can be shown similarly). Given an interval [ t1, t2],\nBy symmetry it suffices to show In\nl (t2) \u2212 In\nm(t2) \u2264 \u03b5 for any l, m\u2208 [K]. First, for the case that\npredicted class m is selected by the P c\u00b5-rule at some time ns \u2208 [nt1, nt2], we use definition of the\nPc\u00b5-rule to bound such growth. In particular,\nIn\nl (t2) \u2212 In\nm(t2) \u2264 [In\nl (t2) \u2212 In\nl (s)]| {z }\nbounded increase, \u2264\u03b5/2\n+ [In\nl (s) \u2212 In\nm(s)]| {z }\nby the Pc\u00b5-rule, \u2264 0\n+ [ In\nm(s) \u2212 In\nm(t2)]| {z }\nbounded increase, \u2264\u03b5/2\n, (E.2)\nwhere the first and the last term are bounded by \u03b5/2 due to our choice of t2 \u2212 t1 = O(n\u22121/2) and\nthe smoothness of the cost functions in Assumption C, and the second term is non-positive since\npredicted class m is chosen by the P c\u00b5-rule at time ns.\nFor the other case that predicted class m is never selected by the P c\u00b5-rule during the interval\n[nt1, nt2], the analysis is more involved and requires development of novel analysis techniques. If the\nserver is idling at some ns \u2208 [nt1, nt2], our analysis is similar to (E.2) and the second term becomes\nzero since the P c\u00b5-rule is work-conserving. Otherwise, if there is no idling during [ nt1, nt2], then\nintuitively, the server is busy serving other K \u2212 1 predicted classes. By heavy traffic assumptionP\nl \u03c1l = 1 (Assumption B), there exists at least one predicted classkn\n0 that receives sufficient service\nfrom the server (See (D.7)) and incurs sufficient descent in the age process (Lemma 24) in [nt1, nt2].\nThen, by strong convexity of the Pc\u00b5 cost Ckn\n0\n(Assumption D), the Pc\u00b5 index of class kn\n0 , say In\nkn\n0\n,\nalso incurs sufficient descent (Lemma 25). Such descent in the Pc \u00b5 index enables us to bound the\ngrowth of In\nl and derive the desired result in Proposition 10.\nE.2 Comparison to the optimality result in Van Mieghem [63]\nPlugging Qn = I, our proof gives the optimality of the well-known Gc\u00b5-rule where true class labels\nare known [63]. In this special case, our analysis identifies missing arguments in Van Mieghem [63]\u2019s\noriginal proof and provides conditions under which his original claims hold. For example, we require\n65\n\narrival rates to converge at rate o(n\u22121/2), and use Assumption B on \u03bbn, pn\nk and qn\nkl, \u2200k, l\u2208 [K]\naccordingly. We find that the same convergence rate should have been assumed on the analogous\nprocess, \u00afAn\nk in Van Mieghem [63], in order to correctly connect the age and sojourn time processes.\nThe first missing piece is that the G c\u00b5-rule uses the ages of waiting jobs for scheduling,\nbut Van Mieghem [63] does not prove the Gc\u00b5-rule achieves optimality conditions defined in terms\nof the sojourn times [63, Eq (54)]. We show that scaled sojourn time processes converge to a\nlimit satisfying the optimality condition under the G c\u00b5-rule using Proposition 13, and thus con-\ndition (4.3) (extension of Van Mieghem [63, Eq (54)]) is satisfied. This missing justification was\nnontrivial (to us), and we hope our rigorous arguments provide analytical value to subsequent\nworks.\nSecond, we found the proof of Proposition 13 to be nontrivial. Our analysis of the index dy-\nnamics with the particular choice of the partition size of the time horizon entails carefully handling\nerrors of diffusion approximations for predicted classes (Proposition 1 and 6). We control the evo-\nlution of {\u02dcan\nl }l\u2208[K] under the P c\u00b5-rule, which requires formally establishing relationships between\n\u02dcan\nl , \u02dc\u03c4n\nl , and \u02dcT\nn\nl .\nIn particular, our proof of Proposition 13 identifies a previously unstated necessary condition:\nstrong convexity of the cost functions in Assumption D. The curvature ensures that if some predicted\nclass is not served and its index increases in a subinterval of the partition, then there is another\npredicted class kn\n0 that receives ample service so that the index In\nkn\n0\ndecreases enough (Lemma 25),\nimplying that the gap between the indices remains small. On the other hand, under the strict\nconvexity Van Mieghem [63] assumes, we were unable to show the desired convergence he claims\n(either [63, Eq (54)] or a more general version in Proposition 13).\nE.3 Comparison to the optimality result in Mandelbaum and Stolyar [40]\nSimilarly as in Van Mieghem [63], our analysis with perfect classification ( Qn = I) also identifies\nmissing pieces in the optimality proof by Mandelbaum and Stolyar [40] for the G c\u00b5-rule with\nsojourn time cost (called D-Gc\u00b5 in [40]) in single-server systems and provides conditions for the\nclaims to hold.\nFirst, similarly to [63], although Mandelbaum and Stolyar [40] suggests using age processes\nfor the D-Gc\u00b5 rule, they did not prove that their D-Gc\u00b5 rule satisfies optimality conditions they\nadopted, which are based on sojourn time processes and identical to (4.3) in the single-server case.\nSpecifically, we find that [40, Eq (66)] that connects D-Gc\u00b5 to the preceding analysis in [40] should\nhave been shown in terms of the queue length and age processes similarly to Proposition 12 (i).\nUsing an equivalence between the age and sojourn time processes analogous to Proposition 12 (iii)\nand (iv), the optimality of D-Gc\u00b5 could be obtained. Accordingly, the (faster) convergence rate of\no(n\u22121/2) on the arrival rates as in Assumption B would be also required in [40].\nOur analysis shows the optimality of the D-Gc\u00b5 in the single-server case requires weaker as-\nsumptions on cost functions than those adopted in Mandelbaum and Stolyar [40]. The optimality\nin [40, Theorem 2] is built on the attraction propery of the fluid-scaled queue length limit [40,\nTheorem 3]. In the single-server case, the key implications of the attraction property are the small\ngaps between the class indices over subintervals [40, Eqs. (55), (56)], which are analogous to Propo-\nsitions 9, 10, and 11. Mandelbaum and Stolyar [40, Theorem 3] require the cost functions to be\ntwice continuously differentiable (and strongly convex) in order for the workload and queue length\nlimits to be amenable to analysis in the multi-server setting. In contrast, our analysis directly\n66\n\nidentifies the dynamics of the age processes under the D-Gc\u00b5 in the single-server case, and prove\nthe counterpart propositions under the weaker conditions, namely Assumptions C and D.\nE.4 Detailed proof of Theorem 3\nWe begin by showing the convergence of the age process, whose proof we give in Section E.5.\nLemma 26 (Convergence of \u02dcan). Given a classifier f\u03b8, suppose that Assumptions A, B, C, D,\nand H hold. Under the P c\u00b5-rule, there exists \u02dca \u2208 CK such that \u02dcan \u2192 \u02dca in (DK, \u2225 \u00b7 \u2225) Pcopy-a.s..\nFrom the above lemma and Proposition 1, the relation between \u02dcan\nl and \u02dc\u03c4n\nl in Proposition 12 implies\nconvergence of \u02dc\u03c4n\nl \u2192 \u02dc\u03c4l, \u02dcan\nl \u2192 \u02dcal, \u02dcN\nn\nl \u2192 \u02dcNl, \u02dcT\nn\nl \u2192 \u02dcTl, and \u02dcW\nn\nl \u2192 \u02dcWl.\nIf \u02dc\u03c4l, \u02dcal \u2208 C, Proposition 12 implies \u02dc\u03c4l = \u02dcal. Since \u02dcal \u2208 Cby Lemma 26, it is easy to verify\n\u02dcNl, \u02dcTl, \u02dcWl \u2208 Cfrom the relation between \u02dcal and \u02dcNl in Proposition 12, relation (B.14) between \u02dcNl\nand \u02dcTl, and relation (B.10) between \u02dcTl and \u02dcWl. Using the relation (B.15) between \u02dc\u03c4l, \u02dcWl, and \u02dcTl,\none can check that \u02dc\u03c4l \u2208 C.\nBy Lemma 16 and Proposition 8, we have \u02dc\u03c4l = \u02dcWl/\u03c1l, \u2200 l \u2208 [K]. Proposition 13 then implies\n\u02dc\u03c4l = \u02dcWl/\u03c1l, \u2200 l \u2208 [K],\nX\nl\u2208[K]\n\u02dcWl = \u02dcW+, \u00b5 lC\u2032\nl(\u02dc\u03c4l) = \u00b5mC\u2032\nm(\u02dc\u03c4m), \u2200 l, m\u2208 [K]. (E.3)\nBy Proposition 15, it follows \u03c1l\u02dc\u03c4l = [ h( \u02dcW+)]l, \u2200 l \u2208 [K]. This yields \u02dcJn\nPc\u00b5(\u00b7; Qn) \u2192 \u02dcJ\u2217(\u00b7; Q)\nPcopy-a.s. according to Theorem 2 and Lemma 1.\nThe weak convergence on the original systems\u02dcJn\nPc\u00b5(\u00b7; Qn) \u21d2 \u02dcJ\u2217(\u00b7; Q) in (D, \u2225\u00b7\u2225) follows from [31,\nLemma 3.2, Lemma 3.7]. Moreover, for any x \u2208 R, t \u2208 [0, 1], by reverse Fatou\u2019s lemma and the\nPcopy-a.s. convergence of \u02dcJn\nPc\u00b5(\u00b7; Qn), we have\nlim sup\nn\nPn[ \u02dcJn\nPc\u00b5(t; Qn) > x] \u2264EPcopy[lim sup\nn\nI{ \u02dcJn\nPc\u00b5(t; Qn) > x}]\n=EPcopy[I{ \u02dcJ\u2217(t; Qn) > x}]\n=Pcopy[ \u02dcJ\u2217(t; Q) > x].\nCombining this with lim inf n Pn[ \u02dcJn\nPc\u00b5(t; Qn) > x] \u2265 Pcopy[ \u02dcJ\u2217(t; Q) > x] from Theorem 2 gives the\ndesired result: Pn[ \u02dcJn\nPc\u00b5(t; Qn) > x] \u2192 Pcopy[ \u02dcJ\u2217(t; Q) > x].\nE.5 Proof of Lemma 26\nBy Proposition 13 and Lemma 21, the P c\u00b5-rule gives max l,s\u2208[K] \u2225\u00b5lC\u2032\nl(\u02dcan\nl ) \u2212 \u00b5sC\u2032\nl(\u02dcan\ns )\u2225 \u21920.\nGiven s \u2208 [K], for any l \u2208 [K], since \u00b5l > 0 by Assumption A and Definition 10, we have\nC\u2032\nl(\u02dcan\nl )\u2212\n\u00b5s\n\u00b5l\nC\u2032\ns(\u02dcan\ns ) \u2192 0. Letting fs(\u00b7) := PK\nl=1 \u03c1l\u00b7(C\u2032\nl)\u22121\u0000\u00b5s\n\u00b5l\nC\u2032\ns(\u00b7)\n\u0001\n, note that PK\nl=1 \u03c1l\u02dcan\nl \u2212\n\u0000\nfs\u25e6\u02dcan\ns\n\u0001\n\u2192\n0 from continuity of (C\u2032\nl)\u22121 (Assumption C). Under p-FCFS feasible policies, Lemma 16 and Propo-\nsition 12 implies \u02dcW\nn\nl \u2212 \u03c1l\u02dcan\nl \u2192 0. Applying Proposition 1, there exists \u02dcW+ \u2208 C([0, 1], R) such thatPK\nl=1 \u03c1l\u02dcan\nl \u2192 \u02dcW+. Hence, fs \u25e6 \u02dcan\ns \u2192 \u02dcW+.\nSince fs is continuous and strictly increasing, f\u22121\ns is well-defined and also continuous. Conclude\n(f\u22121\ns , fs \u25e6 \u02dcan\ns ) \u2192 (f\u22121\ns , \u02dcW+) in C2 under the product topology induced by \u2225 \u00b7 \u2225. By the continuity of\ncomposition (e.g., [68, Theorem 13.2.1]), \u02dcan\ns = f\u22121\ns \u25e6\n\u0000\nfs \u25e6 \u02dcan\ns\n\u0001\n\u2192 \u02dcas := f\u22121\ns \u25e6 \u02dcW+ where \u02dcas \u2208 Cby\ncontinuity of f\u22121\ns and \u02dcW+. This completes our proof.\n67\n\nE.6 Proof of Proposition 12\nWe show the asymptotically linear relationship (i) between \u02dcan\nl and \u02dcN\nn\nl . Other results immediately\nfollow from (i) and Propositions 1 and Proposition 8. We use a reformulation of the age process.\nClaim 27.\nan\nl (nt) = nt \u2212 Un\nl (An\nl (nt) \u2212 Nn\nl (nt) + 1) +on(n1/2). (E.4)\nSince Un\nl (nt) = n \u00afUn\nl (t) + n1/2 \u02dcU\nn\nl (t) + on(n1/2) by Proposition 6, we can further rewrite (E.4) as\n\u02dcan\nl (t) = n1/2[t \u2212 \u00afUn\nl (n\u22121(An\nl (nt) \u2212 Nn\nl (nt) + 1))]\u2212 \u02dcU\nn\nl (n\u22121(An\nl (nt) \u2212 Nn\nl (nt) + 1)) +on(1).\nRecall An\nl (nt) = n \u00afAn\nl (t) +n1/2 \u02dcA\nn\nl (t) +on(n1/2) by Proposition 6, \u02dcN\nn\nkl := n\u22121\n2 Nn\nkl by Definition 11,\nand lim supn \u2225 \u02dcN\nn\nkl\u2225 \u2264lim supn \u2225 \u02dcN\nn\nl \u2225 < +\u221e by Proposition 1. Evidently,\nn\u22121(An\nl (nt) \u2212 Nn\nl (nt) + 1) = \u00afAn\nl (t) + n\u22121/2 \u02dcA\nn\nl (t) \u2212 n\u22121/2 \u02dcN\nn\nk(t) + on(n\u22121/2)\n= \u00afAl(t) + n\u22121/2 \u02dcAl(t) \u2212 n\u22121/2 \u02dcN\nn\nk(t) + on(n\u22121/2) = \u00afAl(t) + on(1),\n\u02dcU\nn\nl (n\u22121(An\nl (nt) \u2212 Nn\nl (nt) + 1))\n(a)\n= \u02dcUl( \u00afAl(t) + on(1)) + on(1)\n(b)\n= \u2212 \u03bb\u22121\nl \u02dcAl(t + on(1)) + on(1)\n(c)\n= \u2212\u03bb\u22121\nl \u02dcAl(t) + on(1)\nwhere we used \u02dcU\nn\nl \u2192 \u02dcUl by Proposition 6 in step (a), \u02dcUl(t) = \u2212\u03bb\u22121\nl \u02dcAl(\u03bb\u22121\nl t) by the proof of\nProposition 6 in step (b), and the uniform continuity of \u02dcAl on compact intervals in step (c). Since\nn1/2( \u00afUn\nl \u2212 \u00afUl) = on(1) by Assumption B, and \u00afAl(t) = \u03bblt, \u00afUl(t) = \u03bb\u22121\nl t by Proposition 6\nn1/2[t \u2212 \u00afUn\nl (n\u22121(An\nl (nt) \u2212 Nn\nl (nt) + 1))] = n1/2t \u2212 n1/2 \u00afUl(n\u22121(An\nl (nt) \u2212 Nn\nl (nt) + 1)) +on(1)\n= \u2212 \u03bb\u22121\nl [ \u02dcAl(t) \u2212 \u02dcN\nn\nl (t)] + on(1).\nCollecting previous derivations, we have the desired result.\nProof of claim For fixed t \u2208 [0, 1], we first consider the case that An\nl (nt) = 0. Since there is no\narrival to the predicted class l at time nt, it is easy to verify that an\nl (nt) = 0, Nn\nl (nt) = 0, and\nnt \u2264 ul1. Therefore, we obtain that\n\f\f\fan\nl (nt) \u2212 [nt \u2212 Un\nl (An\nl (nt) \u2212 Nn\nl (nt) + 1)]\n\f\f\f = |0 \u2212 [nt \u2212 Un\nl (1)]| \u2264 |ul1| = on(n1/2),\nwhere the last equality follows from Propositon 6. When An\nl (nt) \u2265 1, An\nl (nt)\u2212Nn\nl (nt) jobs from the\npredicted class l have completed service and exited the queue. Under a p-FCFS policy, the oldest\ncustomer from the predicted class l at time nt corresponds to the [An\nl (nt)\u2212Nn\nl (nt)+1]th arrival of\npredicted class l. From the definition of an\nl (nt) as the time difference betweennt and the arrival time\nof the oldest job in predicted class l, the exact formulation an\nl (nt) = nt \u2212Un\nl (An\nl (nt) \u2212Nn\nl (nt) + 1)\nfollows. This completes our proof of (E.4).\nF Proofs for Section 6\nF.1 Proof for Proposition 4\nFrom Theorem 2, \u02dcJ\u2217(t; Q) =\nRt\n0\nPK\nl=1\nPK\nk=1 \u03bbpkqklCk(\u02dc\u03c4l(s))ds where {\u02dc\u03c4l}l\u2208[K] is characterized by\n\u02dc\u03c4l = \u02dcWl/\u03c1l, \u2200 l \u2208 [K],\nX\nl\n\u02dcWl = \u02dcW+, \u00b5 lC\u2032\nl(\u02dc\u03c4l) = \u00b5mC\u2032\nm(\u02dc\u03c4m), \u2200 l, m\u2208 [K]. (F.1)\n68\n\nAccording to Assumption E, we can equivalently reformulate (F.1) as\n\u03c1l\u02dc\u03c4l(t; Q) = (\u03b2l(Q))\u22121\nPK\nm=1(\u03b2m(Q))\u22121\n\u02dcW+(t), \u03b2 l(Q) =\n\u00b5lcl\n\u03c1l\n, \u2200 t \u2208 [0, 1], \u2200 l \u2208 [K].\nFor any s \u2208 [0, t], the integrand PK\nl=1\nPK\nk=1 \u03bbpkqklCk(\u02dc\u03c4l(s)) can be written as\nKX\nl=1\nKX\nk=1\n\u03bbpkqkl\nck\n2\n1\n\u03c12\nl\n\u0010 \u02dcW+(s)\nPK\nm=1\n\u03b2l(Q)\n\u03b2m(Q)\n\u00112\n= 1\n2\n\u02dcW2\n+(s)\nKX\nl=1\n1\n\u03c12\nl\n\u0010 1\nPK\nm=1\n\u03b2l(Q)\n\u03b2m(Q)\n\u00112 KX\nk=1\n\u03bbpkqklck\n= 1\n2\n\u02dcW2\n+(s)\nKX\nl=1\n\u03b2l(Q)\u0000PK\nm=1\n\u03b2l(Q)\n\u03b2m(Q)\n\u00012 ,\nwhere the last equality holds since \u03b2l(Q) = \u00b5lcl/\u03c1l, cl =\nP\u03bbpkqklckP\u03bbpkqkl\nby definition. The summation\nterm can be further written as\nKX\nl=1\n\u03b2l(Q)\u0000PK\nm=1\n\u03b2l(Q)\n\u03b2m(Q)\n\u00012 =\nKX\nl=1\n\u03b2l(Q)\n\u0000Q\nr\u0338=l \u03b2r(Q)\n\u00012\n\u0000PK\nm=1\n\u03b2l(Q)\n\u03b2m(Q)\n\u00012\u0000Q\nr\u0338=l \u03b2r(Q)\n\u00012\n=\nKX\nl=1\n\u03b2l(Q)\n\u0000Q\nr\u0338=l \u03b2r(Q)\n\u00012\n\u0000PK\nm=1\nQ\nr\u0338=m \u03b2m(Q)\n\u00012 =\nQK\nr=1 \u03b2r(Q)PK\nm=1\nQ\nr\u0338=m \u03b2r(Q)\n= 1PK\nm=1(\u03b2m(Q))\u22121 .\nBy a similar approach to the proof of Lemma 26, the age process converges under the Naive\nGc\u00b5-rule, and by Lemma 1, the cumulative cost converges to\n\u02dcJNaive(t; Q) =\nKX\nl=1\nKX\nk=1\nZ t\n0\n\u03bbpkqklCk(\u02dc\u03c4l,Naive(s))ds,\nwhere {\u02dc\u03c4l,Naive}l\u2208[K] is the limit of the sojourn time process under the Naive G c\u00b5-rule. By similar\nanalysis as in the proof of Theorem 3, the limit {\u02dc\u03c4l,Naive}l\u2208[K] is characterized by\n\u02dc\u03c4l,Naive = \u02dcWl/\u03c1l, \u2200 l \u2208 [K],\nX\nl\n\u02dcWl = \u02dcW+, \u00b5 lC\u2032\nl(\u02dc\u03c4l) = \u00b5mC\u2032\nm(\u02dc\u03c4m), \u2200 l, m\u2208 [K].\nIn contrast with Eq. (E.3), each predicted class l \u2208 [K] is associated with the original cost function\nCl in the above characterization, which does not take into account misclassification errors in the\nmarginal cost rate of the class. It follows that\n\u03c1l\u02dc\u03c4l,Naive(t; Q) = (\u03b2l,Naive(Q))\u22121\nPK\nm=1(\u03b2m,Naive(Q))\u22121\n\u02dcW+(t), \u03b2 l,Naive(Q) =\n\u00b5lcl\n\u03c1l\n, \u2200 l \u2208 [K].\nCombining the equations above and noting \u03b2l(Q) = \u00b5lcl/\u03c1l, we have\n\u02dcJNaive(t; Q) =\nKX\nl=1\nKX\nk=1\nZ t\n0\n\u03bbpkqkl\nck\n2\u03c12\nl\n\u02dcW2\n+(s)\n\u0010 (\u03b2l,Naive(Q))\u22121\nPK\nm=1(\u03b2m,Naive(Q))\u22121\n\u00112\nds\n=\nKX\nl=1\n\u03b2l(Q)\n\u0000P\nm\n\u03b2l,Naive(Q)\n\u03b2m,Naive(Q)\n\u00012 \u00b7 1\n2\nZ t\n0\n\u02dcW2\n+(s)ds.\n(F.2)\n69\n\nG Proof of results in Section 7\nG.1 Joint convergence of the AI-based triage system\nWe define the concerned processes below to analyze the AI triage system.\nDefinition 12 (Arrival processes of the AI-based triage system) . Given a classifier f\u03b8, filtering\nlevel zFL, the number of hired reviewers \u0393(zFL), and a sequence of queueing systems, suppose that\nAssumptions F and G hold. We define the following for any system n, reviewer r \u2208 \u0393(zFL), and\ntime t \u2208 [0, n]:\n(i) (Arrival process of the triage system) Let Un\n0 (t) := P\u230at\u230b\ni=1 un\ni be the partial sum of interarrival\ntimes among the first \u230at\u230b jobs arriving at the triage system, and An\n0 (t) be the number of jobs\nthat arrive at the triage system n up to time t. Moreover, let \u02dcUn\n0 (t), \u02dcAn\n0 (t) be the corresponding\ndiffusion-scaled process, defined as\n\u02dcUn\n0 (t) = n\u22121/2[Un\n0 (nt) \u2212 \u039b\u22121\nn \u00b7 nt], \u02dcAn\n0 (t) = n\u22121/2[An\n0 (nt) \u2212 \u039bn \u00b7 nt], \u2200 t \u2208 [0, 1];\n(ii) (Arrival process of jobs filtered out) For each class k \u2208 {1, 2}, let Un\nfl,k(t) be the partial sum\nof interarrival times among the first \u230at\u230b class k jobs that are filtered out, and An\nfl,k(t) be\nthe number of class k jobs that are filtered out by the filtering system up to time t, i.e.,\nAn\nfl,k(t) = PAn\n0 (t)\ni=1 I(f\u03b8(Xn\ni ) < zFL) \u00b7 Y n\nik, \u2200 k \u2208 {1, 2}. Moreover, let \u02dcUn\nfl,0(t) and \u02dcAn\nfl,k(t) be the\ncorresponding diffusion-scaled processes, defined as\n\u02dcUn\nfl,k(t) = n\u22121/2\nh\nUn\nfl,k(nt) \u2212 (\u039bnpn\nk(1 \u2212 gn\nk (zFL)))\u22121 \u00b7 nt\ni\n, \u2200 t \u2208 [0, 1], \u2200 k \u2208 {1, 2}\n\u02dcAn\nfl,k(t) = n\u22121/2\nh\nAn\nfl,k(nt) \u2212 \u039bnpn\nk(1 \u2212 gn\nk (zFL)) \u00b7 nt\ni\n, \u2200 t \u2208 [0, 1], \u2200 k \u2208 {1, 2};\n(iii) (Arrival process of the queueing system) Let Un\nps,0(t) be the partial sum of interarrival times\namong the first \u230at\u230b jobs that pass through the filtering system and arrive at the queueing\nsystem, and An\nps,0(t) be the number of jobs that pass through the filtering system and arrive at\nthe queueing system up to time t, i.e., An\nps,0(t) = PAn\n0 (t)\ni=1 I(f\u03b8(Xn\ni ) \u2265 zFL). Also, let \u02dcUn\nps,0 and\n\u02dcAn\nps,0 be the corresponding diffusion-scaled arrival process, defined as\n\u02dcUn\nps,0(t) = n\u22121/2[An\nps,0(nt) \u2212 nt \u00b7 (\u039bn\n2X\nk=1\npn\nkgn\nk (zFL))\u22121], \u2200 t \u2208 [0, 1],\n\u02dcAn\nps,0(t) = n\u22121/2[An\nps,0(nt) \u2212 nt \u00b7 \u039bn\n2X\nk=1\npn\nkgn\nk (zFL)], \u2200 t \u2208 [0, 1];\n(iv) (Arrival process of each reviewer) Let Un\nps,r(t) := P\u230at\u230b\ns=1 un\ns,r be the partial sum of interarrival\ntimes among the first \u230at\u230b jobs that are assigned to reviewer r, and An\nps,r(t) be the number of\njobs that are assigned to reviewer r up to time t, i.e., An\nps,r(t) = PAn\nps,0(t)\nj=1 Bjr. Moreover, let\n\u02dcUn\nps(t) = {\u02dcUn\nps,r(t)}r\u2208\u0393(zFL), \u02dcAn\nps(t) = { \u02dcAn\nps,r(t)}r\u2208\u0393(zFL) be the corresponding diffusion-scaled\n70\n\narrival process, defined as\n\u02dcUn\nps,r(t) = n\u22121/2\nh\nUn\nps,r(nt) \u2212 nt \u00b7 \u0393(zFL)\n\u039bn\nP2\nk=1 pn\nkgn\nk (zFL)\ni\n, \u2200 t \u2208 [0, 1],\n\u02dcAn\nps,r(t) = n\u22121/2\nh\nAn\nps,r(nt) \u2212 nt \u00b7 \u039bn\n\u0393(zFL)\n2X\nk=1\npn\nkgn\nk (zFL)\ni\n, \u2200 t \u2208 [0, 1];\n(v) (Split probability) Let pn\nfl,k be the probability that a job arriving at the triage system is of\nclass k and is filtered out by the filtering system, i.e., pn\nfl,k = pn\nk(1 \u2212 gn\nk (zFL)), and pn\nps be the\nprobability that a job arriving at the triage system passes through the filtering system, i.e.,\npn\nps = P2\nk=1 pn\nkgn\nk (zFL). Moreover, let pfl,k and pps be the corresponding limiting probability\ndefined as pfl,k = pk(1 \u2212 gk(zFL)) and pps = P2\nk=1 pkgk(zFL);\n(vi) (Spliting process) Let Sp fl,0(t) be the number of jobs that are filtered out by the filtering system\namong the first \u230at\u230b jobs arriving at the triage system, and Sp ps,r(t) be the number of jobs that\nare assigned to reviewer r among the first \u230at\u230b jobs arriving at the triage system. Moreover, let\nfSpfl(t) = {fSpfl,k(t)}k\u2208{1,2}, fSpps(t) = {fSpps,r(t)}r\u2208\u0393(zFL) be the corresponding diffusion-scaled\nsplitting process, defined as\nfSpfl,k(t) = n\u22121/2[Spfl,k(nt) \u2212 pn\nfl,k \u00b7 nt], \u2200 t \u2208 [0, 1], k \u2208 {1, 2}\nfSpps,r(t) = n\u22121/2[Spps,r(nt) \u2212 pn\nps \u00b7 nt\n\u0393(zFL)], \u2200 t \u2208 [0, 1].\nSimilar to Definition 8, we define processes above on [0, n] or [0, 1] for analysis simplicity. These\nprocesses can be naturally extended to [0 , +\u221e) to apply the martingale FCLT (Lemma 5) and\nFCLT for split processes from [68, Theorem 9.5.1], which yields the joint convergence result below.\nWith a slight abuse of notation, we adopt Assumption H to guarantee unform integrability of\nquantities associated with the triage system.\nLemma 28 (Joint convergence of the AI-based triage system) . Given a classifier f\u03b8, filtering\nlevel zFL, the number of hired reviewers \u0393(zFL), and a sequence of queueing systems, suppose\nthat Assumptions F, G, and H hold. Then, we have that: (i) there exists Brownian motion\n( \u02dcA0, fSpfl, fSpps) such that ( \u02dcAn\n0 , fSp\nn\nfl, fSp\nn\nps) \u21d2 ( \u02dcA0, fSpfl, fSpps) in (D\u0393(zFL)+3, W J1); (ii) there exist\ncontinuous stochastic processes ( \u02dcAfl,1, \u02dcAfl,2, \u02dcAps) such that\n( \u02dcAn\nfl,1, \u02dcAn\nfl,2, \u02dcAn\nps) \u21d2 ( \u02dcAfl,1, \u02dcAfl,2, \u02dcAps), in (D\u0393(zFL)+2, W J1),\nwhere \u02dcAfl,k(t) = pfl,k \u02dcA0(t) + fSpfl,k(\u039bt) and \u02dcAps,r(t) = pps \u02dcA0(t)\n\u0393(zFL) + fSpps,r(\u039bt); (iii) there exists contin-\nuous stochastic processes ( \u02dcUfl,1, \u02dcUfl,2, \u02dcUps) such that\n( \u02dcUn\nfl,1, \u02dcUn\nfl,2, \u02dcUn\nps) \u21d2 ( \u02dcUfl,1, \u02dcUfl,2, \u02dcUps), in (D\u0393(zFL)+2, W J1).\nProof As for (i), according to Assumption H, we have that Var[ un\n1 ] < +\u221e for each n, and\nVar[un\n1 ] converges to some constant \u03c32\nu. Then, by martingale FCLT (Lemma 5), it is easy to show\nthat ( \u02dcUn\n0 , fSp\nn\nfl, fSp\nn\nps) jointly convrges to ( \u02dcU0, fSpfl, fSpps). Here, \u02dcU0 is a zero-drift Brownian mo-\ntion with variance being some \u03c32\nu, and fSpps is a zero-drift Bronian motion with covariance matrix\nbeing \u03a3 = ( \u03c32\nr1,r2), where \u03c32\nr1,r1 = \u0393(zFL)\u22121\n\u03932(zFL) and \u03c32\nr1,r2 = \u2212 1\n\u03932(zFL), \u2200 r1 \u0338= r2. According to [68,\n71\n\nCorollary 13.8.1], the joint convergence of ( \u02dcA0, fSpfl, fSpps) follows immediately. (ii) is a direct con-\nsequence of (i) and [68, Theorem 9.5.1]. Then, by [68, Corollary 13.8.1], (iii) is a corollary of (ii).\nWith a slight abuse of notation, we extend from Definition 8 and Section 2 in order to define\nZn\nkl,r, Rn\nl,r, V n\nps,r on the jobs that are assigned to each reviewerr. Let \u02dcZ\nn\n:= { \u02dcZ\nn\nkl,r}k,l\u2208{1,2},r\u2208[\u0393(zFL)],\n\u02dcR\nn\n:= { \u02dcR\nn\nl,r}l\u2208{1,2},r\u2208[\u0393(zFL)], \u02dcVn\nps := {\u02dcV n\nps,r}r\u2208[\u0393(zFL)] be the corresponding diffusion-scaled pro-\ncesses. As the job assignment process is independent of any other random objects by Assumption G,\nit is easy to show that {( \u02dcZ\nn\nkl,r, \u02dcR\nn\nl,r, \u02dcV n\nps,r)} are i.i.d. processes across all reviewers. Therefore, by\nindependence and Lemma 9, we can extend Lemma 8 to achieve joint convergence of ( \u02dcZ\nn\n, \u02dcR\nn\n, \u02dcVn\nps)\nover all reviewers.\nLemma 29 (Joint weak convergence of the AI-based triage system I) . Suppose that Assump-\ntions F, G, and H hold. Then, there exist Brownian motions (\u02dcZ, \u02dcR, \u02dcVps) such that\n(\u02dcZ\nn\n, \u02dcR\nn\n, \u02dcVn\nps) \u21d2 (\u02dcZ, \u02dcR, \u02dcVps), in (D7\u0393(zFL), W J1).\nNext, we claim that ( \u02dcUn\nfl,1, \u02dcUn\nfl,2, \u02dcUn\nps) and ( \u02dcZ\nn\n, \u02dcR\nn\n, \u02dcVn\nps) are independent processes under As-\nsumption F. Recall that by Definition 14, Un\nps,0(t) denotes the partial sum of interarrival times\namong the first \u230at\u230b jobs that pass throught the filtering system. Let{un\nj : j \u2208 N} and {(Xn\nj , vn\nj , Yn\nj ) :\nj \u2208 N} be the interarrival time and tuples for jobs that pass through the filtering system . Then, we\nhave that Un\nps,0(t) := P\u230at\u230b\nj=1 un\nj .\nWe first show that {un\nj : j \u2208 N} and {(Xn\nj , vn\nj , Yn\nj ) : j \u2208 N} are independent. Let {un\ni : i \u2208 N}\nand {(Xn\ni , vn\ni , Yn\ni ) : i \u2208 N} be the interarrival times and tuples for all jobs arriving at the triage\nsystem. Note that the primitive sequences {un\ni : i \u2208 N} and {(Xn\ni , vn\ni , Yn\ni ) : i \u2208 N} are independent\nby Assumption F (ii). Therefore, by construction, {un\nj : j \u2208 N} are the thinned interarrival times\nfrom {un\ni : i \u2208 N}, where each arriving job is retained independetly with equal probability pn\nps.\nMoreover, since {(Xn\ni , vn\ni , Yn\ni ) : i \u2208 N} are i.i.d. by Assumption F (i), {(Xn\nj , vn\nj , Yn\nj ) : j \u2208 N} are\nalso i.i.d., following the conditional distribution ( Xn\n1 , vn\n1 , Yn\n1 ) | f\u03b8(Xn\n1 ) \u2265 zFL. It is important to\nnote that although {un\nj : j \u2208 N} depends on {(Xn\ni , vn\ni , Yn\ni ) : i \u2208 N} (through whether a general\njob is retained, i.e., f\u03b8(Xn\ni ) \u2265 zFL), the realization of un\nj can not provide additional information\non a job that is known to have been retained and its ( Xn\nj , vn\nj , Yn\nj ): we only know that such job\nsatisfies f\u03b8(Xn\nj ) \u2265 zFL on (Xn\nj , vn\nj , Yn\nj ). Therefore, un\nj and (Xn\nj , vn\nj , Yn\nj ) are independent according\nto independence by Assumption F (ii).\nAccording to analysis above, Un\nps,0(t) and {(Xn\nj , vn\nj , Yn\nj ) : j \u2208 N} are independent, as the former\nis a function of {un\nj : j \u2208 N}. Let {(Xn\ns,r, vn\ns,r, Yn\ns,r) : s \u2208 N} be the tuples for jobs assigned to\nsome reviewer r, which is splited from {(Xn\nj , vn\nj , Yn\nj ) : j \u2208 N} according to the reviewer assignment\n{Bn\nj : j \u2208 N}. Then, since {Bn\nj : j \u2208 N} is independent of any other random objects by Assump-\ntion F, we can adopt a similar approach to establish independence between ( \u02dcUn\nfl,1, \u02dcUn\nfl,2, \u02dcUn\nps) and\n{(Xn\ns,r, vn\ns,r, Yn\ns,r) : s \u2208 N, r\u2208 [\u0393(zFL)]}, which further yields independence between ( \u02dcUn\nfl,1, \u02dcUn\nfl,2, \u02dcUn\nps)\nand ( \u02dcZ\nn\n, \u02dcR\nn\n, \u02dcVn\nps). Finally, according to Lemmas 9, 28, and 29, such independence leads to the\njoint weak convergence of the AI triage system below (Lemma 30), which extends Lemma 3.\nLemma 30 (Joint weak convergence of the AI-based triage system II) . Suppose that Assump-\ntions F, G, and H hold. Then, we have that\n( \u02dcUn\nfl,1, \u02dcUn\nfl,2, \u02dcUn\nps, \u02dcZ\nn\n, \u02dcR\nn\n, \u02dcVn\nps) \u21d2 ( \u02dcUfl,1, \u02dcUfl,2, \u02dcUps, \u02dcZ, \u02dcR, \u02dcVps), in (D8\u0393(zFL)+2, W J1).\n72\n\nSimilarly to Lemma 4, we can then strengthen the convergence to uniform topology and conduct\nsample path analysis on copies of the original processes. With a slight abuse of notation, we still\nuse (\u2126copy, Fcopy, Pcopy) to denote the common probability space.\nLemma 31 (Uniform Convergence of the AI Triage System) . Suppose that Assumptions F, G,\nand H hold. Then, there exist stochastic processes ( \u02dcUn\nfl,1, \u02dcUn\nfl,2, \u02dcUn\nps, \u02dcZ\nn\n, \u02dcR\nn\n, \u02dcVps), \u2200 n \u2265 1 and\n( \u02dcUfl,1, \u02dcUfl,2, \u02dcUps, \u02dcZ, \u02dcR, \u02dcVps) defined on a common probability space (\u2126copy, Fcopy, Pcopy) such that\n( \u02dcUn\nfl,1, \u02dcUn\nfl,2, \u02dcUn\nps, \u02dcZ\nn\n, \u02dcR\nn\n, \u02dcVps), \u2200 n \u2265 1 and ( \u02dcUfl,1, \u02dcUfl,2, \u02dcUps, \u02dcZ, \u02dcR, \u02dcVps) are identical in distribution\nwith their original counterparts and\n( \u02dcUn\nfl,1, \u02dcUn\nfl,2, \u02dcUn\nps, \u02dcZ\nn\n, \u02dcR\nn\n, \u02dcVps) \u2192 ( \u02dcUfl,1, \u02dcUfl,2, \u02dcUps, \u02dcZ, \u02dcR, \u02dcVps), in (D8\u0393(zFL)+2, \u2225 \u00b7 \u2225), Pcopy \u2212 a.s..\nG.2 Sample path analysis of each reviewer\nIn this section, we conduct sample path analysis for each reviewer. We adopt a similar analysis\napproach as in Section 3 and 4. In particular, we consider copies of the original processes defined\non the common probability space Pcopy, as shown in Lemma 31. We establish all subsequent results\nregarding almost sure convergence for the copied processes, which can then be converted back into\ncorresponding weak convergence results for the original processes.\nHeavy Traffic Condition for Each Reviewer We first show that our Assumptions F and G\nare compatible with Assumptions A and B we adopt for each single-server queueing system.\nDefinition 13. Given a classifier f\u03b8, filtering level zFL, tpxicity level zTX, the number of hired\nreviewers \u0393(zFL), and a sequence of queueing systems, suppose that Assumptions F and G hold.\nWe define the following for any system n and reviewer r:\n(i) (Class prevalence) Let pn\nk,r(zFL) be the conditional probability that a job that passes through\nthe filtering system and is assigned to reviewer r is of class k, i.e., pn\nk,r(zFL) := Pn[Y n\n1k,r =\n1 | f\u03b8(Xn\n1,r) \u2265 zFL]. Moreover, let pk(zFL) be the limiting probability, defined as pk(zFL) :=\npkgk(zFL)\np1g1(zFL)+p2g2(zFL);\n(ii) (Confusion matrix) Let qn\nkl,r(z) be the conditional probability that a class k job arriving at re-\nviewer r is predicted as class l, i.e., qn\nkl,r(z) := Pn[Y n\n1l,r = 1 | f\u03b8(Xn\n1,r) \u2265 zFL, Yn\n1k,r = 1]. More-\nover, let qkl(z) be the limiting probability, defined as qk1(zFL, zTX) = gk(zTX)\ngk(zFL) , qk2(zFL, zTX) =\ngk(zFL)\u2212gk(ztx)\ngk(zFL) , \u2200 k \u2208 {1, 2};\n(iii) (Arrival rate) Let \u03bbn\nr = \u039bn\n\u0393(zFL)[pn\n1 gn\n1 (zFL) + pn\n2 gn\n2 (zFL)] be the arrival rate of jobs assigned to\nreviewer r. Moreover, let \u03bb = \u039b\n\u0393(zFL)[p1g1(zFL) + p2g2(zFL)] be the limiting arrival rate.\nWe define the arrival rate \u03bbn\nr based on Lemma 28, which shows that n\u22121An\nps,r(nt) = \u039bnt\n\u0393(zFL) \u00b7\nP2\nk=1 pn\nkgn\nk (zFL)+o(1). According to Assumptions F and G, it is easy to verify that class prevalence,\nconfusion matrix, and arrival rate all converges to their limiting values at the rate of n1/2.\nLemma 32. Given a classifier f\u03b8, filtering level zFL, toxicity level zTX, the number of hired review-\ners \u0393(zFL), and a sequence of queueing systems, suppose that Assumptions F and G hold. Then,\nfor any k, l\u2208 {1, 2}, an reveiwer r \u2208 [\u0393(zFL)], we have that\nn1/2(\u03bbn\nr \u2212 \u03bb) \u2192 0, n 1/2(pn\nk,r(zFL) \u2212 pk(zFL)) \u2192 0, n 1/2(qn\nkl,r(z) \u2212 qkl(z)) \u2192 0.\n73\n\nAs a direct corollary of Lemma 32 and Assumption G (ii), for each reviewer r, their limiting traffic\nintensity satisfies\n\u03bb\n2X\nk=1\npk(zFL)\n\u00b5k\n= \u039b\n\u0393(zFL)[p1g1(zFL) + p2g2(zFL)] \u00b7\n2X\nk=1\npkgk(zFL)\n\u00b5k(p1g1(zFL) + p2g2(zFL)) = 1.\nTherefore, all reviewers operate under heavy traffic conditions and satisfy Assumption A and B.\nThis enables us to directly apply results for the single-server queueing system to each reviewer.\nSince the analysis is similar, we only present the main results below and skip proof details.\nEndogenous Processes of the AI-based Triage System We define the concerned endogenous\nprocesses below to analyze the AI-based triage system following Definition 11.\nDefinition 14 (Endogenous processes of the AI-based triage system). Given the filtering level zFL,\ntoxicity level zTX, and the number of hired reviewers \u0393(zFL), for each system n and reviewer r, we\ndefine the following processes:\n(i) (Input process for predicted classes) Let Ln\nl,r(t) be the total service time requested by all jobs\npredicted as classl and assigned to reviewer r by time t \u2208 [0, n], i.e., Ln\nl,r(t) = PAn\nps,r(t)\ns=1 Y n\nsl,rvn\ns,r,\nt \u2208 [0, n]. Moreover, let \u02dcL\nn\nl,r(t) be the corresponding diffusion-scaled process, defined as\n\u02dcL\nn\nl (t) = n\u22121/2\nh\nLn\nl,r(nt) \u2212 \u039bn\n\u0393(zFL)\nKX\nk=1\npn\nkgn\nk (zFL)\n\u00b5n\nk\nqn\nkl(z) \u00b7 nt\ni\n, t \u2208 [0, 1].\n(ii) (Cumulative total input process) Let Ln\n+(t; z, r) = P\nl Ln\nl,r(t), t\u2208 [0, n] be the cumulative total\ninput process and \u02dcLn\n+(t; z, r) := PK\nl=1 \u02dcL\nn\nl,r(t), t \u2208 [0, 1] be the corresponding diffusion-scaled\nprocess, i.e.,\n\u02dcLn\n+(t; z, r) = n\u22121/2\nh\nLn\n+(nt; z, r) \u2212 \u039bn\n\u0393(zFL)\nKX\nk=1\npn\nkgn\nk (zFL)\n\u00b5n\nk\n\u00b7 nt\ni\n, \u2200 t \u2208 [0, 1].\n(iii) (Policy process) Let Tn\nl,r(t) be total amount of time during [0, t] that the server r allocates to\njobs from predicted class l;\n(iv) (Remaining workload process) Let Wn\nl,r(t) be the remaining service time requested by jobs\npredicted as class l and present\u2014waiting for service or being served\u2014by reviewer r at time\nt \u2208 [0, n]\nWn\nl,r(t) = Ln\nl,r(t) \u2212 Tn\nl,r(t), t \u2208 [0, n].\nand \u02dcW\nn\nl,r(t) := n\u22121/2Wn\nl,r(nt), \u2200 t \u2208 [0, 1] be the corresponding diffusion scaled process.\n(v) (Total remaining workload process) Let Wn\n+(t; z, r) = P\nl Wn\nl,r(t) be the total remaining work-\nload p rocess and \u02dcWn\n+(t; z, r) := n\u22121/2 PK\nl=1 Wn\nl (nt; z, r), \u2200 t \u2208 [0, 1] be the corresponding\ndiffusion scaled process.\nThen, by extending Lemma 13 and Proposition 1, we have the following results for the endogenous\nprocesses of each reviewer r.\n74\n\nLemma 33 (Convergence of \u02dcLn\n+(t; z, r) and \u02dcWn\n+(t; z, r)). Suppose that Assumptions F, G, and H\nhold.\n(i) for a sequence of feasible policies {\u03c0n}, we have that for each reviewer r,\n\u02dcLn\n+(\u00b7; z, r) \u2192 \u02dcL+(\u00b7; z, r)in (D, \u2225 \u00b7 \u2225) Pcopy \u2212 a.s., where\n\u02dcL+(t; z, r) := \u02dcVps,r\n\u0010 \u039bt\n\u0393(zFL)[p1g1(zFL) + p2g2(zFL)]\n\u0011\n+\nKX\nk=1\npk(zFL)\n\u00b5k\n\u02dcAps,r(t), t \u2208 [0, 1].\n(ii) for a sequence of work-conserving p-FCFS feasible policy, we have that for each reviewer r,\n\u02dcWn\n+(\u00b7; z, r) \u2192 \u02dcW+(\u00b7; z, r) := \u03d5(\u02dcLn\n+(\u00b7; z, r)) in (D, \u2225 \u00b7 \u2225) Pcopy \u2212 a.s., where \u03d5 is the reflection\nmapping.\nStarting from Lemma 33, we can then follow the sample path analysis and establish Theorem 5;\nwe skip the detailed proof here.\nG.3 Simulation of the total cost of the AI-based Triage System\nAs shown in Theorem 5, the limiting total cost is solely determined by (i) the limiting exogenous\nquantities, such as arrival rate \u039b, class prevalence pk(zFL), confusion matrix qkl(zFL), etc; and (ii)\nthe limiting total workload process \u02dcW+(\u00b7; z, r). Though (i) can be easily estimated, (ii) requires a\nmore detailed analysis to assist a practical estimation.\nAccording to Lemma 33, \u02dcW+(\u00b7; z, r) is a continuous stochastic process. Therefore, it suf-\nfices to approximate the integral by a Riemann sum. In particular, we have that \u02dcW+(t; z, r) :=\n\u03d5(\u02dcLn\n+(t; z, r)), where\n\u02dcLn\n+(t; z, r) \u2192 \u02dcL+(t; z, r) := \u02dcVps,r\n\u0010 \u039bt\n\u0393(zFL)[p1g1(zFL) + p2g2(zFL)]\n\u0011\n+\nKX\nk=1\npk(zFL)\n\u00b5k\n\u02dcAps,r(t).\nIn the sequel, we analyze \u02dcAps,r(t) and \u02dcVps,r separately. By Lemma 28, we have that \u02dcAps,r(t) =\npps \u02dcA0(t)\n\u0393(zFL) + fSpps,r(\u039bt). Note that \u02dcU0 is a zero-drift Brownian motion with variance being \u03c32\nu < +\u221e\nby Assumption H, which can be estimated similarly as in Section A.2.1. Then, by [68, Corollary\n13.8.1], we have that \u02dcA0(t) = \u2212\u039b \u02dcU0(\u039bt) and\n\u02dcAps,r(t) = \u2212 \u039bpps\n\u0393(zFL)\n\u02dcU0(\u039bt) + fSpps,r(\u039bt).\nHere, fSpps is a zero-drift Bronian motion with covariance matrix being \u03a3 = (\u03c32\nr1,r2), where \u03c32\nr1,r1 =\n\u0393(zFL)\u22121\n\u03932(zFL) and \u03c32\nr1,r2 = \u2212 1\n\u03932(zFL), \u2200 r1 \u0338= r2; see discussion following [68, Theorem 9.5.1]. For \u02dcVps,r,\naccording to Assumption H, it is easy to verify that Var[ vn\ns,r] < +\u221e for each n and converges to\nsome constant \u03c32\nv(zFL) = \u03b1v,1p1(zFL)+\u03b1v,2p2(zFL)\u2212\n\u0000 1\n\u00b51\np1(zFL)+ 1\n\u00b52\np2(zFL)\n\u00012. Then, by martingale\nFCLT (Lemma 5), we have that \u02dcVps,r is a zero-drift Brownian motion with variance being \u03c32\nv(zFL).\nIn this way, we rewrite \u02dcW+(t; z, r) as a function of (multi-dimensional) Brownian motion, whose\nRiemann sum can be easily simulated.\n75",
            "source": "pypdf",
            "quality_score": 0.0
          }
        ],
        "metrics": {
          "method": "pypdf",
          "chunk_count": 1,
          "total_chars": 221188,
          "avg_chunk_length": 221188,
          "processing_time": 3.3191590309143066,
          "quality_scores": {},
          "issues": [
            "No semantic chunking - returns entire document as single chunk",
            "No structure preservation",
            "No metadata enrichment",
            "Poor for RAG retrieval"
          ]
        }
      },
      "sherpa": {
        "chunks": [],
        "metrics": {
          "method": "sherpa",
          "chunk_count": 0,
          "total_chars": 0,
          "avg_chunk_length": 0,
          "processing_time": 19.53934669494629,
          "quality_scores": {},
          "issues": [
            "Layout detection weak - produced single chunk",
            "No semantic boundary detection",
            "No metadata enrichment",
            "Relies on visual layout which may not reflect semantic structure"
          ]
        }
      },
      "prompt": {
        "chunks": [
          {
            "chunk_id": "prompt_0",
            "title": "__auto__",
            "text": "Design and Scheduling of an AI-based Queueing System\nJiung Lee1 Hongseok Namkoong2 Yibo Zeng2\nCoupang1 Columbia University2\njiunglee28@gmail.com namkoong@gsb.columbia.edu yibo.zeng@columbia.edu\nAbstract\nTo leverage prediction models to make optimal scheduling decisions in service systems, we\nmust understand how predictive errors impact congestion due to externalities on the delay\nof other jobs. Motivated by applications where prediction models interact with human servers\n(e.g., content moderation), we consider a large queueing system comprising of many single server\nqueues where the class of a job is estimated using a prediction model. By characterizing the\nimpact of mispredictions on congestion cost in heavy traffic, we design an index-based policy that\nincorporates the predicted class information in a near-optimal manner. Our theoretical results\nguide the design of predictive models by providing a simple model selection procedure with\ndownstream queueing performance as a central concern, and offer novel insights on how to design\nqueueing systems with AI-based triage. We illustrate our framework on a content moderation\ntask based on real online comments, where we construct toxicity classifiers by finetuning large\nlanguage models.\n1 Introduction\nRecent advances in predictive models present significant opportunities for utilizing unstructured\ninformation such as images and text to solve real-world sequential decision-making problems. A\nmajor challenge to effective decision-making is modeling complex endogenous interactions. For\ninstance, prioritizing a particular job in a service system incurs negative externalities that affect the\ncongestion of other jobs. Building effective scheduling policies requires a fundamental understanding\nof how decisions based on (potentially erroneous) predictions propagate through the system.\nIn this paper, we explore the use of predictive information to allocate scarce resources across\nstochastic workloads. We are motivated by content moderation systems on social media, a critical\nprocess for maintaining the health and sustainability of online platforms. Delays in removing\nviolating posts (e.g., hate speech) can exacerbate their negative impact. While clear-cut cases can\nbe filtered out by an initial AI-based filtering system, nuanced moderation requires human reviewers\nto account for nonstationary social contexts and avoid unnecessary censorship and violations of\nfreedom of speech [3, 39].\nWe model content moderation as a large-scale service system involving human reviewers and\nstate-of-the-art AI models (Figure 1). To ensure fairness and similar workload between human\nreviewers, jobs are typically assigned to different human reviewers in an identically random manner.\nThe dynamic scheduling problem can thus be reduced to a single-server queuing system for each\nhuman reviewer, where jobs are categorized into different classes according to toxicity and whether\nthe content targets protected demographic features such as race or religion. Online platforms incur\ndifferential cost of delay across job classes depending on their potential harm, and AI models present\nopportunities to utilize predictions of harm based on sophisticated content and user features.\nThe random assignment assumption allows us to model the system as a set of single-server\nqueues where job classes (e.g., toxicity) are a priori unknown. Here, misclassifications have endoge-\nnous impact on congestion since prioritizing a job delays the processing of others. To minimize the\n1\narXiv:2406.06855v1  [math.OC]  11 Jun 2024",
            "source": "prompt",
            "quality_score": 0.0,
            "metadata": {
              "content_type": [
                "Result/Finding",
                "Procedure"
              ],
              "difficulty_level": 4,
              "retrieval_hints": [
                "What is the impact of predictive errors on scheduling in queueing systems?",
                "How can AI-based models improve scheduling decisions in service systems?"
              ],
              "summary": "This paper discusses the design of an AI-based queueing system that utilizes predictive models to optimize scheduling decisions, highlighting the effects of mispredictions on congestion and proposing an index-based policy for improved performance."
            }
          },
          {
            "chunk_id": "prompt_1",
            "title": "__auto__",
            "text": "1\nFiltering \nSystem\nContents \ufb02agged for review\nContents deemed safe by AI-based \ufb01ltering system\n\u2026\nHuman  \nreviewers\nrandomly \nassigned\nContents require human review\n\u0393\n2\u2026\nEach reviewer\nAI model\nGI/GI/1 queue with \npredicted classes\nContents require \nhuman review\nAn AI model classifies each content into  \npredicted job classes  green ,  pink ,  red \nFigure 1. Schematic of a content moderation system as a triage system. Each content\nmay be violating the user agreement (red toxicity symbol) or considered safe (green checkmark).\nThis ground truth requires human review to uncover (\u201cservice\u201d). Contents are flagged for review by\nusers or automated filters, which we view as \u201centering\u201d the triage system. The online platform uses\nan initial AI model to filter out contents most deemed to be safe. Then, remaining jobs/contents\nare randomly assigned to the human reviewers, a common practice due to fairness considerations in\nterms of mental workload. An AI model classifies each content into different classes (e.g., hate speech\non a protected group), placing them in the corresponding virtual queue for the predicted class.\noverall cost, we must balance heterogeneous service rates\u2014such as political misinformation being\nharder to review than nudity\u2014and the adverse effects of congestion, like toxic content going viral,\nby accounting for how misclassification errors reverberates through the queueing system.\nWhen the class of every job is known, a simple index-based myopic policy\u2014the oracle G c\u00b5-\nrule\u2014is optimal in highly congested systems [63, 40]. Concretely, consider a single-server queue\nwith K distinct job classes with arrival and service rates \u03bbk and \u00b5k, which we assume are known\nto the modeler. Let Ck(\u00b7) be a convex cost function defined on sojourn time of jobs in class\nk = 1, . . . , K(time between job arrival and service completion). The oracle G c\u00b5-rule is intuitive\nand simple: it greedily prioritizes jobs with the highest marginal cost of delay\nargmax\nk\u2208[K]\n\u00b5k(t)(Ck)\u2032(ak(t)) Oracle G c\u00b5-rule, (1.1)\nwhere ak(\u00b7) is the age or the waiting time of the oldest unfinished job of class k.\nWhen the true classes are unknown, we predict the job class using a classifier. Letting \u03bbl and\n\u00b5l be the arrival and service rates for a predicted class l, a naive adaptation of the G c\u00b5-rule is\nargmax\nl\u2208[K]\n\u00b5l(t)(Cl)\u2032(al(t)) Naive G c\u00b5-rule, (1.2)\nwhere al(\u00b7) is the age or the waiting time of the oldest unfinished job with predicted class l (Defini-\ntion 2). This index policy does not consider misclassifications and ignores the fact that delay cost\ndepends on the true class label instead of the predicted class: the delay cost of a content depends\non whether it is toxic, rather than the prediction of toxicity. This mismatch leads to suboptimal\nscheduling decisions as we show in Theorem 3 to come.\nWe propose and analyze an index policy that optimally incorporates the impact of prediction\nerrors in the overall cost of delay. We consider the weighted average of true class costs Ck using\nthe conditional probability that a job predicted as class l belongs to class k\nCl(t) :=\nKX\nk=1\npkqklPK\nk\u2032=1 pk\u2032 qk\u2032l\n\u00b7 Ck(t), t \u2208 [0, \u221e), (1.3)\n2",
            "source": "prompt",
            "quality_score": 0.0,
            "metadata": {
              "content_type": [
                "Result/Finding",
                "Procedure"
              ],
              "difficulty_level": 4,
              "retrieval_hints": [
                "What is the impact of predictive errors on scheduling in queueing systems?",
                "How can AI-based models improve scheduling decisions in service systems?"
              ],
              "summary": "This paper discusses the design of an AI-based queueing system that utilizes predictive models to optimize scheduling decisions, highlighting the effects of mispredictions on congestion and proposing an index-based policy for improved performance."
            }
          },
          {
            "chunk_id": "prompt_2",
            "title": "__auto__",
            "text": "20 40 60 80\nAverage Cumulative Cost\n1\n10\n100# of Hyperparameters\n# of Hyperparameters\nCDF\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nCDF\nFigure 2. Histogram of average cumulative\nqueueing cost of deep Q-learning policies over\n672 hyperparameter configurations.\nOracle Gc\n Our Method DRL\n6.0\n6.5\n7.0\n7.5\n8.0\n8.5Cumulative Cost\nFigure 3. Cumulative cost with 2 \u00d7 stan-\ndard errors\nwhere pk is the probability that an arbitrary job in the system belongs to class k, and qkl is the\nprobability that an arbitrary class k job is predicted as class l. This gives rise to the index rule\nargmax\nl\u2208[K]\n\u00b5l(t)(Cl)\u2032(al(t)) P c\u00b5-rule, (1.4)\nwhich is easy to implement since the arrival rates and misclassification errors that determine Cl(t)\ncan be efficiently estimated. In the specific case of linear delay costs and steady-state waiting time\nas the performance metric, the Pc\u00b5-rule bears resemblance to Argon and Ziya [4, Section 8]\u2019s policy\ndefined with conditional distributions of the true classes given the signal from a job. In contrast,\nwe model increasing marginal cost of delay in content moderation through strongly convex cost\nfunctions and prove (heavy traffic) optimality over all feasible policies, in contrast to Argon and\nZiya [4]\u2019s analysis focusing on dominance over first-come-first-serve policies.\nOffline deep reinforcement learning (DRL) methods are a popular contender to sequential\ndecision-making. While flexible, DRL methods require significant engineering efforts to be reli-\nably trained [29, 66, 16], and the performance of DRL methods is known to be highly sensitive to\nhyperparameters, implementation details, and even random seeds [29]. On a single-server queue\nwith 10 classes, we observe that deep Q-learning policies with experience replay exhibits substantial\nvariation in performance across hyperparameters, even when using identical instant rewards func-\ntions, training/testing enviroments, and same random seeds across training runs (Figure 2). The\nsimple index policy P c\u00b5-rule significantly outperforms the best-performing DRL hyperparameter\nconfiguration (Figure 3), as we illustrate in detail in Section 5.\nIn contrast to the growing body of work on learning in queueing that develop online learning\nalgorithms [13, 34, 36, 59, 65, 22], we propose an off-policy method to model applications where\nexperimentation is risky or unwieldy. This reflects operational constraints that arise from modern\nAI-based service systems where models are trained offline using previously collected data. Since\nwe assume service times are determined by true classes, in principle observed service times contain\ninformation about true class labels that can be used to improve the classifier in real time. Even\nin the largest industrial scenarios, however, online learning requires prohibitive infrastructure due\nto the high engineering complexity required for implementation. Any prediction model must be\nthoroughly validated prior to deployment, and the timescale for model development is typically\nlonger (weeks to months) than that for scheduling decisions (hours to days). We thus view our\noffline heavy traffic analysis to be an useful analytic device for modeling AI-based queueing systems\nthat operate close to system capacity. See Section 8 for a thorough literature review.\n3",
            "source": "prompt",
            "quality_score": 0.0,
            "metadata": {
              "content_type": [
                "Result/Finding",
                "Procedure"
              ],
              "difficulty_level": 4,
              "retrieval_hints": [
                "What is the impact of predictive errors on scheduling in queueing systems?",
                "How can AI-based models improve scheduling decisions in service systems?"
              ],
              "summary": "This paper discusses the design of an AI-based queueing system that utilizes predictive models to optimize scheduling decisions, highlighting the effects of mispredictions on congestion and proposing an index-based policy for improved performance."
            }
          },
          {
            "chunk_id": "prompt_3",
            "title": "__auto__",
            "text": "Contributions Our work contributes to the growing literature studying the interface between\npredictive models and decision-making [4, 41, 57, 33, 12, 60]. Prediction is rarely the end goal\nin operational scenarios, but the link between predictive performance and downstream decision-\nmaking performance is complex due to endogeneity\u2014misclassifications have downstream impact on\ndelays. This work crystallizes how classical tools from queueing theory can be modified to provide\nmanagerial insights on the control and design of AI-based service systems.\nSince solving for the optimal scheduling policy is computationally intractable even when job\nclasses are known due to large state/policy spaces [46], we study highly congested systems in the\nheavy traffic limit as is standard in the queueing literature [50, 63, 28, 68, 40]. Our theoretical\nframework characterizes the optimal queueing performance in the presence of misclassification errors\n(Sections 3, 4), and offers several insights on the design of AI-based service systems like the one\nwe study in Figure 1. Along the way, we identify a number of technical errors in the classical\nframework [63] and identify conditions under which prior results hold by giving corrected proofs\nbased on our new techniques.\nFirst, we derive a simple scheduling algorithm (1.4) with strong optimality and robustness\nguarantees by analyzing the stochastic fluctuations in the queue lengths of the unobservable true\nclass jobs, and aggregating them to represent the fluctuation in the queue length of each predicted\nclass (Section 3). We quantify the optimal workload allocation across the predicted classes and\nderive the Pc\u00b5 cost function from the KKT conditions of the optimal resource allocation problem\nin the heavy traffic limit (3.4) (Section 4). Our theoretical results show that the P c\u00b5-rule induces\nqueueing dynamics that achieve the asymptotic optimality with exogenous costs Cl(\u00b7).\nNext, we study the design of AI models with a central focus on decision-making. Although\npredictive performance is rarely the final goal, models are typically validated based on predictive\nmeasures such as precision or recall for convenience. But overparameterized models (e.g., neural\nnetworks) can achieve the same predictive performance, yet exhibit very different downstream deci-\nsion performance [17, 8]. We quantify the connection between predictive performance and the cost\nof delay, allowing us to design AI models with downstream decision-making performance as a cen-\ntral concern (Section 6). We propose a model selection procedure based on the cumulative queueing\ncost, and demonstrate its advantages in contrast to conventional model selection approaches in ML\nthat solely rely on predictive measures.\nFinally, we use our characterization of the optimal queueing cost under misclassifications to\ninform the design of the queueing system itself. In the context of our motivating content mod-\neration problem, we design an AI-based triaging system that helps determine staffing levels and\ncorresponding filtering levels based on predictions from an initial round AI model (which may or\nmay not be the same model used to classify jobs into classes). We propose a holistic framework\ntrading off filtering cost, predictive performance, hiring costs, and congestion in the queueing sys-\ntem (Section 7). Our formulation significantly contributes to the practical discussion on designing\ncontent moderation systems, which traditionally focuses on pure prediction metrics [2, 54, 67, 1].\nIn Section 7.4, we demonstrate that traditional prediction-based metrics may accurately reflect the\noverall costs of a triage system when either filtering costs or hiring costs are the predominant fac-\ntor. However, these metrics fall short in more complex scenarios where there are trade-offs between\ndifferent types of costs. As a result, optimizing for these metrics typically requires computationally\nexpensive queueing simulations. In contrast, our method reliably determines the optimal staffing\nand filtering levels across all scenarios by simulating a (reflected) Brownian motion.\n4",
            "source": "prompt",
            "quality_score": 0.0,
            "metadata": {
              "content_type": [
                "Result/Finding",
                "Procedure"
              ],
              "difficulty_level": 4,
              "retrieval_hints": [
                "What is the relationship between predictive models and decision-making?",
                "How can queueing theory be applied to AI-based service systems?",
                "What are the implications of misclassification errors in scheduling policies?"
              ],
              "summary": "This work explores the intersection of predictive models and decision-making, highlighting the complexities introduced by misclassifications and proposing a modified queueing theory framework to enhance AI-based service system design."
            }
          },
          {
            "chunk_id": "prompt_4",
            "title": "__auto__",
            "text": "2 Model\nWe begin by presenting our analytic framework in the heavy traffic regime. There are two possible\ndata generating processes we can study. We could view jobs as originating from a single common\narrival process, where interarrival times are independent of job features, true classes labels, and\nservice times. This single arrival stream allows us to disentangle the arrival and service processes\nof predicted classes, and directly use the diffusion limit to show optimality of the P c\u00b5-rule. On\nthe other hand, we may consider a more general generating process where the arrival and service\nprocesses for different classes are exogenously given. In this setting, we can still show similar\nmathematical guarantees as under the single stream model using heavy traffic analysis techniques\npioneered by Mandelbaum and Stolyar [40]. However, this proof approach weakens our optimality\nresults: we can only show optimality of the P c\u00b5-rule over first-come-first-serve policies, whereas\nunder the single stream model, the direct analysis allows proving optimality over all feasible policies\n(see Section B.4). Furthermore, this proof approach requires more restrictive regularity conditions\nthan the direct method that is possible under the single arrival stream model\u2014see Section E.3\nfor a detailed discussion. We view the practical modeling capabilities of the two data generating\nassumptions to be similar; the singe arrival stream is a good model of the content moderation\nsystem (as depicted in Figure 1). Henceforth, we thus focus on the single common arrival process\nfor expositional clarity and crisp mathematical results.\nWe consider a sequence of single-server multi-class queueing systems indexed by n \u2208 N, con-\nnected through a heavy traffic condition. Each system n operates on a finite time horizon [0 , n],\nand starts empty. Let un\ni be i.i.d. interarrival times with an arrival rate \u03bbn. For t \u2208 [0, n], let\nUn\n0 (t) := P\u230at\u230b\ni=1 un\ni be the arrival time of the \u230at\u230bth job in the system and An\n0 (t) = max{m : Un\n0 (m) \u2264\nt} be the total number of jobs that arrive up to time t. For each class k, let pn\nk := Pn[Y n\n1k = 1]\nbe the class prevalence and ( \u00b5n\nk)\u22121 := En[vn\n1 | Y n\n1k = 1] the expected service time. For each job, a\ntuple (Xn\ni , Yn\ni , vi) is generated independently of its interarrival time un\ni where Xn\ni \u2208 Rd represents\nthe feature vector associated with the ith job, vn\ni indicates the time required to serve the ith job,\nand Y n\ni = ( Y n\ni1, ..., Yn\niK) denotes the one-hot encoded representation of its true class label. Let\nV n\n0 (t) := P\u230at\u230b\ni=1 vn\ni , \u2200 t \u2208 [0, n] be the total service time required by the first \u230at\u230b jobs.\nA classifier f\u03b8 predicts a class for each job i using observed features Xn\ni , and the job i joins the\n(virtual) queue corresponding to the (one-hot encoded) predicted class Y n\ni := f\u03b8(Xn\ni ) to wait for\nservice. Let qn\nkl := Pn[Y n\n1l = 1 | Y n\n1k = 1] be the probability of a class k job being predicted as class\nl; Qn := (qn\nkl)k,l\u2208[K] is the confusion matrix.\nWe assume service time is conditionally independent of the covariates given the true class label\nY n\ni , vn\ni \u22a5 Xn\ni | Y n\ni , which simplies our anlysis by only considering true class label\u2019s impact on\nservice time. In practice, if covariates influence service time (e.g., content length), we can mitigate\nsuch dependency by creating more fine-grained true classes. We summarize our data generating\nprocess as in the following assumption.\nAssumption A (Data Generating Processes). For any system n \u2208 N, i) {(un\ni , vn\ni , Xn\ni , Yn\ni ) : i \u2208 N}\nis a sequence of i.i.d. random vectors, ii) {un\ni : i \u2208 N} and {(vn\ni , Xn\ni , Yn\ni ) : i \u2208 N} are independent,\nand iii) for any i \u2208 N, vn\ni and Xn\ni are conditionally independent given Y n\ni .\nThe following assumption formalizes the notion of heavy traffic.\n5",
            "source": "prompt",
            "quality_score": 0.0,
            "metadata": {
              "content_type": [
                "Definition",
                "Result/Finding",
                "Context"
              ],
              "difficulty_level": 4,
              "retrieval_hints": [
                "What are the implications of using a single common arrival process?",
                "How does the heavy traffic regime affect queueing systems?",
                "What are the optimality results of the P c\u00b5-rule?"
              ],
              "summary": "The chunk discusses an analytic framework for multi-class queueing systems under heavy traffic conditions, comparing single and general arrival processes and their implications for optimality of the P c\u00b5-rule."
            }
          },
          {
            "chunk_id": "prompt_5",
            "title": "__auto__",
            "text": "Assumption B (Heavy Traffic Condition). Given a classifier f\u03b8 and a sequence of queueing sys-\ntems, there exist pk, qkl \u2208 [0, 1] and \u03bb, \u00b5k such that PK\nk=1 pkqkl > 0, \u03bb PK\nk=1\npk\n\u00b5k\n= 1, and\nn1/2\u0000\n\u03bbn \u2212 \u03bb\n\u0001\n\u2192 0, n 1/2\u0000\n\u00b5n\nk \u2212 \u00b5k\n\u0001\n\u2192 0, n 1/2\u0000\npn\nk \u2212 pk\n\u0001\n\u2192 0, n 1/2\u0000\nqn\nkl \u2212 qkl\n\u0001\n\u2192 0. (2.1)\n\u03bbn \u2212 \u03bb = o(n\u22121/2) and \u00b5n\nk \u2212 \u00b5k = o(n\u22121/2) aligns with classical assumptions [40, Eq. (2)], and as\nusual we have that traffic intensity \u03c1n := \u03bbn P\nk pn\nk/\u00b5n\nk converges to 1 at o(n\u22121/2)-rate\nn1/2[\u03c1n \u2212 1] = n1/2\nh\n\u03bbn\nKX\nk=1\npn\nk\n\u00b5n\nk\n\u2212 1\ni\n\u2192 0. (2.2)\nThe convergence rates in Assumption B are necessary for the results in Theorem 2 and Theorem 3\nto come.\nNotation Let C be the space of continuous [0, 1] 7\u2192 R functions, D the set of the right-continuous\nwith left limits (RCLL); all stochastic processes will be RCLL. Let Dk be its product space and\n\u2225x(t)\u2225 := maxi\u2208[k] |xi(t)|. Define dJ1(\u00b7, \u00b7) : D \u00d7 D \u2192R+ to be the J1 (Skhorohod) metic [68, Page\n79]. For any vector-valued functions x(t), y(t) \u2208 Dk, define dp(x, y) = Pk\ni=1 dJ1(xi, yi) [68, Page 83]\nand its topology W J1 (weak J1 topology). For a stochastic process, An\nk(t), the underlined format\nis used to denote the counterpart process associated with the predicted class, An\nl (t).\n3 Lower bound on queueing cost\nOur analysis relies on a diffusion limit for predicted classes of the model. Scheduling is based on\npredicted classes, but service times are determined by the true classes. We characterize how mis-\nclassifications incur externalities on other jobs, and derive the optimal queueing cost in Theorem 2\nto come. Compared to classical results in queueing that assume job classes are known [63, Proposi-\ntion 6], our analysis requires handling the unobservable queue lengths of true classes as mentioned\nearlier; see the discussion in Section C.1.\nWhen the job classifier is \u201cperfect\u201d, we haveQn = I where Qn is the confusion matrix defined in\nthe previous section. In this case, our setting reduces to the classical setting where true classes are\nknown, and our proofs to come give the counterpart results in Van Mieghem [63] and Mandelbaum\nand Stolyar [40]. Even in this classical setting, our analysis identifies missing assumptions (e.g.,\nthe zero limits in Assumption B) and provides proofs of missing arguments in Van Mieghem [63],\nMandelbaum and Stolyar [40].\n3.1 Convergence of endogenous processes\nDefine the counting processes for arrivals and service completions in the predicted classes. Let the\nl-th component of An : [0, n] \u2192 NK be the number of jobs that are predicted as class l until time\nt \u2208 [0, n], and similarly let Sn : [0, n] \u2192 NK count service completions as a function of the total\ntime that the server dedicates to each predicted class. Let \u00b5n\nl be the service rate of jobs in predicted\nclass l, with \u00b5l as the corresponding limit. For ease of exposition, we defer a formal discussion of\ndiffusion limits Section A and defer precise definitions to Section B.3.\nFeasible Policies A scheduling policy \u03c0n is characterized by an allocation process Tn : [0, n] \u2192\nRK whose l-th coordinate denotes the total time dedicated to predicted class l up to t \u2208 [0, n].\n6",
            "source": "prompt",
            "quality_score": 0.0,
            "metadata": {
              "content_type": [
                "Definition",
                "Result/Finding",
                "Context"
              ],
              "difficulty_level": 4,
              "retrieval_hints": [
                "What are the implications of using a single common arrival process?",
                "How does the heavy traffic regime affect queueing systems?",
                "What are the optimality results of the P c\u00b5-rule?"
              ],
              "summary": "The chunk discusses an analytic framework for multi-class queueing systems under heavy traffic conditions, comparing single and general arrival processes and their implications for optimality of the P c\u00b5-rule."
            }
          },
          {
            "chunk_id": "prompt_6",
            "title": "__auto__",
            "text": "We use \u03c0n and Tn interchangably. Let Nn(t) : [0 , n] \u2192 NK be the queue length process; its\nl-th coordinate denotes total jobs from predicted class l remaining in system at t \u2208 [0, n]. Let\nIn(t) := t \u2212 P\nl Tn\nl (t) be the cumulative idling time up to t \u2208 [0, n]. The scheduler has full\nknowledge of arrivals and the queue of predicted classes.\nDefinition 1 (Feasible Policies). The sequence of scheduling policies {\u03c0n} is feasible if the associ-\nated processes {Tn(t), Nn(t), In(t)} satisfy for all n \u2208 N,\n(i) Tn(0) = 0, Tn is continuous and nondecreasing, Nn \u2265 0, and In is nondecreasing;\n(ii) {Tn(t), t\u2208 [0, n]} is adapted to the filtration \u03c3{(An(s), Nn(s)) : 0 \u2264 s < t}.\nCondition (i) is natural, and condition (ii) ensures that {\u03c0n} only relies on arrivals and queue\nstatus of predicted classes up to time t. We allow preemption (preemptive-resume policy) so that\nthe server is able to pause serving one job and switch to another in a different predicted class.\nPreemption is not allowed between jobs from the same predicted class, consistent with classical\nsettings [40].\nCumulative Queueing Cost Our goal is to minimize the cumulative queueing cost determined\nby true class labels. For a true class k job, its queueing cost is Cn\nk (\u03c4) where \u03c4 is sojourn time.\nLet \u03c4n\nlj be the sojourn time of the jth job of predicted class l, and \u03c4 n = {\u03c4n\nl }l\u2208[K] be the sojourn\ntime process tracking that of the most recently arriving job in predicted class l by time t, i.e.,\n\u03c4n\nl (t) = \u03c4n\nlAn\nl (t). Since ( \u03c4n\nl )l\u2208[K] is of order n1/2 (see Proposition 1 to come), we also assume\ncommensurate scaling on {Cn\nk }k\u2208[K] in Assumption C.\nAssumption C (Cost functions I) . For all k \u2208 [K], Cn\nk (\u00b7) is differentiable, nondecreasing, and\nconvex for all n. There exists a continuously differentiable and strictly convex function Ck with\nC\u2032\nk(0) = 0 such that Cn\nk (n1/2\u00b7) \u2192 Ck(\u00b7) and n1/2(Cn\nk )\u2032(n1/2\u00b7) \u2192 C\u2032\nk(\u00b7) uniformly on compact sets.\nThe scaled cumulative cost function incurred by \u03c0n is\n\u02dcJn\n\u03c0n(t; Qn) = n\u22121\nKX\nl=1\nKX\nk=1\nZ nt\n0\nCn\nk (\u03c4n\nl (s))dAn\nkl(s), \u2200 t \u2208 [0, 1], (3.1)\nwhere dAn\nkl is the the Lebesgue-Stieltjes measure induced byAn\nkl. \u02dcJn\n\u03c0n(t; Qn) relies on the scheduling\npolicy via the sojourn time process {\u03c4n\nl }. Similar to the classical settings [63, 40], we study p-\nFCFS policies\u2014those serving each predicted class in a first-come-first-served manner. Given a\nfeasible policy \u03c0n, we can reorder service within each predicted class to derive a feasible p-FCFS\ncounterpart, \u03c0n,p-FCFS, which dominates the original policy stochastically, i.e., Pn[ \u02dcJn\n\u03c0n,p-FCFS(t) >\nx] \u2264 Pn[ \u02dcJn\n\u03c0n(t) > x], \u2200 x \u2208 R, t \u2208 [0, 1] (see Lemma 11). Since the objective (3.1) does not\ninclude preemption cost like [63, 40], work-conserving policies\u2014the server never idles when jobs\nare present\u2014dominates non-work-conserving policies in cumulative cost \u02dcJn a.s. (see Lemma 12).\nThus, we henceforth focus on p-FCFS and work-conserving feasible policies.\nSample path analysis Let \u02dcUn\n0 , \u02dcV n\n0 be diffusion-scaled versions of partial sums of interarrival\nand service times:\n\u02dcUn\n0 (t) = n\u22121/2[Un\n0 (nt) \u2212 (\u03bbn)\u22121 \u00b7 nt], \u02dcV n\n0 (t) = n\u22121/2[V n\n0 (nt) \u2212\nnX\nk=1\npn\nk\n\u00b5n\nk\n\u00b7 nt], t \u2208 [0, 1]. (3.2)\n7",
            "source": "prompt",
            "quality_score": 0.0,
            "metadata": {
              "content_type": [
                "Definition",
                "Result/Finding",
                "Context"
              ],
              "difficulty_level": 4,
              "retrieval_hints": [
                "What are the implications of using a single common arrival process?",
                "How does the heavy traffic regime affect queueing systems?",
                "What are the optimality results of the P c\u00b5-rule?"
              ],
              "summary": "The chunk discusses an analytic framework for multi-class queueing systems under heavy traffic conditions, comparing single and general arrival processes and their implications for optimality of the P c\u00b5-rule."
            }
          },
          {
            "chunk_id": "prompt_7",
            "title": "__auto__",
            "text": "In Lemma 3 to come, we show there exist Brownian motions (\u02dcU0, \u02dcV0) such that (\u02dcUn\n0 , \u02dcV\nn\n0 ) \u21d2 ( \u02dcU0, \u02dcV 0)\nin (D2, W J1). Building off of our diffusion limit, we can strengthen the convergence to the uniform\ntopology using standard tools (e.g., see Lemma 6 and Lemma 7), and conduct a sample path\nanalysis where we construct copies of ( \u02dcUn\n0 , \u02dcV n\n0 ) and ( \u02dcU0, \u02dcV0) that are identical in distribution with\ntheir original counterparts and converge almost surely under a common probability space. With a\nslight abuse of notations, we use the same notation for the newly construced processes.\nSample path analysis allows us to leverage properties of uniform convergence and significantly\nsimplifies our analysis. All subsequent results and their proofs in the appendix, will be established\non the copied processes in the common probability space (\u2126 copy, Fcopy, Pcopy) with probability\none, i.e., Pcopy-a.s., and all of the convergence results will be understood to hold in the uniform\nnorm \u2225 \u00b7 \u2225. For instance, Lemma 3 can be strengthen to ( \u02dcUn\n0 , \u02dcV\nn\n0 ) \u21d2 ( \u02dcU0, \u02dcV 0) in ( D2, \u2225 \u00b7 \u2225),\nPcopy \u2212 a.s. as shown in Lemma 4. Also, in Lemma 10 to come, the diffusion-scaled process for\nAn\n0 converges to \u02dcA0 in ( D2, W J1), Pcopy \u2212 a.s., where \u02dcA0 a function of \u02dcU0. In addition, since\nthese newly constructed processes are identical in distribution with their original counterparts, all\nsubsequent results regarding almost sure convergence for the copied processes can be converted into\ncorresponding weak convergence results for the original processes; see more discussion in Theorems 2\nand 3.\nConvergence of the Endogenous processes Let Wn : [0, n] \u2192 RK be the remaining workload\nprocess representing the service requirement of remaining\u2014waiting or being served\u2014jobs predicted\nas class l at t \u2208 [0, n]. Then, Wn\n+(t) = P\nl Wn\nl (t) is the total remaining workload. Let \u02dcWn\n+, \u02dcW\nn\n,\n\u02dc\u03c4 n, and \u02dcN\nn\nbe the diffusion-scaled processes corresponding to Wn\n+, Wn, \u03c4 n, and Nn.\nProposition 1 (Fundamental Convergence Results). Under Assumptions A, B, and H, and any\nwork-conserving p-FCFS feasible policy\n(i) (Invariant Convergence) \u02dcWn\n+ \u2192 \u02dcW+ := \u03d5\n\u0010\n\u02dcV0 \u25e6 \u03bbe + PK\nk=1\npk\n\u00b5k\n\u02dcA0\n\u0011\n, where \u03d5 is the reflection\nmapping as defined in [68, Page 140, (2.5)];\n(ii) (Equivalence of Convergence) For any predicted class l \u2208 [K], lim supn \u2225 \u02dcT\nn\nl \u2225, lim supn \u2225 \u02dcN\nn\nl \u2225,\nlim supn \u2225\u02dc\u03c4n\nl \u2225, and lim supn \u2225 \u02dcW\nn\nl \u2225 are all bounded for any predicted class l \u2208 [K]. Moreover,\nif any of the processes \u02dcT\nn\nl , \u02dcN\nn\nl , \u02dc\u03c4n\nl , or \u02dcW\nn\nl converges, then all of \u02dcT\nn\nl , \u02dcN\nn\nl , \u02dc\u03c4n\nl , and \u02dcW\nn\nl converge.\nProposition 1 extends the classical results of Van Mieghem [63, Proposition 2] by relaxing the\nassumption that true classes are known. When true classes are known, convergence for arrival\nand service processes of true classes ( \u02dcAn and \u02dcSn) can be derived directly via the the Functional\nCentral Limit Theorem (FCLT) [63, Assumption 1]. In comparison, our generalization requires\nnovel analysis approaches to establish convergence of diffusion-scaled arrival and service processes\nof predicted classes ( \u02dcA\nn\nand \u02dcS\nn\n) in Proposition 6. Specifically, we exploit the joint convergence\nresult in Lemma 4 and characterize how misclassifications impact each subprocess. We develop\nnovel connections from the primitives \u02dcZ\nn\nand \u02dcR\nn\nto \u02dcA\nn\nand \u02dcS\nn\n, which involves techniques of\nrandom time change and continuous mapping approach. We give the full proof in Section B.1.\n3.2 Asymptotic lower bound of the scaled delay cost function\nWe are now ready to present the main result of this section, the asymptotic lower bound for the\ncumulative queueing cost in the heavy traffic limit. Our lower bound motivates the design of the\nPc\u00b5-rule in Section 4. For predicted class l \u2208 [K], we let \u03c1l := P\nk\n\u03bbpkqkl\n\u00b5k\n> 0 (Assumption B).\n8",
            "source": "prompt",
            "quality_score": 0.0,
            "metadata": {
              "content_type": [
                "Definition",
                "Result/Finding",
                "Context"
              ],
              "difficulty_level": 4,
              "retrieval_hints": [
                "What are the implications of using a single common arrival process?",
                "How does the heavy traffic regime affect queueing systems?",
                "What are the optimality results of the P c\u00b5-rule?"
              ],
              "summary": "The chunk discusses an analytic framework for multi-class queueing systems under heavy traffic conditions, comparing single and general arrival processes and their implications for optimality of the P c\u00b5-rule."
            }
          },
          {
            "chunk_id": "prompt_8",
            "title": "__auto__",
            "text": "Theorem 2 (Heavy-traffic lower bound). Given a classifier f\u03b8 and a sequence of queueing systems,\nsuppose that Assumptions A, B, C, and H hold. Under any feasible scheduling policies {\u03c0n}, the\nassociated sequence of cumulative costs { \u02dcJn\n\u03c0n(\u00b7; Qn) : n \u2208 N} satisfies\nlim inf\nn\u2192\u221e\n\u02dcJn\n\u03c0n(t; Qn) \u2265 \u02dcJ\u2217(t; Q) :=\nKX\nk=1\nKX\nl=1\nZ t\n0\n\u03bbpkqklCk\n\u0010\u0002\nh\n\u0000 \u02dcW+(s)\n\u0001\u0003\nl\n\u03c1l\n\u0011\nds, \u2200t \u2208 [0, 1], (3.3)\nPcopy-a.s., where h(r) is an optimal solution to the following resource allocation problem\nOpt(r) := min\nx\nKX\nl=1\nKX\nk=1\n\u03bbpkqklCk\n\u0010xl\n\u03c1l\n\u0011\ns.t.\nKX\nl=1\nxl = r, x l \u2265 0, \u2200 l \u2208 [K].\n(3.4)\nMoreover, for the original processes under Pn, under any feasible policies {\u03c0\u2032\nn},\nlim inf\nn\u2192\u221e\nPn[ \u02dcJn\n\u03c0\u2032n\n(t; Qn) > x] \u2265 Pcopy[ \u02dcJ\u2217(t; Q) > x], \u2200 x \u2208 R, \u2200 t \u2208 [0, 1]. (3.5)\nAccording to Proposition 1, \u02dcW+ is solely determined by the exogenous processes \u02dcA0 and \u02dcV0. Con-\nsequently, the lower bound in Theorem 2 is independent of the scheduling policy Tn. Our proof is\ninvolved and deferred to Section C, where we also contrast our analytic approach to classical proof\ntechniques.\n4 Heavy-traffic optimality of the P c\u00b5-rule\nWe are ready to formally derive the P c\u00b5-rule, which is motivated by the convex optimization\nproblem (3.4). We prove heavy traffic optimality of the P c\u00b5-rule by showing that it attains the\nlower bound in Theorem 2. Our result (Theorem 3) extends the classical result in Van Mieghem\n[63, Proposition 7].\nWhile not the main contribution of this work, our analytic framework extend the standard\nheavy traffic analysis techniques [63, 40] in subtle ways as we detail in Sections E.2 and E.3. Even\nwhen specialized to the classical setting of known true classes, our analysis fills gaps in classical\nproofs for the optimality of the Gc\u00b5-rule [63] and D-Gc\u00b5 [40]. The two methods use ages of waiting\njobs, but only establish optimality stated in terms of the sojourn times . To bridge this gap, we\nprovide a rigorous proof in Proposition 13. The proof of the proposition is nontrivial (to us) and\nreveals a necessary condition that was previously unstated in [63]: strong convexity of the cost\nfunctions. Also, our analysis circumvents the stronger assumptions on the cost functions in [40] in\nthe single-server case by directly analyzing the age dynamics. See Sections E.3 for details.\nWe first characterize the limiting cumulative cost of a convergent policy. Let let \u00afAkl be the limit\nof n\u22121An\nkl(n\u00b7) (see Definition 10 for a formal statement). In the following, \u02dcJ\u03c0(t; Q) is dependent on\n\u02dc\u03c4 = {\u02dc\u03c4l}l\u2208[K] through the subscript \u03c0.\nLemma 1 (Convergence of \u02dcJn\n\u03c0n(\u00b7; Qn)). Given a classifier f\u03b8, suppose that Assumption A, B, C,\nand H hold. For feasible policies {\u03c0n} satisfying \u02dc\u03c4n\nl \u2192 \u02dc\u03c4l, \u2200 l \u2208 [K],\nsup\nt\u2208[0,1]\n| \u02dcJn\n\u03c0n(t; Qn) \u2212 \u02dcJ\u03c0(t; Q)| \u21920, (4.1)\n9",
            "source": "prompt",
            "quality_score": 0.0,
            "metadata": {
              "content_type": [
                "Result/Finding"
              ],
              "difficulty_level": 4,
              "retrieval_hints": [
                "What is the heavy-traffic lower bound?",
                "How does the P c\u00b5-rule achieve optimality?",
                "What are the assumptions in Theorem 2?"
              ],
              "summary": "Theorem 2 establishes a heavy-traffic lower bound for queueing systems under certain assumptions, and the P c\u00b5-rule is shown to achieve this bound, extending classical results in the field."
            }
          },
          {
            "chunk_id": "prompt_9",
            "title": "__auto__",
            "text": "where the limiting cumulative cost \u02dcJ\u03c0(t; Q) is defined by\n\u02dcJ\u03c0(t; Q) :=\nKX\nl=1\nKX\nk=1\nZ t\n0\nCk(\u02dc\u03c4l(s))d \u00afAkl(s) =\nKX\nl=1\nKX\nk=1\nZ t\n0\n\u03bbpkqklCk(\u02dc\u03c4l(s)) ds.\nSee Section B.5 for the proof.\nCombining our characterization of the cumulative cost with the lower bound in Theorem 2,\nwe conclude that {\u03c0n} is asymptotically optimal if the following conditions are satisfied: i) the\nscaled sojourn time processes converge, i.e., \u02dc\u03c4n\nl \u2192 \u02dc\u03c4l, \u2200 l \u2208 [K], and ii) the limiting sojourn time\nprocesses satisfy \u02dc\u03c4l(t) = [h( \u02dcW+(t))]l/\u03c1l, \u2200 t \u2208 [0, 1], l \u2208 [K], where h(\u00b7) is an optimal solution to\nthe optimization problem (3.4). Recalling Opt( \u02dcW+(t)), the optimization problem (3.4), is convex\nwith linear constraints, its KKT conditions characterize the optimal workload allocation h. For\npredicted class l, recall its limiting service rate \u00b5l and the Pc\u00b5 cost function (1.3).\nLemma 2 (KKT conditions). {xl}l\u2208[K] is an optimal solution for Opt ( \u02dcW+(t)) if xl > 0, \u2200 l \u2208 [K]\nand is a solution to\n\u00b5lC\u2032\nl\n\u0010xl\n\u03c1l\n\u0011\n= \u00b5mC\u2032\nm\n\u0010xm\n\u03c1m\n\u0011\n, \u2200 l, m\u2208 [K],\nKX\nl=1\nxl = \u02dcW+(t). (4.2)\nWe also show that the KKT conditions (4.2) have a unique solution (Proposition 15, Section C)\nand thus h( \u02dcW+(t)) is well-defined.\nThe cost function Cl(t) (1.3) arises from the KKT conditions of Opt( \u02dcW+(t)) as a weighted\naverage with weights proportional to pkqkl, reflecting how predicted class l is composed of jobs\nfrom different true classes. As pk and qkl rely on the arrival rates and misclassification errors, Cl(t)\ncan be viewed as the exogenous average cost function associated with predicted class l. We aim to\ndevelop a scheduling policy that induces the workload allocation to align with the exogenous cost\nCl(t), in the sense that the conditions (4.2) are satisfied for all t \u2208 [0, 1].\nAccording to Proposition 1, convergence of the sojourn time process \u02dc\u03c4 n \u2192 \u02dc\u03c4 is equivalent to\nconvergence of workload \u02dcW\nn\n\u2192 \u02dcW. Moreover, if \u02dcW\nn\nconverges, then \u02dc\u03c4l = \u02dcWl/\u03c1l, \u2200 l \u2208 [K] (see\nLemma 8 and Lemma 16). Consequently, our goal is to develop a policy that satisfies \u02dc\u03c4 n \u2192 \u02dc\u03c4 and\n\u00b5lC\u2032\nl(\u02dc\u03c4l) = \u00b5mC\u2032\nm(\u02dc\u03c4m), \u2200 l, m\u2208 [K], (4.3)\nin the heavy traffic limit. When the balance (4.3) is achieved, the limiting workload allocation\n\u02dcWl = xl := \u02dc\u03c4l\u03c1l satisfies the KKT conditions (4.2) and both conditions (a) and (b) are met, which\nleads to the policy\u2019s optimality.\nSince the sojourn time\u2014time between job arrival and service completion\u2014is not observable, we\nsubstitute \u03c4 n = {\u03c4n\nl }l\u2208[K] with the observable age processes.\nDefinition 2 (Age Process) . Given a classifier f\u03b8 and feasible policies {\u03c0n}, a predicted class l\nand time t \u2208 [0, n], let an\nl (t) be the waiting time of the oldest job in predicted class l at time t,\nwhere a job being served is defined to be waiting in the system. Let an\nl be the age process of the\npredicted class l \u2208 [K] in system n, and let \u02dcan\nl (t) := n\u22121/2an\nl (nt), t \u2208 [0, 1] and \u02dcan := {\u02dcan\nl }l\u2208[K] be\nthe corresponding diffusion-scaled process and its vector-valued version.\nIf either {\u02dcan\nl }l\u2208[K] or {\u02dc\u03c4n\nl }l\u2208[K] converges, then both of the processes converge to the same limit,\ni.e., \u02dc\u03c4l(t) = \u02dcal(t), \u2200 l \u2208 [K], t\u2208 [0, 1] (see Proposition 12). Thus, we can equivalently reformulate\nthe optimality condition for sojourn time (4.3) into that with observable age processes\n\u00b5lC\u2032\nl(\u02dcal) = \u00b5mC\u2032\nm(\u02dcam), \u2200 l, m\u2208 [K]. (4.4)\n10",
            "source": "prompt",
            "quality_score": 0.0,
            "metadata": {
              "content_type": [
                "Result/Finding"
              ],
              "difficulty_level": 4,
              "retrieval_hints": [
                "What is the heavy-traffic lower bound?",
                "How does the P c\u00b5-rule achieve optimality?",
                "What are the assumptions in Theorem 2?"
              ],
              "summary": "Theorem 2 establishes a heavy-traffic lower bound for queueing systems under certain assumptions, and the P c\u00b5-rule is shown to achieve this bound, extending classical results in the field."
            }
          },
          {
            "chunk_id": "prompt_10",
            "title": "__auto__",
            "text": "Heavy-Traffic Optimality We design the Pc\u00b5-rule in the prelimit systems to achieve (4.4) in the\nheavy traffic limit. The P c\u00b5-rule prioritizes predicted classes with the highest prelimit Pc \u00b5 index,\ndefined as follows.\nDefinition 3 (Pc\u00b5-rule). Given a classifier f\u03b8, for any system n at time nt with t \u2208 [0, 1], the\nPc\u00b5-rule serves the oldest job in the predicted class having the maximum P c\u00b5-rule index, i.e.,\nl \u2208 arg maxm\u2208[K] In\nm(t), with preemption, where\nIn\nl (t) := \u00b5n\nl \u00b7 n1/2(Cn\nl )\u2032(an\nl (nt)), \u2200 t \u2208 [0, 1], (4.5)\nis the P c\u00b5-rule index for predicted class l at time nt in system n, and Cn\nl (t) :=\nP\nk pn\nk qn\nklCn\nk (t)P\nk\u2032 pn\nk\u2032 qn\nk\u2032l\n, t \u2208\n[0, \u221e), l \u2208 [K], is the weighted average of Cn\nk and the prelimit counterpart of Cl(t).\nThe Pc\u00b5-rule is a work-conserving p-FCFS policy by definition, and the n1/2 scaling ensures a\nwell-defined heavy traffic limit. The P c\u00b5-rule naturally allows for preemption: since we consider\njobs being served as waiting in the system, the age process an\nl corresponds to the same job waiting\nin the queue until its service completion. We adopt preemption for analysis purposes. In particular,\nwe can develop a non-preemptive counterpart of the P c\u00b5-rule and show its optimality using the\nsame analytic framework.\nWe are now ready to present our optimality result, which shows that the cumulative queueing\ncost associated with the P c\u00b5-rule, \u02dcJn\nPc\u00b5(\u00b7; Qn), converges to the asymptotic lower bound \u02dcJ\u2217(\u00b7; Q).\nOur proof relies on the fact that the Pc\u00b5-rule is a greedy method minimizing the largest difference of\nthe Pc\u00b5 indices , supt\u2208[0,1] maxl,m\u2208[K] |In\nl (t)\u2212In\nm(t)|, which guarantees (Proposition 13, Section E.1)\nsup\nt\u2208[0,1]\nmax\nl,m\u2208[K]\n|In\nl (t) \u2212 In\nm(t)| \u21920. (4.6)\nWe develop novel analysis techniques to show the convergence (4.6), which requires strong convexity\nof the cost function.\nAssumption D (Cost functions II). The limiting cost Ck is strongly convex for all k \u2208 [K].\nTheorem 3 (Optimality of P c\u00b5-rule). Given a classifier f\u03b8 and a sequence of queueing systems,\nsuppose that Assumptions A, B, C, D, and H hold. Then, \u02dcJn\nPc\u00b5(\u00b7; Qn) \u2192 \u02dcJ\u2217(\u00b7; Q) in (D, \u2225\u00b7\u2225 ) Pcopy-\na.s.. For the original processes under Pn, \u02dcJn\nPc\u00b5(\u00b7; Qn) \u21d2 \u02dcJ\u2217(\u00b7; Q) in (D, J1), and in particular,\nPn[ \u02dcJn(t; Qn) > x] \u2192 Pcopy[ \u02dcJ\u2217(t; Q) > x], \u2200 x \u2208 R, t \u2208 [0, 1].\nOur proof is highly involved so we provide a brief overview in Section E.1 and defer detailed\narguments to Section D and E. Our analytic framework extends upon prior work in subtle ways;\nsee Sections E.2 and E.3 for an in-depth discussion of our proof compared to Van Mieghem [63]\nand Mandelbaum and Stolyar [40].\n5 Empirical demonstration of the P c\u00b5-rule\nWe demonstrate the effectiveness of P c\u00b5-rule on a content moderation problem using real-world\nuser-generated text comments with the data generating process in Section 2. To operate at a\nmassive scale, online platforms use AI models to provide initial toxicity predictions. However,\nthese models are imperfect due to the inherent nonstationarity in the system; for example, they\n11",
            "source": "prompt",
            "quality_score": 0.0,
            "metadata": {
              "content_type": [
                "Result/Finding"
              ],
              "difficulty_level": 4,
              "retrieval_hints": [
                "What is the heavy-traffic lower bound?",
                "How does the P c\u00b5-rule achieve optimality?",
                "What are the assumptions in Theorem 2?"
              ],
              "summary": "Theorem 2 establishes a heavy-traffic lower bound for queueing systems under certain assumptions, and the P c\u00b5-rule is shown to achieve this bound, extending classical results in the field."
            }
          },
          {
            "chunk_id": "prompt_11",
            "title": "__auto__",
            "text": "cannot reliably detect context related to hate speech following a recent terrorist attack. As a result,\nplatforms must rely on human reviewers as the final inspectors [39], especially since they bear the\ncost of mistakenly removing non-violating comments. Our goal is to analyze the downstream impact\nof prediction errors on scheduling decisions in the content moderation queueing system.\nDifferent comments incur varying levels of negative impact on the platform. If not removed in\na timely manner, toxic comments attacking historically marginalized or oppressed groups can have\nparticularly harmful effects. We model this using heterogeneous delay costs based on the level of\ntoxicity and the demographic group targeted by the comment. These factors also affect processing\ntime; for instance, reviewing comments about an ethnic minority group in a foreign nation is more\nchallenging and time-consuming compared to domestic content.\nWe use real user-generated text comments on online articles from the CivilComments dataset [10].\nEach comment has been labeled by at least ten crowdsourcing workers with binary toxicity labels\nand whether it mentions one of the 8 demographic identities: male, female, LGBTQ, Christian,\nMuslim, other religions, Black, White . For simplicity, we focus on comments that mention one and\nonly one of the common groups white, black, male, female, LGBTQ . By crossing them with binary\ntoxicity labels, we derive 10 job classes. We assume the system has exact knowledge of target group\n(using simple rule-based logic), but can only predict the toxicity through an AI model.\nThe toxicity predictor, which can also be viewed as the job class predictor f\u03b8, utilizes the same\nneural network architecture and training approach as described in Koh et al. [32]. To showcase\nthe versatility of our scheduling algorithm regardless of the underlying prediction model, we study\nthree models fine-tuned based on a pre-trained language model (DistilBERT-base-uncased [53]):\nempirical risk minimization (ERM), reweighted ERM that upsamples toxic comments, and a sim-\nple distributionally robust model trained to optimize worst-group performance over target demo-\ngraphic groups (GroupDRO [52]). We observe significant variation in predictive performance across\nthe 10 job classes defined by {toxicity \u00d7 target demographic}. Across the three models (ERM,\nReweighted, GroupDRO), the worst-class accuracy (55%, 68%, 67%) is significantly lower than the\nmean accuracy (88%, 84%, 84%), leading to diverse patterns in the confusion matrix Q.\nQueueing system We assume jobs are assigned to reviewers randomly to ensure fairness, as\nmentioned in Section 1, and view each reviewer as a single-server queueing system. For simplicity,\nwe consider a queueing model operating in a finite time interval [0 , 1] with 10 job classes. New\njobs/comments arrive with i.i.d. exponential interarrival times with rate 100 (uniformly drawn from\nthe test set). Toxic comments have a lower service rate and toxic comments mentioning minority\ngroups have an even lower service rate. The service times follow exponentially distributions that\nsolely depend on the true class label Y : for white, black, male, female, LGBTQ , respectively,\n\u00b5toxic = [100, 30, 110, 25, 15] and \u00b5non-toxic = [150, 150, 150, 150, 150]. (If the service rate depends on\nthe covariate X, e.g., length of the comment, we can create further classes by splitting on relevant\ncovariates.) Our queueing system operates in heavy traffic with overall traffic intensity\u2248 1, aligning\nwith Assumption B. We set higher delay costs for toxic comments and coments targeting historically\nmarginalized or oppressed groups. Specifically, for each demographic group i, we set the delay cost\nas Ci,\u00b7(t) = ci,\u00b7t2/2, with ci,toxic = [10 , 22, 12, 20, 25] and ci,non-toxic = [1 , 1, 1, 1, 1] for toxic and\nnontoxic comments mentioning the aforementioned demographic groups, respectively.\nQueueing policies We compare our proposed P c\u00b5-rule against three scheduling approaches.\nFirst, we consider the Naive G c\u00b5-rule (1.2) that treats the predicted classes as true, and employs\n12",
            "source": "prompt",
            "quality_score": 0.0,
            "metadata": {
              "content_type": [
                "Result/Finding",
                "Context"
              ],
              "difficulty_level": 4,
              "retrieval_hints": [
                "What are the challenges in detecting hate speech?",
                "How do prediction errors affect content moderation?",
                "What is the role of human reviewers in content moderation?"
              ],
              "summary": "The chunk discusses the challenges of detecting hate speech in content moderation and the impact of prediction errors on scheduling decisions, emphasizing the need for human reviewers and the modeling of toxicity based on demographic factors."
            }
          },
          {
            "chunk_id": "prompt_12",
            "title": "__auto__",
            "text": "Oracle Gc\n Our Method Naive Gc\n DRL\n6.0\n6.5\n7.0\n7.5\n8.0\n8.5Cumulative Cost\n0.0 0.2 0.4 0.6 0.8 1.0\nTime\n0.0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7Traffic intensity\nNo Distribution Shift\nwhite\nblack\nmale\nfemale\nLGBTQ\nOracle Gc\n Our Method Naive Gc\n DRL8.5\n9.0\n9.5\n10.0\n10.5\n11.0\n11.5Cumulative Cost\n0.0 0.2 0.4 0.6 0.8 1.0\nTime\n0.0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7Traffic intensity\nDistribution Shift I\nwhite\nblack\nmale\nfemale\nLGBTQ\nOracle Gc\n Our Method Naive Gc\n DRL\n6.5\n7.0\n7.5\n8.0\n8.5\n9.0\n9.5Cumulative Cost\n0.0 0.2 0.4 0.6 0.8 1.0\nTime\n0.0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7Traffic intensity\nDistribution Shift II\nwhite\nblack\nmale\nfemale\nLGBTQ\nFigure 4. We present the cumulative cost for different policies under different testing environments\n(with 2\u00d7 the standard error encapsulated in the orange bracket).\nthe usual Gc\u00b5-rule. For both P c\u00b5-rule and Naive Gc\u00b5-rule, we assume the scheduler has complete\nknowledge of the arrival/service rates of the predicted classes, and use the confusion matrix Q\ncomputed on the validation dataset. Second, we study a black-box approach scheduling using\ndeep reinforcement learning methods (DRL), where we use a Q-learning method to estimate the\nvalue function using a feedforward neural network (deep Q-Networks [42]). Finally, we consider\nthe Oracle Gc \u00b5 policy, which knows the true class as well as associated arrival/service rates. All\npolicies are evaluated in the aforementioned setup, where the scheduler predicts the class label\nusing the AI model f\u03b8.\nTo train our DRL policy, we use Namkoong et al. [44]\u2019s discrete event queueing simulator. We\nuse {(queue length, age of the oldest job) } of all predicted classes as our state space and let the\npredicted classes {1, . . . , K= 10} be the action space. We learn a Q-function parameterized by a\nthree-layer fully connected network, and serve the oldest job in the predicted class that maximizes\nthe Q-function. As instantaneous rewards, we use the sum of cost rates, ci,\u00b7 times the age, for all\nclasses. We employ a similar training procedure as described in [44, Section D.1], and impose a\nlarge penalty to discourage the policy from serving empty queues.\nInstability of reinforcement learning We run the deep Q-learning method with experience\nreplay over 672 distinct sets of hyperparameters and evaluate them based on the average cumula-\ntive queuing cost over 5000 independent sample paths simulated from the testing enviroment. In\nFigure 2, we observe substantial variation in queueing performance across hyperparameters even\nwhen using identical instant reward functions and training/testing enviroments. (We also use the\nsame random seed across training runs.) In particular, the minimum, bottom & top deciles of\ncumulative costs are 7.98, 9.79, and 60.46. Our empirical observation highlights the significant\nengineering effort required to apply DRL approaches to scheduling and replicates previous findings\nin the RL literature (e.g., [29]). In the rest of the experiments, we select the best hyperparameter\nbased on average queueing costs reported in Figure 2.\n13",
            "source": "prompt",
            "quality_score": 0.0,
            "metadata": {
              "content_type": [
                "Result/Finding",
                "Context"
              ],
              "difficulty_level": 4,
              "retrieval_hints": [
                "What are the challenges in detecting hate speech?",
                "How do prediction errors affect content moderation?",
                "What is the role of human reviewers in content moderation?"
              ],
              "summary": "The chunk discusses the challenges of detecting hate speech in content moderation and the impact of prediction errors on scheduling decisions, emphasizing the need for human reviewers and the modeling of toxicity based on demographic factors."
            }
          },
          {
            "chunk_id": "prompt_13",
            "title": "__auto__",
            "text": "Main results In Figure 4, we present cumulative cost averaged over 50 K sample paths. In the\nfirst column of Figure 4, we test scheduling policies under the environment they were designed\nfor: constant arrival/service rates as we described above, with traffic intensity \u2248 1. The P c\u00b5-rule\noutperforms Naive G c\u00b5-rule by \u223c 30% and DRL by 60 \u2212 70% in terms of the cost gap towards\nthe Oracle G c\u00b5-rule. While we expect the DRL policy can be further improved by additional\nengineering (reward shaping, neural network architecture search etc), we view the simplicity of\nour index-based policy as a significant practical advantage. Next, we assess the robustness of\nthe scheduling policies against nonstationarity in the system. We consider two additional testing\nenviroments with heavy traffic conditions that differ from that the policies were designed for. We\nobserve the performance gains of the P c\u00b5-rule hold over nonstationarities in the system.\nThe Pc\u00b5-rule consistently shows superior performance across different scenarios, demonstrating\nits robustness and practical utility in real-world content moderation tasks.\n6 Model selection based on queueing cost\nPredictive models with similar accuracy levels can exhibit significant differences in queueing per-\nformance. By explicitly deriving the optimal queueing cost under misclassification, our theoretical\nresults allow designing AI models with queueing cost as a central concern. Since the P c\u00b5-rule is\noptimal in the heavy traffic limit, the corresponding \u02dcJ\u2217(t; Q) represents the best possible cost when\nemploying the given classifer, f\u03b8, and the relative regret \u02dcJ\u2217(t; Q)/ \u02dcJ\u2217(t; I) serves as an evaluation\nmetric with queueing performance as the central consideration. We empirically demonstrate that\nthis simple model selection criteria based on our theory can provide substantial practical benefits\nin our content moderation simulator.\nFor quadratic cost functions, we can explicitly solve the optimization problem (3.4) and derive\nanalytic expressions for \u02dcJ\u2217(\u00b7; Q) and \u02dcJ\u2217(\u00b7; I).\nAssumption E (Quadratic Cost Functions) . For all k \u2208 [K], the cost functions are defined as\nCn\nk (t) = 1\n2ncn\nkt2, t \u2208 [0, n], n \u2208 N, and Ck(t) = 1\n2ckt2, t \u2208 [0, 1], where {cn\nk}n\u2208N and ck are positive\nconstants such that cn\nk \u2192 ck as n \u2192 \u221e.\nThe following formulas are easy to approximate since the confusion matrix Q can be effectively\nestimated on held-out data.\nProposition 4 (Cumulative Cost Rate of the P c\u00b5-rule). Given a classifier f\u03b8 and a sequence of\nqueueing systems, suppose that Assumptions A, B, E, and H hold. Then, we have that\n\u02dcJ\u2217(t; Q) = 1PK\nm=1(\u03b2m(Q))\u22121 \u00b7 1\n2\nZ t\n0\n\u02dcW+(s)2ds, \u2200 t \u2208 [0, 1],\nwhere \u03b2l(Q) := \u00b5lcl/\u03c1l. Under the Naive G c\u00b5-rule, the scaled cumulative queueing cost \u02dcJn\nNaive(\u00b7; Qn)\nhas the limit\n\u02dcJNaive(t; Q) =\nKX\nl=1\n\u03b2l(Q)\u0010P\nm\n\u03b2l,Naive(Q)\n\u03b2m,Naive(Q)\n\u00112 \u00b7 1\n2\nZ t\n0\n\u02dcW+(s)2ds,\nwhere \u03b2l,Naive(Q) = \u00b5lcl/\u03c1l.\nSee Section F.1 for the proof of Proposition 4. \u02dcJ\u2217(\u00b7; Q) is dominated by small values of \u03b2m(Q), as\nis the case for the limiting workload \u02dcWm under the Pc\u00b5-rule(see Section F.1). Small \u03b2m(Q) implies\n14",
            "source": "prompt",
            "quality_score": 0.0,
            "metadata": {
              "content_type": [
                "Result/Finding",
                "Context"
              ],
              "difficulty_level": 4,
              "retrieval_hints": [
                "What are the challenges in detecting hate speech?",
                "How do prediction errors affect content moderation?",
                "What is the role of human reviewers in content moderation?"
              ],
              "summary": "The chunk discusses the challenges of detecting hate speech in content moderation and the impact of prediction errors on scheduling decisions, emphasizing the need for human reviewers and the modeling of toxicity based on demographic factors."
            }
          },
          {
            "chunk_id": "prompt_14",
            "title": "__auto__",
            "text": "50% 60% 70% 80% 90% 100%\nAccuracy\n100%\n110%\n120%\n130%\n140%\n150%Theoretical Criteria\nMax Theoretical Criteria\nMin Theoretical Criteria\n(a) High arrival rate of positive\nclass\n50% 60% 70% 80% 90% 100%\nAccuracy\n100%\n120%\n140%\n160%\n180%\n200%\n220%Theoretical Criteria\nMax Theoretical Criteria\nMin Theoretical Criteria\n(b) Low arrival rate of positive\nclass\n75% 80% 85%\nAccuracy\n0%\n20%\n40%\n60%\n80%\n100%\n120%Theoretical Gap\nHigh Arrival Rate of Positive Class\nLow Arrival Rate of Positive Class\n(c) Theoretical gap under\ndifferent accuracy levels\nFigure 5. Maximum and minimum relative regret \u02dcJ(t; Q)/ \u02dcJ\u2217(t; I) in the heavy traffic limit (\u201cthe-\noretical criteria\u201d) across accuracy levels. Each green dot corresponds to theoretical criteria and\naccuracy of a simulated confusion matrix Q.\neither high intensity or low priority of the predicted class, meaning the impact of f\u03b8 is determined\nby the \u201cimbalance\u201d of {\u03b2m(Q) : m \u2208 [K]} between the predicted classes.\nIn what follows, we heavily rely on the independence between \u02dcW+ and misclassification errors\nfrom Proposition 1.\nModel Multiplicity It is well known that models of equal prediction accuracy can perform\ndifferently in downstream decision-making tasks [17, 8]. This phenomenon, known as model multi-\nplicity [8], is particularly important in our setting, since prediction errors over different classes can\nhave disproportionate impacts on downstream queueing performance. We consider a two-class toy\nexample to showcase that models with high accuracy levels can still exhibit significant differences\nin queueing performances.\nWe simplify the setting from Section 5 to two classes: toxic comments (positive class, class 1),\nand non-toxic comments (negative class, class 2), where delay costs are set as Ck(t) = ckt2/2 with\nc1 = 15, c2 = 1. We examine two settings: (i) high arrival rate of the positive class, with [ \u03bb1, \u03bb2] =\n[25, 100], [\u00b51, \u00b52] = [50, 200]; and (ii) low arrival rate of the positive class, with [ \u03bb1, \u03bb2] = [1, 100],\n[\u00b51, \u00b52] = [2 , 200]. The arrival and service rates are chosen to achieve an overall traffic intensity\nclose to 1 and approximate heavy traffic limits.\nGiven fixed costs, arrival rates, and service rates, we can explcitly quantify the relative regret\n\u02dcJ\u2217(t; Q)/ \u02dcJ\u2217(t; I) for different classifiers through the confusion matrix Q, considering the maximum\nand minimum possible relative regret given a fixed accuracy level. In Figure 5(a)-(b), we study\nsystems with two different arrival rates. We randomly generate 500 confusion matrix Q (q11, q22\niid\u223c\nUnif[0, 1]) and plot the resulting accuracy level and theoretical criteria in green dots. The variation\nin relative regret is substantial in both settings, and in Figure 5(c), even at high accuracy levels\n(75%, 80%, 85%), the relative regret can vary by 30% to 80%. This indicates that model multiplicity\nsignificantly affects queuing performance, which highlights the potential of using our evaluation\nmetric in guiding model selection.\nComparison to Traditional Model Selection Criterias Next, we explore the effectiveness of\nour model selection criterion by comparing it with traditional criteria that focus on predictive per-\nformance, such as accuracy, precision, recall, or their weighted combinations. In particular, we com-\npare our evaluation metric \u02dcJ\u2217(t; Q)/ \u02dcJ\u2217(t; I) against two straightforward criteria: (i) cost-weighted\naccuracy, defined as c1q11+c2q22\nc1+c2\n, and (ii) frequency-weighted accuracy, defined as \u03bb1q11+\u03bb2q22\n\u03bb1+\u03bb2\n. As we\n15",
            "source": "prompt",
            "quality_score": 0.0,
            "metadata": {
              "content_type": [
                "Result/Finding",
                "Context"
              ],
              "difficulty_level": 4,
              "retrieval_hints": [
                "What are the challenges in detecting hate speech?",
                "How do prediction errors affect content moderation?",
                "What is the role of human reviewers in content moderation?"
              ],
              "summary": "The chunk discusses the challenges of detecting hate speech in content moderation and the impact of prediction errors on scheduling decisions, emphasizing the need for human reviewers and the modeling of toxicity based on demographic factors."
            }
          },
          {
            "chunk_id": "prompt_15",
            "title": "__auto__",
            "text": "Simulated Criteria Theoretical Criteria\n100%\n101%\n102%\n103%\n104%\n105%\n106%\nSimulated Criteria\nHigh Arrival Rate of Positive Class\nOur Method\nCost-Weighted\nFreq-Weighted\n100%\n102%\n104%\n106%\n108%\n110%\nTheoretical Criteria\nSimulated Criteria Theoretical Criteria\n100%\n101%\n102%\n103%\n104%\nSimulated Criteria\nLow Arrival Rate of Positive Class\nOur Method\nCost-Weighted\nFreq-Weighted\n100%\n105%\n110%\n115%\n120%\n125%\n130%\nTheoretical Criteria\n(a) threshold selection for a fixed classifer\nSimulated Criteria Theoretical Criteria\n100%\n101%\n102%\n103%\n104%\n105%\n106%\n107%\nSimulated Criteria\nHigh Arrival Rate of Positive Class\nOur Method\nCost-Weighted\nFreq-Weighted\n100%\n102%\n104%\n106%\n108%\n110%\n112%\n114%\nTheoretical Criteria\nSimulated Criteria Theoretical Criteria\n100%\n101%\n102%\n103%\n104%\nSimulated Criteria\nLow Arrival Rate of Positive Class\nOur Method\nCost-Weighted\nFreq-Weighted\n100%\n110%\n120%\n130%\n140%\n150%\nTheoretical Criteria (b) model training\nFigure 6. Our model selection approach vs. traditional weighted-accuracy-based methods. For\nthresholds or models optimized for each criteria, we present normalized simulated queueing cost\n(simulated critera) and relative regret in the heavy traffic limit (theoretical criteria). Our method\nreduces cumulative queueing costs; traditional methods exhibit varying rankings across settings.\nobserve below, model rankings under the traditional methods change across arrival rates, indicating\ntheir unreliability in queueing tasks.\nWe consider two different approaches for utilizing our metric: (i) setting the threshold for\npredicting the positive class for a fixed classifier, and (ii) model training. For threshold selection,\nwe adopt the two environments from the above and generate covariatesX for positive and negative\nclasses from independent normal distributions, N(0, 0.5) and N(1, 0.5), respectively. We focus on\nf\u03b8(X) := I(X \u2265 \u03b8), \u2200 \u03b8 \u2208 [0, 1], study thresholds selected by our method, cost-weighted accuracy,\nand frequency-weighted accuracy, and present corresponding simulated queueing cost under the\nPc\u00b5-rule in Figure 6 (a). (We use line search to to optimize each critera.) In Figure 6, we show the\naverage simulated queueing costs (simulated criteria) at T = 1 over 3 \u00d7 106 independent sample\npaths using solid bars, with 2\u00d7 the standard error encapsulated in the orange brackets. The shaded\nbar depicts the relative regret (theoretical criteria) corresponding to the selected thresholds in the\nheavy traffic limit. To facilitate comparison with our method, we normalize the theoretical and\nsimulated criteria by the relative regret and the average simulated cumulative cost associated with\nour method, respectively.\nWe also study model training using relative regret. Specifically, we consider the 2 dimensional\nlogistic regression problem, where covariates X \u2208 R2 for positive and negative classes are generated\nfrom N([1, 0], [[1, \u22120.25], [\u22120.25, 1]]) and N([\u22121, 0], [[1, 0.75], [0.75, 1]]), respectively. For simplicity,\nwe fix the threshold at 0.5 and focus on classifiers defined as:fa,b(X) := I([1+exp{\u2212(a\u22a4X+b)}]\u22121 \u2265\n16",
            "source": "prompt",
            "quality_score": 0.0,
            "metadata": {
              "content_type": [
                "Result/Finding",
                "Context"
              ],
              "difficulty_level": 4,
              "retrieval_hints": [
                "What are the challenges in detecting hate speech?",
                "How do prediction errors affect content moderation?",
                "What is the role of human reviewers in content moderation?"
              ],
              "summary": "The chunk discusses the challenges of detecting hate speech in content moderation and the impact of prediction errors on scheduling decisions, emphasizing the need for human reviewers and the modeling of toxicity based on demographic factors."
            }
          },
          {
            "chunk_id": "prompt_16",
            "title": "__auto__",
            "text": "Simulated Criteria Theoretical Criteria\n100%\n105%\n110%\n115%\n120%\nSimulated Criteria\nOracle Gc\nOur Method, threshold = 0.05\nOur Method, threshold = 0.5\nOur Method, threshold = 0.95\nNaive Gc\n100%\n120%\n140%\n160%\n180%\nTheoretical Criteria\n(a) Threshold selection\nSimulated Criteria Theoretical Criteria\n100%\n105%\n110%\n115%\n120%\nSimulated Criteria\nOracle Gc\nOur Method, GroupDRO\nOur Method, Reweighted\nOur Method, ERM\nNaive Gc\n100%\n120%\n140%\n160%\n180%\nTheoretical Criteria (b) Model selection\nFigure 7. For different policies, we present our proposed model selection criteria (theoretical criteria)\nbased on the relative regret \u02dcJ(t; Q)/ \u02dcJ\u2217(t; I) in the heavy traffic limit. To test its validity, we plot the\nsimulated/acutal counterpart (simulated criteria) in the left. The relative ranking of policies based\non our theoretical criteria exactly matches that given by the simulated quantities.\n0.5), \u2200 a \u2208 R2, b\u2208 R. Due to the simplicity of the toy problem, we can directly minimize relative\nregret by grid search.\nWe compare our method with traditional methods using weighted cross-entropy loss as the\ntraining objective. Given weight w = [w1, w2], predicted logits pred, and true labels Y, the loss\nfunction is defined as \u2113w(pred, Y) := \u2212P\ni:Yi=1 w1 log(predi) \u2212 P\nj:Yj=2 w2 log(1 \u2212 predj). We\nstudy two straightforward methods: (i) cost-weighted loss, where w1 = c1/\u03bb1, w2 = c2/\u03bb2, and (ii)\nfrequency-weighted loss, where w1 = 1, w2 = 1. For both methods, we use the Adam optimizer\nwith a learning rate of 0 .1, a batch size of 512, and train the model over 5 epochs using 10 5 datas\npoints. We present the normalized theoretical and simulated criteria in Figure 6 (b).\nAs shown in Figure 6, in this simplified toy example, our method still outperforms traditional\nmethods by \u223c 1 \u2212 4% in cumulative queueing costs. This demonstrates the effectiveness of our\nevaluation metric when queueing performance is the major concern. However, we note that there\nare discrepancies between the theoretical and simulated criteria in Figure 6 due to deviations from\nthe heavy traffic limit. While we conduct a brute force grid search over classifier parameters in this\nsimple setting, developing a practical and scalable training algorithm in more complex scenarios\nis an important direction of future work. As an interim solution, we can select between several\ncandidate classifiers as we present next.\nNumerical Experiments on CivilComments Dataset To further understand the validity of\nour proposed model selection criteria, we revisit the fully general testing enviroment from Section 5.\nWe study the performance of the P c\u00b5-rule, Oracle Gc\u00b5, and Naive Gc\u00b5-rule, using the cumulative\nqueueing cost at T = 1 across 5\u00d7104 independent sample paths. As the queueing cost of the Oracle\nGc\u00b5-rule converges to \u02dcJ\u2217(t; I), we normalize all simulated cumulative cost over each sample path\nby the average cumulative cost of the Oracle Gc \u00b5-rule. We refer to this quantity as \u201csimulated\u201d\nrelative regret.\nWe demonstrate the utility of selecting and evaluating classifiers based on\u02dcJ\u2217(t, Q)/ \u02dcJ\u2217(t, I) using\ntwo tasks: (i) threshold selection for a fixed classifier, and (ii) model selection for a given collection\nof classifiers. In both cases, the ranking according to our proposed criteria aligns with simulated\n17",
            "source": "prompt",
            "quality_score": 0.0,
            "metadata": {
              "content_type": [
                "Result/Finding",
                "Context"
              ],
              "difficulty_level": 4,
              "retrieval_hints": [
                "What are the challenges in detecting hate speech?",
                "How do prediction errors affect content moderation?",
                "What is the role of human reviewers in content moderation?"
              ],
              "summary": "The chunk discusses the challenges of detecting hate speech in content moderation and the impact of prediction errors on scheduling decisions, emphasizing the need for human reviewers and the modeling of toxicity based on demographic factors."
            }
          },
          {
            "chunk_id": "prompt_17",
            "title": "__auto__",
            "text": "counterparts, illustrating how an analytic characterization of queueing cost can provide an effective\ncomparison between ML models without extensive queueing simulation. For threshold selection,\nwe consider the P c\u00b5-rule using the aforementioned ERM predictor and compare its queueing per-\nformance with thresholds being [0 .05, 0.5, 0.95], positioned from left to right in Figure 7 (a). In\nFigure 7, we present simulated relative regret using solid bars, with 2 \u00d7 the standard error encap-\nsulated in the orange brackets. The shaded bar depicts our proposed model selection (theoretical\ncriteria) given by the relative regret in the heavy traffic limit. For model selection, we consider\nthe aforementioned three different classifiers: GroupDRO, Reweighted, and ERM with thresholds\n0.05, 0.05, and 0.95. (These thresholds are chosen to showcase diverse queueing performances). In\nFigure 7 (b), we evaluate the Pc\u00b5-rule using these models. We also compare P c\u00b5-rule to the Naive\nGc\u00b5-rule, where the classifier is fixed to the aforementeioned ERM classifier with threshold 0.5 in\nFigure 7 (a)(b).\nWe demonstrated that our proposed evaluation metric \u02dcJ\u2217(t, Q)/ \u02dcJ\u2217(t, I) effectively guides model\nselection by focusing on queueing performance. This approach ensures that the selected models\noptimize overall system performance, not just predictive accuracy, providing a robust basis for\ndesigning and selecting AI models in service systems.\n7 Design of an AI-based triage system\nOur characterization of queueing cost can be further utilized to design comprehensive job process-\ning systems assisted by AI models. Motivated by content moderation systems on social media\nplatforms [11, 64, 62], we study a triage system where an initial AI model filters out clear-cut cases,\nafter which the queueing system serves remaining jobs (Figure 1). Standard triage systems in on-\nline platforms determine the filtering level using simple metrics such as maximizing recall subject\nto a fixed high precision level (e.g., [11]). These designs [2, 54, 67, 1] lead to suboptimal system\nperformance as they do not consider the downstream operational cost such as hiring cost of human\nreviewers and queueing costs.\nIn this section, we provide a novel framework for designing AI-assisted triage systems that\njointly optimize the filtering and queueing systems, taking into account all four types of costs:\nfiltering costs, hiring costs, misclassification costs, and queueing congestion costs. Our objective\ncan be easily estimated using a small set of validation data and a simple simulation of a (reflected)\nBrownian motion, allowing us to find the optimal filtering level through methods like line search.\nIn Section 7.4, we conduct numerical experiments to demonstrate effectiveness of this approach.\nWe find that prediction-based metrics, which is a norm in practice, may align with the total cost\nwhen either filtering cost or hiring cost dominates, but it fails to do so in more complicated settings\nwith trade-offs between different types of costs. Our method avoids computationally expensive\nqueueing simulations, and consistently identifies the optimal filtering and staffing levels in all of\nthese scenarios by simply simulating a (reflected) Brownian motion.\n7.1 Model of the AI-based triage system\nWe consider a sequence of single-stream incoming jobs that arrive at the triage system. We assume\nthe nth system operates on a finite time horizon [0 , n], starts empty, has i.i.d. interarrival times\nwith an arrival rate of \u039b n. With a slight abuse of notation, we let un\ni be the interarrival time of\nthe ith job in system n, Un\n0 (t) be the arrival time of the \u230at\u230bth job in system n, and An\n0 (t) be the\n18",
            "source": "prompt",
            "quality_score": 0.0,
            "metadata": {
              "content_type": [
                "Result/Finding",
                "Context"
              ],
              "difficulty_level": 4,
              "retrieval_hints": [
                "What are the challenges in detecting hate speech?",
                "How do prediction errors affect content moderation?",
                "What is the role of human reviewers in content moderation?"
              ],
              "summary": "The chunk discusses the challenges of detecting hate speech in content moderation and the impact of prediction errors on scheduling decisions, emphasizing the need for human reviewers and the modeling of toxicity based on demographic factors."
            }
          },
          {
            "chunk_id": "prompt_18",
            "title": "__auto__",
            "text": "total number of jobs arriving in the triage system n up to time t. For simplicity, we consider a\ntwo-class setting, with class 1 representing toxic content and class 2 representing non-toxic content.\nFor each job, a tuple of (observed features, true class label, service time), denoted as ( Xn\ni , Yn\ni , vn\ni ),\nis generated identically and indepedently of its arrival time un\ni . Similar to our model in Section 2,\nvn\ni and Xn\ni are conditionally independent given Y n\ni .\nWe use the binary classifier f\u03b8 for the filtering procedure across all systems n. With a slight\nabuse of notation, let f\u03b8(\u00b7) \u2208 [0, 1] now be the toxicity score instead of the predicted class label.\nSpecifically, the classifier outputs f\u03b8(Xn\ni ) \u2208 [0, 1] based on the observed features Xn\ni for each job\ni. The system designer is tasked with choosing a threshold zFL that affects the (triage) filtering\nlevel: an arriving job in system n can pass the filtering system and enter the queueing system if\nand only if f\u03b8(Xn\ni ) \u2265 zFL.1 Content that are filtered out are not reviewed and can remain on the\nplatform. A higher filtering level zFL filters more jobs out, resulting in higher false negative rate\n(more filtering and misclassification costs), fewer human reviewers required (lower hiring cost), and\na complex effect on the downstream queueing cost.\nEach job that passes the filtering system is subsequently sent to human reviewers (queueing\nsystem). Given the filtering level zFL, we use the same number of reviewers \u0393( zFL) across all\nsystems, where \u0393( zFL) is a predetermined decision variable, fixed in advance and not subject to\nrandomness. We assume that for each system n, all reviewers have the same service rate for class\nk jobs, i.e., \u00b5n\nk,r = \u00b5n\nk, \u2200 k \u2208 {1, 2} for each reviewer r \u2208 [\u0393(zFL)]. To ensure workload equality\nand fairness among reviewers, we assume jobs passing through the filtering system are assigned\nto one and only one human reviewer with equal probability 1 /\u0393(zFL), independently of any other\nrandom objects. Each human reviewer operates their own single-server queueing system. The jobs\nallocated to the rth reviewer corresponds to their arrival processes, denoted as An\nps,r(t), which are\nsplited from the common arrival process after filtering, denoted as An\nps,0(t). For the jth job passing\nthrough the filtering system, let Bn\nj := (Bn\nj1, . . . , Bn\nj\u0393(zFL)) be the one-hot encoded representation\nof the reviewer it is assigned to. Then, An\nps,r(t) := PAn\nps,0(t)\nj=1 Bjr, \u2200 t \u2208 [0, n], r\u2208 [\u0393(zFL)].\nFor simplicity, we assume all reviewers utilizef\u03b8 to predict the class labels of incoming jobs. The\nsystem designer must decide another threshold zTX \u2265 zFL that affects the toxicity classification. In\nparticular, for the sth job assigned to reviewer r, it is predicted to be toxic (class 1), i.e., Y n\ns1,r = 1,\nif and only if f\u03b8(Xn\ns,r) \u2265 zTX. We assume all human reviewers adopt the same scheduling policy.\nSimilar to our model in Section 2, reviewers use the predicted class Yn\ns,r and feasible scheduling\npolicies must satisfy a variant of Definition 1.\nThroughout this section, we use i when counting jobs that arrive at the triage system; j for jobs\nthat pass the filtering system and arrive at the queueing system; s for jobs assigned to a human\nreviewer; and r for human reviewers (servers). For a stochastic process An\nps,0(t), the subscript ps\nindicates processes associated with jobs passing through the filter and arriving at the queueing\nsystem. We use the subscript 0 to indicate the total arrival process and r to indicate processes\nassociated with the reviewer r. We denote our decision variables ( zFL, zTX) by z. We summarize\nour assumptions for the AI-based triage system below.\nAssumption F (Data generating processes for the AI-based triage system). For any system n \u2208 N,\n(i) {(un\ni , vn\ni , Xn\ni , Yn\ni ) : i \u2208 N} is a sequence of i.i.d. random vectors; (ii) {un\ni : i \u2208 N} and\n1For simplicity, we only consider filtering out clearly safe content in this section, though in practice, the system\ndesigner can choose another threshold to filter out clearly toxic contents from the human review process and directly\ntake further actions.\n19",
            "source": "prompt",
            "quality_score": 0.0,
            "metadata": {
              "content_type": [
                "Procedure",
                "Result/Finding"
              ],
              "difficulty_level": 3,
              "retrieval_hints": [
                "What is the role of the binary classifier in the triage system?",
                "How does the filtering level affect job processing?",
                "What are the implications of a higher filtering level?"
              ],
              "summary": "This chunk discusses the filtering procedure in a triage system for classifying jobs as toxic or non-toxic, highlighting the role of a binary classifier and the implications of varying the filtering level."
            }
          },
          {
            "chunk_id": "prompt_19",
            "title": "__auto__",
            "text": "{(vn\ni , Xn\ni , Yn\ni ) : i \u2208 N} are independent; (iii) for any i \u2208 N, vn\ni and Xn\ni are conditionally independent\ngiven Y n\ni ; (iv) {Bn\nj : j \u2208 N} is a sequence of i.i.d. random vectors; (v) {Bn\nj : j \u2208 N} is independent\nof {un\ni : i \u2208 N} and {(vn\ni , Xn\ni , Yn\ni ) : i \u2208 N}.\nThe data generating process for the AI-based triage system is crucial to our analysis, because it\nenables the reduction of the scheduling problem for all reviewers to stochastically identical single-\nserver scheduling problems across the reviewers. Assumption F (i), (iv) and (v) ensure that each\nreviewer r has a single stream of jobs with i.i.d. tuples {(vn\ns,r, Xn\ns,r, Yn\ns,r) : s \u2208 N}. More importantly,\nthe tuples associated with reviewer r become independent of those of any other reviewers. This\nleads to the joint convergence of the diffusion-scaled processes defined by {(vn\ns,r, Xn\ns,r, Yn\ns,r) : s \u2208 N}\nacross all reviewers r \u2208 [\u0393(zFL)]. In addition, similar to Section 2, Assumption F (i), (iv), and\n(v) allow us to disentangle the interarrival times {un\ns,r : s \u2208 N} from the filtering process, service\nprocesses, and the covariates, ensuring the joint convergence of the diffusion-scaled processes defined\nby {un\ns,r : s \u2208 N} across the reviewers r \u2208 [\u0393(zFL)]. Since Assumption F (ii) and (v) imply\nindependence between {(vn\ns,r, Xn\ns,r, Yn\ns,r) : s \u2208 N}r\u2208[\u0393(zFL)] and {un\ns,r : s \u2208 N}r\u2208[\u0393(zFL)], we can derive\nthe desired joint convergence (Lemma 30) and apply our sample path analysis at the reviewer level .\nFor further discussion, see Appendix G.1.\n7.2 Heavy traffic conditions for the AI-based triage system\nIn the sequel, we assume the triage system operates under heavy traffic conditions and analyze the\nlimiting system. Denote the conditional probability of a class k job passing through the level z as\ngn\nk (z) := Pn[f\u03b8(Xn\ni ) \u2265 z | Y n\nik = 1], \u2200 z \u2208 [0, 1], k \u2208 {1, 2}. Similar to Assumption B, we adopt the\nfollowing heavy traffic conditions for the AI-based triage system.\nAssumption G (Heavy traffic conditions for AI-based triage system) . Given a classifier f\u03b8 and a\nsequence of triage systems, we assume that there exist \u039b, \u00b5k, and gk : [0, 1] \u2192 [0, 1] such that (i)\nfor any filtering level zFL \u2208 [0, 1] and class k \u2208 {1, 2}, we have that\nn1/2(\u039bn \u2212 \u039b) \u2192 0, n 1/2(\u00b5n\nk \u2212 \u00b5k) \u2192 0, n 1/2(gn\nk (zFL) \u2212 gk(zFL)) \u2192 0;\n(ii) given the filtering level zFL, the number of hired reviewers satisfies \u0393(zFL) = \u039b P2\nk=1\npkgk(zFL)\n\u00b5k\n.\nWe adopt Assumption G to ensure that each reviewer aligns with Assumption B. Specifically,\naccording to Assumption G (i) and [68, Theorem 9.5.1], we can show that for each reviewer r,\ntheir class prevalence pn\nk,r(zFL) := Pn[Y n\nsk,r = 1 | f\u03b8(Xn\ns,r) \u2265 zFL] and confusion matrix qn\nkl,r(z) :=\nPn[Y n\nsl,r = 1 | f\u03b8(Xn\ns,r) \u2265 zFL, Yn\nsk,r = 1] all converge to their limits pk(zFL) and qkl(z) at the rate\nof o(n\u22121/2) (Lemma 32). We use Qn(z) and Q(z) to denote the prelimit and limiting confusion\nmatrix for each reviewer. In addition, by Assumption G (ii), we have that\nn1/2\nh \u039bn\n\u0393(zFL)\n2X\nk=1\npn\nkgn\nk (zFL)\n\u00b5n\nk\n\u2212 1\ni\n\u2192 0, (7.1)\nwhich indicates that each reviewer operates under heavy traffic conditions and matches (2.2).\nAccording to Assumption G (ii), when all reviewers operates under heavy traffic conditions, the\nnumber of reviewers is solely determined by limiting traffic indensity and the filtering level zFL.\nThus, our decision variables are filtering level zFL and toxicity level zTX, with the number of\nreviewers determined accordingly. Intuitively, as the filtering levelzFL increases, the traffic intensity\ndecreases and the number of reviewers hired also decreases.\n20",
            "source": "prompt",
            "quality_score": 0.0,
            "metadata": {
              "content_type": [
                "Procedure",
                "Result/Finding"
              ],
              "difficulty_level": 3,
              "retrieval_hints": [
                "What is the role of the binary classifier in the triage system?",
                "How does the filtering level affect job processing?",
                "What are the implications of a higher filtering level?"
              ],
              "summary": "This chunk discusses the filtering procedure in a triage system for classifying jobs as toxic or non-toxic, highlighting the role of a binary classifier and the implications of varying the filtering level."
            }
          },
          {
            "chunk_id": "prompt_20",
            "title": "__auto__",
            "text": "Starting from Assumptions F and G, we first establish the joint convergence result in Lemma 30.\nAs Assumptions F and G are compatible with Assumptions A and B, we derive a common proba-\nbility space Pcopy in Lemma 31 and apply the previous results on single-server queueing systems to\neach reviewer. This allows us to establish the limiting total cost of the triage system in Section 7.3.\n7.3 Total Cost of the AI-based triage system\nMotivated by content moderation problems, we divide the total cost into four components: filtering\ncost, hiring cost, misclassification cost, and queueing cost. Since the P c\u00b5-rule is optimal for each\nsingle-server queueing system under heavy traffic conditions, we can explicitly quantify the best\npossible queueing cost of the limiting system under quadratic cost assumption (Assumption E).\nThis enables us to determine the limiting total cost and minimize it to find the optimal filtering\nand classification levels (zFL, zTX) for a fixed classifier f\u03b8. In the following, we first define each cost\ncomponent and then establish the limiting total cost in Theorem 5.\nDefinition 4 (Total cost of the AI-based triage system) . Given a classifier f\u03b8, filtering level zFL,\ntoxicity level zTX, the number of hired reviewers \u0393(zFL), and a sequence of AI-based triage system,\nfor a sequence of feasible policies {\u03c0n}, define the cost incurred as the following.\n(i) (Filtering cost) For each job that is filtered out, the unit costs for toxic and non-toxic jobs are\ncFL,1 > 0 and cFL,2 < 0. The total filtering cost up to time t \u2208 [0, n] is\nGn(t; zFL) := cFL,1\nAn\n0 (t)X\ni=1\nI(f\u03b8(Xn\ni ) < zFL) \u00b7 Y n\ni1 + cFL,2\nAn\n0 (t)X\ni=1\nI(f\u03b8(Xn\ni ) < zFL) \u00b7 Y n\ni2,\nand \u02dcGn(t; zFL) := n\u22121Gn(nt; zFL) is the scaled filtering cost.\n(ii) (Hiring Cost) Each reviewer costs cr > 0 per unit of time.\n(iii) (Misclassification Cost) The per-job cost of false positive, false negative, true positive, or\ntrue negative are cfp, cfn, ctp, ctn, respectively. The total misclassification cost up to time t is\nMn(z, t), and its scaled counterpart is \u02dcMn(t; z) := n\u22121Mn(nt; z).\n(iv) (Queueing Cost) For each system n and reviewer r, Jn\n\u03c0n,r(t; Qn(z)) is the cumulative queue-\ning cost as defined in Section 3.1, and \u02dcJn\n\u03c0n,r(t; Qn(z)) := n\u22121Jn\n\u03c0n,r(nt; Qn(z)) is its scaled\ncounterpart.\nThe total cost incurred up to time t is defined by\nFn\n\u03c0n(t; z) = Gn(t; zFL)| {z }\nfiltering\n+ cr\u0393(zFL)t| {z }\nhiring\n+ Mn(t; z)| {z }\nmisclassification\n+\n\u0393(zFL)X\nr=1\nJn\n\u03c0n,r(t; Qn(z))\n| {z }\nqueueing\n, \u2200 t \u2208 [0, n],\nand \u02dcFn\n\u03c0n(t; z) := n\u22121Fn\n\u03c0n(nt; z) is its scaled counterpart.\nFor any filtering level zFL and toxicity level zTX, we can easily establish the optimal total cost\nof the AI-based triage system under heavy traffic limits by extending Proposition 6, Theorem 3,\nand Proposition 4. Such optimal cost can be achieved by applying the P c\u00b5-rule to all reviewers as\nshown in (7.2).\n21",
            "source": "prompt",
            "quality_score": 0.0,
            "metadata": {
              "content_type": [
                "Procedure",
                "Result/Finding"
              ],
              "difficulty_level": 3,
              "retrieval_hints": [
                "What is the role of the binary classifier in the triage system?",
                "How does the filtering level affect job processing?",
                "What are the implications of a higher filtering level?"
              ],
              "summary": "This chunk discusses the filtering procedure in a triage system for classifying jobs as toxic or non-toxic, highlighting the role of a binary classifier and the implications of varying the filtering level."
            }
          },
          {
            "chunk_id": "prompt_21",
            "title": "__auto__",
            "text": "Theorem 5 (Total cost the AI-based triage system) . Given a classifier f\u03b8, filtering level zFL,\ntoxicity level zTX, the number of hired reviewers \u0393(zFL), and a sequence of AI-based triage system,\nsuppose that Assumptions E, F, G, and H hold. There exists a common probability space Pcopy such\nthat\n(i) (Lower bound) under any feasible policies {\u03c0n}, the associated total cost \u02dcFn\n\u03c0n(t; z) satisfies\nlim inf\nn\n\u02dcFn\n\u03c0n(t; z) \u2265 \u02dcF\u2217(t; z), \u2200 t \u2208 [0, 1] Pcopy \u2212a.s.. For the original processes under Pn, under\nany feasible policies {\u03c0\u2032\nn},\nlim inf\nn\nPn[ \u02dcFn\n\u03c0\u2032n\n(t; z) > x] \u2265 Pcopy[ \u02dcF\u2217(t; z) > x], \u2200x \u2208 R, t\u2208 [0, 1];\n(ii) (Optimality) under the P c\u00b5-rule, we have that \u02dcFn\nPc\u00b5(\u00b7; z) \u2192 \u02dcF\u2217(\u00b7; z) in (D, \u2225 \u00b7 \u2225), Pcopy \u2212\na.s.. For the original processes under Pn, \u02dcFn\nPc\u00b5(\u00b7; z) \u21d2 \u02dcF\u2217(\u00b7; z) in (D, J1), and in particular,\nPn[ \u02dcFn\nPc\u00b5(t; z) > x] \u2192 Pcopy[ \u02dcF\u2217(t; z) > x], \u2200 x \u2208 R, t\u2208 [0, 1].\nHere, the optimal total cost \u02dcF\u2217(t; z) is defined as\n\u02dcF\u2217(t; z) := \u02dcG\u2217(t; zFL) + cr\u0393(zFL)t + \u02dcM\u2217(t; z) +\n\u0393(zFL)X\nr=1\n\u02dcJ\u2217\nr (t; Q(z)), (7.2)\nwhere\n\u02dcG\u2217(t; zFL) = \u039bt \u00b7 [cFL,1p1(1 \u2212 g1(zFL)) + cFL,2p2(1 \u2212 g2(zFL))],\n\u02dcM\u2217(t; z) = \u039bt \u00b7\n\u0002\np1g1(zFL)[ctpq11(z) + cfnq12(z)] + p2g2(zFL)[cfpq21(z) + ctnq22(z)]\n\u0003\n\u02dcJ\u2217\nr (t; Q(z)) = \u03b21(Q(z))\u03b22(Q(z))\n2\n\u0002\n\u03b21(Q(z)) + \u03b22(Q(z))\n\u0003\nZ t\n0\n\u02dcW+(s; z, r)2ds,\nfor all t \u2208 [0, 1], and \u02dcW+(t; z, r) is the limiting remaining total workload process of reviewer r as\ndefined in Lemma 33.\nAccording to Theorem 5, we can minimize (7.2) to find the optimal filtering and toxicity levels\n(zFL, zTX) for a given classifier f\u03b8. In particular, (7.2) depends solely on limiting exogenous quan-\ntities such as \u039b, pk(zFL), qkl(zFL) that can be easily estimated given a small set of validation data.\n\u02dcWn\n+(t; z, r) is a reflected Brownian motion with a known drift and covariance (see further discussion\nin Appendix G.3), so we can estimate the total cost using a simulated (reflected) Brownian motion.\nThe optimal level z\u2217 can be then found through a simple line search over [0, 1]. Our approach avoids\ntraditional queueing simulations, which can be costly and time-consuming, making it practical and\nscalable for real-world applications.\n7.4 Numerical Experiments for the AI-based triage system\nOur formulation trades off multiple desiderata, in contrast to the standard industry practice that\nchoose z solely based on prediction metrics, such as maximizing recall subject to a fixed high preci-\nsion level [11]. To compare our proposed approach with such standard triage design approaches, we\nconsider the 2-class content moderation problem described in Section 6. We assume the covariates\nfor positive and negative classes are generated in the same fasion as in the 2d logistic regression\nproblem in Section 6, and consider the logistic regression classifier f\u03b8 developed by minimizing\n22",
            "source": "prompt",
            "quality_score": 0.0,
            "metadata": {
              "content_type": [
                "Result/Finding"
              ],
              "difficulty_level": 4,
              "retrieval_hints": [
                "What is Theorem 5 about the total cost of AI-based triage systems?",
                "How can the optimal filtering and toxicity levels be determined?"
              ],
              "summary": "Theorem 5 establishes the conditions under which the total cost of an AI-based triage system can be minimized, providing a framework for determining optimal filtering and toxicity levels based on a classifier."
            }
          },
          {
            "chunk_id": "prompt_22",
            "title": "__auto__",
            "text": "Our Method Classical Method\n100%\n150%\n200%\n250%\n300%\n350%\nEstimtaed T otal Cost\n(i) Filtering costs dominate\nOur Method Classical Method\n100%\n120%\n140%\n160%\nEstimtaed T otal Cost (ii) Hiring costs dominate\nOur Method Classical Method\n100%\n103%\n105%\n108%\n110%\n112%\n115%\nEstimtaed T otal Cost (iii) Trade-off between\nfiltering and hiring costs\nFigure 8. For different methods, we consider the selected filtering level zFL and present the asso-\nciated estimated total cost of the AI-based triage system. The classical method maximizes recall\nsubject to the precision level [0 .93, 0.94, 0.95, 0.96, 0.97], positioned from left to right. This method\nexhibits highly varying total cost even at high precision levels, making it hard to determine the best\nfiltering level. In contrast, our method effectively minimizes the total cost by cheap simulations of\n(reflected) Brownian motion.\nthe equally-weighted cross-entropy loss ( w1 = 1, w2 = 1). For simplicity, we fix the toxicity level\nzTX = 0.5 and only study how filtering level zFL affects the total cost.\nWe examine the setting where the positive class has a relatively high arrival rate to mimic\nthe setting where only flagged content is sent to the triage system, which results in a relatively\nhigh proportion of positive class; recall Figure 1. In particular, we set [\u039b 1, \u039b2] = [10000 , 40000],\n[\u00b51, \u00b52] = [50, 200], where [\u039b 1, \u039b2] is the arrival rate of positive and negative classes to the triage\nsystem, and [ \u00b51, \u00b52] is the common service rate for the positive and negative classes across all\nreviewers. We consider three cases: (i) filtering costs dominate, (ii) hiring costs dominate, and\n(iii) a trade-off between filtering cost and hiring costs. The filtering costs and hiring costs are\nset as follows: (i) [ cFL,1, cFL,2] = [200 , \u22123], cr = 500, (ii) [ cFL,1, cFL,2] = [20 , \u22123], cr = 5000,\nand (iii) [ cFL,1, cFL,2] = [20 , \u22123], cr = 500. In all cases, the misclassification costs are set as\n[cfp, cfn, ctp, ctn] = [3, 3, \u22123, \u22123], and the delay costs are set as C\u00b7(t) = c\u00b7t2/2 with c1 = 15, c2 = 1.\nOur goal is to find the best filtering level zFL that minimizes the total cost. We compare our\nmethod that minimizes (7.2) to the following classical method from Chandak [11], which finds the\nfiltering level zFL by maximizing recall subject to a high precision level lower bound zprec \u2208 [0, 1]. 2\nBoth methods can be effectively implemented using small set of validation data and a linear search.\nWe set the search range for zFL as [0.05, 0.48].\nIn Figure 8, we present the average total cost over 10K sample paths of the simulated (reflected)\nBrownian motion, with 2\u00d7 the standard error encapsulated in the orange brackets. For the classical\nmethod, we set the precision level as [0 .93, 0.94, 0.95, 0.96, 0.97], positioned from left to right. To\nfacilitate comparison with our method, we normalize the estimated total cost by that of our method.\nWe observe that the classical method exhibits highly varying total cost (by \u223c 10% \u2212250%) even at\nhigh precision levels in Figure 8. This demonstrates the importance of selecting the right filtering\nlevel to minimize the total cost. In addition, for the classical method, it also shows the total\ncost is highly sensitive to the precision level. Therefore, the precision level serves as an important\nhyperparameter, and it is challenging to determine the best precision level that corresponds to\noptimal filtering level using the classical method.\nSuch challenge arises since our method takes a holistic view of the entire triage system, yet the\nclassical method only considers the prediction metrics. In our toy example, a higher precision level\n2We follow notations used in Chandak [11]. For the filtering system, precision and recall are calculated by treating\nsafe content as the positive class.\n23",
            "source": "prompt",
            "quality_score": 0.0,
            "metadata": {
              "content_type": [
                "Result/Finding"
              ],
              "difficulty_level": 4,
              "retrieval_hints": [
                "What is Theorem 5 about the total cost of AI-based triage systems?",
                "How can the optimal filtering and toxicity levels be determined?"
              ],
              "summary": "Theorem 5 establishes the conditions under which the total cost of an AI-based triage system can be minimized, providing a framework for determining optimal filtering and toxicity levels based on a classifier."
            }
          },
          {
            "chunk_id": "prompt_23",
            "title": "__auto__",
            "text": "leads to a lower selected filtering level zFL, which results in lower filtering costs and higher hiring\ncosts. Figure 8 (i)(ii) corresponds to simpler settings where the total cost aligns with prediction\nmetrics. That is, when filtering costs or hiring costs dominate, the total cost is monotone with\nrespect to the filtering level and thus the precision level, as shown in Figure 8 (i)(ii). Therefore,\nwhen adopting the classical method, we can simply choose the precision level at the search boundary,\nwhich yields a filtering level near the search boundary that minimizes the total cost. In contrast,\nin Figure 8 (iii), where there is a trade-off between filtering and hiring costs, the total cost is\nnon-monotone and \u201cU\u201d-shaped with respect to the precision/filtering level. In this case, prediction\nmetrics fails to capture the total cost. While hyperparameter (precision) tuning based on total\ncosts is possible, the classical method merely shifts our search space to hyperparameters (precision\nlevels). In other words, hyperparameter tuning is equivalently to a naive line search for the decision\nvariable (filtering levelzFL) based on simulated total cost and the classical method does not serve as\neffective objectives/metrics. More importantly, without our Theorem 5, the total cost can only be\nestimtaed through multiple costly simulations of the entire triage system. Our method, in contrast,\neffectively identifies the correct objective and finds the best filtering level through cheap simulations\nof (reflected) Brownian motion.\nOur numerical experiments demonstrate the the effectiveness of our method and the importance\nof taking a holistic view of the entire content moderation system. We hope our method paves the\nway for more advanced system designs for complex AI-based triage systems in practical use.\n8 Discussion\nOur work builds on the large literature on queueing, as well as the more nascent study of decision-\nmaking problems with prediction models [4, 41, 57, 33, 12, 60]. Unlike previous works that study\nrelatively simple optimization problems (e.g., linear programming [19]) that take as input predic-\ntions, our scheduling setting requires modeling the endogenous impact of misclassifications.\n8.1 Related work\nHeavy traffic analysis allows circumventing the complexity of state/policy spaces via state-space\ncollapse, thereby identifying asymptotically optimal queueing decisions [28, 40, 50, 63, 68]. The\nc\u00b5-rule was shown to be optimal among priority rules in [15], and Van Mieghem [63] proved heavy\ntraffic optimality of the G c\u00b5-rule with convex delay costs in single-server systems with general\ndistributions of interarrival and service times. Under a heavy traffic regime defined with a complete\nresource pooling condition [27], Mandelbaum and Stolyar [40] extended the result to multi-server\nand multi-class queues. In the many server Halfin-Whitt heavy traffic regime (where the server\npool is also scaled [26]), Gurvich and Whitt [25] showed their state-dependent policy that minimizes\nthe holding cost reduces to a simple index-rule with linear holding costs, and to the G c\u00b5-rule with\nconvex costs. When customers in queues can abandon systems, a similar index rule that accounts\nfor the customer abandonment rate was shown to minimize the long-run average holding cost under\nthe many-server fluid limit [5].\nWe focus on the single-server model and relax a common assumption that the class of every job\nis known. We study the impact of AI models in queueing jobs, and use the heavy traffic limit to\nanalyze the downstream impacts of miclassifications. Our results provide a unified framework for\nevaluating and selecting AI models for optimal queueing. Along the way, we also provide rigorous\n24",
            "source": "prompt",
            "quality_score": 0.0,
            "metadata": {
              "content_type": [
                "Result/Finding"
              ],
              "difficulty_level": 4,
              "retrieval_hints": [
                "What is Theorem 5 about the total cost of AI-based triage systems?",
                "How can the optimal filtering and toxicity levels be determined?"
              ],
              "summary": "Theorem 5 establishes the conditions under which the total cost of an AI-based triage system can be minimized, providing a framework for determining optimal filtering and toxicity levels based on a classifier."
            }
          },
          {
            "chunk_id": "prompt_24",
            "title": "__auto__",
            "text": "proofs for the classical setting with known classes by proving unjustified steps in Van Mieghem [63]\nand qualifying conditions under which they hold.\nThe challenge of unknown traffic parameters was identified as early as Cox [14]. Using an off-\npolicy ML model in queueing systems was also proposed for classifying jobs into different types\nor priority classes [57, 60] and predicting service times [12]. Argon and Ziya [4], Singh et al. [57]\nfocus on minimizing the mean stationary waiting time with Poisson arrivals, while we allow general\ndistributions of arrival and service times in our heavy traffic analysis. Although Argon and Ziya\n[4, Section 8] proposes a policy similar in form to the P c\u00b5-rule, their policy is compared to the\nFCFS policies in terms of the stationary waiting time, while our analysis shows the optimality of\nPc\u00b5-rule over all feasible policies in terms of cumulative cost. Sun et al. [60] consider a two-class\nsetting (triage or not) where classes can be inferred with additional time, and analyze when it is\noptimal to triage all (or no) jobs. Importantly, they assume service times follow predicted classes.\nChen and Dong [12] develop a two-class priority rule using predicted service times and show the\nconvergence of the queue length process to the same limit as in the perfect information case when\nestimation error is sufficiently small. In contrast, we characterize the optimal queueing cost given\na fixed classifier instead of aiming to match the performance of the perfect classifier. Our approach\nallows us to provide guidance on model selection for classifiers as we illustrate in Section 6.\nGoing beyond simple index policies, deep reinforcement learning (DRL) algorithms can be used\nfor queueing systems with unknown parameters. Dai and Gluzman [16] develop a policy optimiza-\ntion approach for multiclass Markovian queueing networks and proposes several variance reduction\ntechniques. Pavse et al. [47] combine proximal and trust region-based policy optimization algo-\nrithms [55] with a Lyapunov-inspired technique to ensure stability. Developing further approaches\nto overcome the challenges of applying RL algorithms in queueing (e.g., infinite state spaces, un-\nbounded costs) is a fertile direction of future research.\nThere is a growing body of work on learning in queueing systems that focus on online learning\nand analyze regret, the performance gap between the learning algorithm and the best policy in\nhindsight with the complete knowledge of system parameters [16, 21, 22, 23, 34, 35, 36, 56, 65, 66,\n70]. Inspired by the well-known static priority policies in queueing literature [5, 6, 40, 48, 49, 63],\nempirical versions of such policies were proposed where plug-in estimates of unknown parameters\nare used to compute static priorities. When service rates are unknown, Krishnasamy et al. [35]\npropose an empirical c\u00b5 rule for multi-server settings and show constant regret for linear cost\nfunctions, and Zhong et al. [70] develop an algorithm for learning service and abandonment rates\nin time-varying multiclass queues with many servers and show the empirical c\u00b5/\u03b8 rule achieves\noptimal regret. In the machine scheduling literature, where a finite set of jobs are given (with\nno external arrivals), Lee and Vojnovic [37] studies settings where delay costs are unknown, and\nshow that a plug-in version of the c\u00b5-rule can achieve near-optimal regret when coupled with an\nexploration strategy.\nFor more general queueing networks, Walton and Xu [66] present a connection between the\nMaxWeight policy [61] and Blackwell approachability [9], relating the waiting time regret to that\nof a policy for learning service rates. Borrowing insights from the stochastic multi-armed bandit\nliterature [58], a body of work [13, 34, 36, 59, 65] develops learning algorithms to minimize expected\nqueue length, addressing challenges in the queueing bandit model such as ensuring stability until\nthe parameters are sufficiently learned [36]. Freund et al. [22] propose a new performance measure\nof time-averaged queue length, and show near-optimality of the upper-confidence bound (UCB)\nalgorithm in a single-queue multi-server setting, as well as new UCB-type variants of MaxWeight\n25",
            "source": "prompt",
            "quality_score": 0.0,
            "metadata": {
              "content_type": [
                "Result/Finding"
              ],
              "difficulty_level": 4,
              "retrieval_hints": [
                "What is Theorem 5 about the total cost of AI-based triage systems?",
                "How can the optimal filtering and toxicity levels be determined?"
              ],
              "summary": "Theorem 5 establishes the conditions under which the total cost of an AI-based triage system can be minimized, providing a framework for determining optimal filtering and toxicity levels based on a classifier."
            }
          },
          {
            "chunk_id": "prompt_25",
            "title": "__auto__",
            "text": "and BackPressure [61] in multi-queue systems and queueing networks, respectively. For queueing\nsystems with multi-server multiclass jobs, Yang et al. [69] recently developed another UCB-type\nvariant of the MaxWeight algorithm. Learning service rates has also been studied in decentralized\nqueueing systems, where classes of jobs are considered as strategic agents [21, 23, 56] and stability\nis a primary concern. Motivated by content moderation, a concurrent work [38] studies the joint\ndecision of content classification, and admission and scheduling for human review in an online\nlearning framework.\n8.2 Future directions\nWe discuss limitations of our framework and pose future directions of research. First, implementing\nthe Pc\u00b5-rule needs more information than the previous index-based policies. It necessitates arrival\ninformation, \u03bb and {pk}k\u2208[K], as well as the misclassification probabilities Qn = ( qn\nkl)k,l\u2208[K]. In\npractice, such parameters need to be estimated on a limited amount of data and estimation errors\nare unavoidable.\nExtension of the queueing model We identify conceptual and analytical challenges in ex-\ntending our framework to the multiserver setting. Modeling the extension after Mandelbaum and\nStolyar [40] who consider known true classes, we can posit the complete resource pooling (CRP)\ncondition. This condition requires the limit of the arrival rates to be located in the outer face of\nthe stability region, and to be uniquely represented as a maximal allocation of the servers\u2019 service\ncapacity. For our setting in Section 2, the main challenge is that the CRP condition will not neces-\nsarily hold on the arrival and service rates of the predicted classes. Because the service rate of each\npredicted class in prelimit will be a mixture of the original service rates as \u00b5n\nl in Definition 10, the\nCRP condition on true classes may not be preserved for predicted classes.\nUnderstanding of how prediction error interacts with queueing performance under general dy-\nnamics is an important direction of future research. For example, when jobs exhibit abandonment\nbehavior, a suitable adjustment to the c \u00b5-rule minimizes the long-run holding cost under many-\nserver fluid scaling [5]. Policies that simultaneously account for predictive error and job impatience\nmay yield fruit.\nDesign of queueing systems under class uncertainty While we focus on optimal scheduling,\nan even more important operational lever is thedesign of the queueing system [20, 30]. For example,\ndesigning priority classes that account for predictive error is a promising research direction [12]. In\nour model, if we keep the limiting distributions of the interarrival and service times the same, class\ndesigns satisfying the heavy traffic condition (2.2) should have an identical limiting total workload\n\u02dcW+ by Proposition 1, implying similar forms of the lower bound in (3.3). Given this observation,\nwe may investigate how class design interacts with the AI model\u2019s predictive performance.\nCombining the P c\u00b5-rule with AI-based approaches The performance of RL algorithms\ndegrade under distribution shift, and simple index-based policies may offer robustness benefits. The\ntwo approaches may provide synergies. For example, we can pre-train a policy to initially imitate\nan index-based policy, and then fine-tune it to maximize performance in specific environments.\nFor quadratic costs, we showed the effectiveness of using the relative regret \u02dcJ\u2217(\u00b7; Q) to select\nthe classification threshold. Alternatively, we could directly fine-tune the classifier to minimize\nthis metric, which may further enhance downstream queueing performance, albeit at the cost of\nincreased engineering complexity.\n26",
            "source": "prompt",
            "quality_score": 0.0,
            "metadata": {
              "content_type": [
                "Other"
              ],
              "difficulty_level": 4,
              "retrieval_hints": [
                "What are the future directions of research in queueing systems?",
                "How does prediction error affect queueing performance?",
                "What challenges exist in extending queueing models?"
              ],
              "summary": "The text discusses advancements in queueing systems, particularly focusing on the challenges of implementing the Pc\u00b5-rule and extending models to multi-server settings, while highlighting the impact of prediction errors on performance."
            }
          },
          {
            "chunk_id": "prompt_26",
            "title": "__auto__",
            "text": "References\n[1] How facebook uses super-efficient ai models to detect hate speech. https://ai.meta.com/\nblog/how-facebook-uses-super-efficient-ai-models-to-detect-hate-speech , 2020.\n[2] Harmful content can evolve quickly. our new ai sys-\ntem adapts to tackle it. https://ai.meta.com/blog/\nharmful-content-can-evolve-quickly-our-new-ai-system-adapts-to-tackle-it ,\n2021.\n[3] A. Allouah, C. Kroer, X. Zhang, V. Avadhanula, N. Bohanon, A. Dania, C. Gocmen,\nS. Pupyrev, P. Shah, N. Stier-Moses, and K. R. Taarup. Fair allocation over time, with\napplications to content moderation. In Proceedings of the 29th ACM SIGKDD Conference on\nKnowledge Discovery and Data Mining (KDD) , pages 25\u2013\u201335, 2023.\n[4] N. T. Argon and S. Ziya. Priority assignment under imperfect information on customer type\nidentities. Manufacturing & Service Operations Management , 11(4):674\u2013693, 2009.\n[5] R. Atar, C. Giat, and N. Shimkin. The c\u00b5/\u03b8 rule for many-server queues with abandonment.\nOperations Research, 58(5):1427\u20131439, 2010.\n[6] R. Atar, C. Giat, and N. Shimkin. On the asymptotic optimality of the c\u00b5/\u03b8 rule under ergodic\ncost. Queueing Systems, 67:127\u2013144, 2011.\n[7] P. Billingsley. Convergence of Probability Measures. Wiley, Second edition, 1999.\n[8] E. Black, M. Raghavan, and S. Barocas. Model multiplicity: Opportunities, concerns, and\nsolutions. In Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Trans-\nparency, pages 850\u2013863, 2022.\n[9] D. Blackwell. An analog of the minimax theorem for vector payoffs. Pacific Journal of Math-\nematics, 6(1):1\u20138, Spring 1956.\n[10] D. Borkan, L. Dixon, J. Sorensen, N. Thain, and L. Vasserman. Nuanced metrics for measuring\nunintended bias with real data for text classification. In Proceedings of the 2019 World Wide\nWeb Conference, pages 491\u2013500, 2019.\n[11] A. Chandak. Augmenting our content moderation efforts through\nmachine learning and dynamic content prioritization, 2023. URL\nhttps://www.linkedin.com/blog/engineering/trust-and-safety/\naugmenting-our-content-moderation-efforts-through-machine-learni . Accessed\nMar 2024.\n[12] Y. Chen and J. Dong. Scheduling with service-time information: The power of two priority\nclasses. arXiv:2105.10499 [math.OC], 2021.\n[13] T. Choudhury, G. Joshi, W. Wang, and S. Shakkottai. Job dispatching policies for queueing\nsystems with unknown service rates. In 22nd International Symposium on Theory, Algorithmic\nFoundations, and Protocol Design for Mobile Networks and Mobile Computing , pages 181\u2014-\n190. Association for Computing Machinery, 2021.\n27",
            "source": "prompt",
            "quality_score": 0.0,
            "metadata": {
              "content_type": [
                "Other"
              ],
              "difficulty_level": 3,
              "retrieval_hints": [
                "What are the recent advancements in AI for content moderation?",
                "How does Facebook utilize AI to detect hate speech?",
                "What are the challenges in measuring bias in text classification?"
              ],
              "summary": "This chunk discusses various references related to AI applications in content moderation, highlighting advancements, challenges, and methodologies in the field."
            }
          },
          {
            "chunk_id": "prompt_27",
            "title": "__auto__",
            "text": "[14] D. R. Cox. Some problems of statistical analysis connected with congestion (with discussion).\nIn Proceedings of the Symposium on Congestion Theory , pages 289\u2013316. Chapel Hill, North\nCarolina: University of North Carolina Press, 1966.\n[15] D. R. Cox and W. L. Smith. Queues, volume 2. Methuen, 1961.\n[16] J. G. Dai and M. Gluzman. Queueing network controls via deep reinforcement learning.\nStochastic Systems, pages 1\u201338, 2021.\n[17] A. D\u2019Amour, K. Heller, D. Moldovan, B. Adlam, B. Alipanahi, A. Beutel, C. Chen, J. Deaton,\nJ. Eisenstein, M. D. Hoffman, et al. Underspecification presents challenges for credibility in\nmodern machine learning. Journal of Machine Learning Research , 23(226):1\u201361, 2022.\n[18] R. Durrett. Probability: Theory and Examples . Cambridge University Press, 2010.\n[19] A. N. Elmachtoub and P. Grigas. Smart \u201dpredict, then optimize\u201d. Management Science, 2021.\n[20] Z. Feldman, A. Mandelbaum, W. A. Massey, and W. Whitt. Staffing of time-varying queues\nto achieve time-stable performance. Management Science, 54(2):324\u2013338, 2008.\n[21] D. Freund, T. Lykouris, and W. Weng. Efficient decentralized multi-agent learning in asym-\nmetric bipartite queueing systems. arXiv:2206.03324 [cs.LG], 2022.\n[22] D. Freund, T. Lykouris, and W. Weng. Quantifying the cost of learning in queueing systems.\narXiv:2308.07817 [cs.LG], 2023.\n[23] J. Gaitonde and \u00b4E. Tardos. The price of anarchy of strategic queuing systems. Journal of the\nACM, 70(20):1\u201363, May 2023.\n[24] P. W. Glynn. Chapter 4 diffusion approximations. In Stochastic Models, volume 2 of Handbooks\nin Operations Research and Management Science , pages 145\u2013198. Elsevier, 1990.\n[25] I. Gurvich and W. Whitt. Scheduling flexible servers with convex delay costs in many-server\nservice systems. Manufacturing & Service Operations Management , 11(2):237\u2013253, 2008.\n[26] S. Halfin and W. Whitt. Heavy-traffic limits for queues with many exponential servers. Oper-\nations Research, 29(3):567\u2013587, 1981.\n[27] J. M. Harrison and M. J. L\u00b4 opez. Heavy traffic resource pooling in parallel-server systems.\nQueueing Systems, 33:339\u2013368, 1999.\n[28] J. M. Harrison and A. Zeevi. Dynamic scheduling of a multiclass queue in the halfin-whitt\nheavy traffic regime. Operations Research, 52(2):243\u2013257, 2004.\n[29] P. Henderson, R. Islam, P. Bachman, J. Pineau, D. Precup, and D. Meger. Deep reinforcement\nlearning that matters. In Thirty-Second AAAI Conference on Artificial Intelligence . AAAI\nPress, 2018.\n[30] O. B. Jennings, A. Mandelbaum, W. A. Massey, and W. Whitt. Server staffing to meet\ntime-varying demand. Management Science, 42(10):1383\u20131394, 1996.\n[31] O. Kallenberg. Foundations of Modern Probability. Springer, 1997.\n28",
            "source": "prompt",
            "quality_score": 0.0,
            "metadata": {
              "content_type": [
                "Other"
              ],
              "difficulty_level": 3,
              "retrieval_hints": [
                "What are the recent advancements in AI for content moderation?",
                "How does Facebook utilize AI to detect hate speech?",
                "What are the challenges in measuring bias in text classification?"
              ],
              "summary": "This chunk discusses various references related to AI applications in content moderation, highlighting advancements, challenges, and methodologies in the field."
            }
          },
          {
            "chunk_id": "prompt_28",
            "title": "__auto__",
            "text": "[32] P. W. Koh, S. Sagawa, H. Marklund, S. M. Xie, M. Zhang, A. Balsubramani, W. Hu, M. Ya-\nsunaga, R. L. Phillips, S. Beery, et al. Wilds: A benchmark of in-the-wild distribution shifts.\narXiv:2012.07421 [cs.LG], 2020.\n[33] J. Kotary, F. Fioretto, P. Van Hentenryck, and B. Wilder. End-to-end constrained optimization\nlearning: A survey. arXiv:2103.16378 [cs.LG], 2021.\n[34] S. Krishnasamy, R. Sen, R. Johari, and S. Shakkottai. Regret of queueing bandits. In Advances\nin Neural Information Processing Systems 16 , volume 29, 2016.\n[35] S. Krishnasamy, A. Arapostathis, R. Johari, and S. Shakkottai. On learning the c\u00b5 rule in\nsingle and parallel server networks. arXiv:1802.06723 [cs.PF], 2018.\n[36] S. Krishnasamy, R. Sen, R. Johari, and S. Shakkottai. Learning unknown service rates in\nqueues: A multiarmed bandit approach. Operations Research, 69(1):315\u2013330, 2021.\n[37] D. Lee and M. Vojnovic. Scheduling jobs with stochastic holding costs. In Advances in Neural\nInformation Processing Systems 21 , 2021.\n[38] T. Lykouris and W. Weng. Learning to defer in content moderation: The human-ai interplay.\narXiv:2402.12237 [cs.LG], 2024.\n[39] R. Makhijani, P. Shah, V. Avadhanula, C. Gocmen, N. E. Stier-Moses, and J. Mestre. Quest:\nQueue simulation for content moderation at scale. arXiv:2103.16816, 2021.\n[40] A. Mandelbaum and A. L. Stolyar. Scheduling flexible servers with convex delay costs: Heavy-\ntraffic optimality of the generalized c \u00b5-rule. Operations Research, 52(6):836\u2013855, 2004.\n[41] V. V. Mi\u02c7 si\u00b4 c and G. Perakis. Data analytics in operations management: A review. Manufac-\nturing & Service Operations Management , 22(1):158\u2013169, 2020.\n[42] V. Mnih, K. Kavukcuoglu, D. Silver, A. Graves, I. Antonoglou, D. Wierstra, and M. Riedmiller.\nPlaying Atari with deep reinforcement learning. arXiv:1312.5602 [cs.LG], 2013.\n[43] P. M\u00a8 orters and Y. Peres.Brownian Motion. Cambridge University Press, 2010.\n[44] H. Namkoong, Y. Ma, and P. W. Glynn. Minimax optimal estimation of stability under\ndistribution shift. arXiv:2212.06338 [stat.ML], 2022.\n[45] G. Pang, R. Talreja, and W. Whitt. Martingale proofs of many-server heavy-traffic limits for\nMarkovian queues. Probability Surveys, 4:193\u2013267, 2007.\n[46] C. H. Papadimitriou and J. N. Tsitsiklis. The complexity of optimal queueing network control.\nIn Proceedings of IEEE 9th Annual Conference on Structure in Complexity Theory, pages 318\u2013\n322. IEEE, 1994.\n[47] B. S. Pavse, Y. Chen, Q. Xie, and J. P. Hanna. Tackling unbounded state spaces in continuing\ntask reinforcement learning. arXiv:2306.01896 [cs.LG], 2023.\n[48] A. L. Puha and A. R. Ward. Scheduling an overloaded multiclass many-server queue with\nimpatient customers. INFORMS TutORials in Operations Research, pages 189\u2013217, 2019.\n[49] A. L. Puha and A. R. Ward. Fluid limits for multiclass many-server queues with general\n29",
            "source": "prompt",
            "quality_score": 0.0,
            "metadata": {
              "content_type": [
                "Other"
              ],
              "difficulty_level": 3,
              "retrieval_hints": [
                "What are the recent advancements in AI for content moderation?",
                "How does Facebook utilize AI to detect hate speech?",
                "What are the challenges in measuring bias in text classification?"
              ],
              "summary": "This chunk discusses various references related to AI applications in content moderation, highlighting advancements, challenges, and methodologies in the field."
            }
          },
          {
            "chunk_id": "prompt_29",
            "title": "__auto__",
            "text": "reneging distributions and head-of-the-line scheduling. Mathematics of Operations Research ,\n47(2):1192\u20131228, 2021.\n[50] M. I. Reiman. Some diffusion approximations with state space collapse. In Modelling and\nPerformance Evaluation Methodology, pages 207\u2013240. Springer, 1984.\n[51] H. Royden. Real Analysis. Pearson, third edition, 1988.\n[52] S. Sagawa, P. W. Koh, T. B. Hashimoto, and P. Liang. Distributionally robust neural net-\nworks for group shifts: On the importance of regularization for worst-case generalization. In\nProceedings of the Seventh International Conference on Learning Representations , 2019.\n[53] V. Sanh, L. Debut, J. Chaumond, and T. Wolf. Distilbert, a distilled version of BERT: smaller,\nfaster, cheaper and lighter. arXiv:1910.01108 [cs.CL], 2019.\n[54] M. Schroepfer. Community standards report, 2019. URL https://ai.meta.com/blog/\ncommunity-standards-report. Accessed Apr 2024.\n[55] J. Schulman, S. Levine, P. Abbeel, M. Jordan, and P. Moritz. Trust region policy optimiza-\ntion. In Proceedings of the 32nd International Conference on Machine Learning , volume 37\nof Proceedings of Machine Learning Research, pages 1889\u20131897, Lille, France, 07\u201309 Jul 2015.\nPMLR.\n[56] F. Sentenac, E. Boursier, and V. Perchet. Decentralized learning in online queuing systems. In\nAdvances in Neural Information Processing Systems 34 , volume 34, pages 18501\u201318512, 2021.\n[57] S. Singh, I. Gurvich, and J. A. Van Mieghem. Feature-based design of priority queues: Digital\ntriage in healthcare. SSRN3731865, 2020. URL http://dx.doi.org/10.2139/ssrn.3731865.\n[58] A. Slivkins. Introduction to multi-armed bandits. arXiv:1904.07272 [cs.LG], 2019.\n[59] T. Stahlbuhk, B. Shrader, and E. Modiano. Learning algorithms for minimizing queue length\nregret. IEEE Transactions on Information Theory , 67(3):1759\u20131781, 2021.\n[60] Z. Sun, N. T. Argon, and S. Ziya. When to triage in service systems with hidden customer\nclass identities? Production and Operations Management, 31(1):172\u2013193, 2022.\n[61] L. Tassiulas and A. Ephremides. Stability properties of constrained queueing systems and\nscheduling policies for maximum throughput in multihop radio networks. IEEE Transactions\non Automatic Control, 37:1936\u20131948, 1992.\n[62] Tiktok Content Moderation. Our approach to content moderation. https://www.tiktok.\ncom/transparency/en/content-moderation/.\n[63] J. A. Van Mieghem. Dynamic scheduling with convex delay costs: The generalized c- \u00b5 rule.\nAnnals of Applied Probability, pages 809\u2013833, 1995.\n[64] J. Vincent. Facebook is now using ai to sort content for quicker moderation, 2020.\nURL https://www.theverge.com/2020/11/13/21562596/facebook-ai-moderation. Ac-\ncessed Apr 2024.\n[65] N. Walton. Two queues with non-stochastic arrivals. Operations Research Letters, 42(1):53\u201357,\n30",
            "source": "prompt",
            "quality_score": 0.0,
            "metadata": {
              "content_type": [
                "Other"
              ],
              "difficulty_level": 3,
              "retrieval_hints": [
                "What are the recent advancements in AI for content moderation?",
                "How does Facebook utilize AI to detect hate speech?",
                "What are the challenges in measuring bias in text classification?"
              ],
              "summary": "This chunk discusses various references related to AI applications in content moderation, highlighting advancements, challenges, and methodologies in the field."
            }
          },
          {
            "chunk_id": "prompt_30",
            "title": "__auto__",
            "text": "2014.\n[66] N. Walton and K. Xu. Learning and information in stochastic networks and queues. In\nTutorials in Operations Research: Emerging Optimization Methods and Modeling Techniques\nwith Applications, pages 161\u2013198. INFORMS, 2021.\n[67] S. Wang, H. Fang, M. Khabsa, H. Mao, and H. Ma. Entailment as few-shot learner.\narXiv:2104.14690 [cs.CL], 2021.\n[68] W. Whitt. Stochastic Process Limits: An Introduction to Stochastic Process Limits and Their\nApplication to Queues . Springer Science & Business Media, 2002.\n[69] Z. Yang, R. Srikant, and L. Ying. Learning while scheduling in multi-server systems with\nunknown statistics: Maxweight with discounted ucb. In Proceedings of the 26 International\nConference on Artificial Intelligence and Statistics , volume 206 of Proceedings of Machine\nLearning Research, pages 4275\u20134312. PMLR, 2023.\n[70] Y. Zhong, J. R. Birge, and A. R. Ward. Learning the scheduling policy in time-varying\nmulticlass many server queues with abandonment. Available at SSRN , 2022. URL http:\n//dx.doi.org/10.2139/ssrn.4090021.\n31",
            "source": "prompt",
            "quality_score": 0.0,
            "metadata": {
              "content_type": [
                "Other"
              ],
              "difficulty_level": 3,
              "retrieval_hints": [
                "What are the recent advancements in AI for content moderation?",
                "How does Facebook utilize AI to detect hate speech?",
                "What are the challenges in measuring bias in text classification?"
              ],
              "summary": "This chunk discusses various references related to AI applications in content moderation, highlighting advancements, challenges, and methodologies in the field."
            }
          },
          {
            "chunk_id": "prompt_31",
            "title": "__auto__",
            "text": "Appendices\nTable of Contents\nA Diffusion limits 31\nA.1 Review of basic results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32\nA.2 Proof of Lemma 3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34\nA.3 Proof of Lemma 4 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37\nB Proofs of results in Section 3.1 37\nB.1 Convergence of arrival and service processes of predicted classes . . . . . . . . . . . 38\nB.2 Dominance of p-FCFS and work-conserving policies . . . . . . . . . . . . . . . . . . 40\nB.3 Convergence of the endogenous processes of predicted classes . . . . . . . . . . . . 42\nB.4 Diffusion limits of the classical queueing model . . . . . . . . . . . . . . . . . . . . 45\nB.5 Proof of Lemma 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47\nC Proof of heavy traffic lower bound (Theorem 2) 47\nC.1 Overview . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47\nC.2 Detailed proof of heavy traffic lower bound (Theorem 2) . . . . . . . . . . . . . . . 49\nC.3 Proof of Lemma 15 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52\nC.4 Proof of Proposition 8 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52\nC.5 Proof of Proposition 7 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53\nC.6 Proof of Lemma 16 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55\nC.7 Complementary proof for Proposition 6 in Van Mieghem [63] . . . . . . . . . . . . 55\nD Proof of Proposition 13 56\nD.1 Preliminaries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 57\nD.2 Proof of Proposition 9 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59\nD.3 Proof of Proposition 10 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 60\nD.4 Proof of Proposition 11 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62\nE Proof of Theorem 3 62\nE.1 Overview of the proof . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62\nE.2 Comparison to the optimality result in Van Mieghem [63] . . . . . . . . . . . . . . 64\nE.3 Comparison to the optimality result in Mandelbaum and Stolyar [40] . . . . . . . . 64\nE.4 Detailed proof of Theorem 3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 65\nE.5 Proof of Lemma 26 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 65\nE.6 Proof of Proposition 12 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 66\nF Proofs for Section 6 67\nF.1 Proof for Proposition 4 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 67\nG Proof of results in Section 7 68\n32",
            "source": "prompt",
            "quality_score": 0.0,
            "metadata": {
              "content_type": [
                "Other"
              ],
              "difficulty_level": 4,
              "retrieval_hints": [
                "What are the proofs related to diffusion limits?",
                "How are heavy traffic lower bounds established?"
              ],
              "summary": "This section contains appendices detailing various proofs related to diffusion limits and heavy traffic lower bounds in queueing theory."
            }
          },
          {
            "chunk_id": "prompt_32",
            "title": "__auto__",
            "text": "G.1 Joint convergence of the AI-based triage system . . . . . . . . . . . . . . . . . . . . 68\nG.2 Sample path analysis of each reviewer . . . . . . . . . . . . . . . . . . . . . . . . . 71\nG.3 Simulation of the total cost of the AI-based Triage System . . . . . . . . . . . . . . 73\nA Diffusion limits\nWe consider the following processes: partial sum process of interarrival time Un\n0 (t) that depends\nsolely on {un\ni : i \u2208 N}, partial sum process of service time V n\n0 and two other processes Zn :=\n(Zn\nkl)k,l\u2208[K], Rn := ( Rn\nl )l\u2208[K] that solely relies on {(Xn\ni , Yn\ni , vn\ni ) : i \u2208 N}. In particular, given\nsystem n, Zn\nkl(t) is the total number of jobs from real class k and predicted as class l and Rn\nl (t) is\nthe total service time requested by jobs predicted as class l, among the first \u230at\u230b jobs arriving in the\nsystem:\nZn\nkl(t) :=\n\u230at\u230bX\ni=1\nY n\nikY n\nil, R n\nl (t) :=\n\u230at\u230bX\ni=1\nY n\nilvn\ni , t \u2208 [0, n].\nFor any n \u2208 N and t \u2208 [0, 1], let \u02dcUn\n0 , \u02dcV n\n0 , \u02dcZ\nn\n:= ( \u02dcZ\nn\nkl)k,l\u2208[K], \u02dcR\nn\n:= ( \u02dcR\nn\nl )l\u2208[K] be the diffusion-\nscaled process, where\n\u02dcUn\n0 (t) = n\u22121/2[Un\n0 (nt) \u2212 (\u03bbn)\u22121 \u00b7 nt], \u02dcV n\n0 (t) = n\u22121/2[V n\n0 (nt) \u2212\nnX\nk=1\npn\nk\n\u00b5n\nk\n\u00b7 nt], t \u2208 [0, 1]; (A.1)\nand formal definitions of \u02dcZ\nn\nand \u02dcR\nn\nare deferred to Definition 8. In Assumption H to come, we\nstate basic moment conditions that allows the application of the martingale FCLT.\nLemma 3 (Joint weak convergence). Suppose that Assumptions A, B, and H hold. Then, there\nexist Brownian motions ( \u02dcU0, \u02dcZ, \u02dcR, \u02dcV0) such that\n( \u02dcUn\n0 , \u02dcZ\nn\n, \u02dcR\nn\n, \u02dcV n\n0 ) \u21d2 ( \u02dcU0, \u02dcZ, \u02dcR, \u02dcV0) in (DK(K+1)+2, W J1).\nDeferring a detailed proof to Section A.2, we highlight the main ingredients of the joint con-\nvergence result. Our main observation is that the diffusion-scaled processes admit a martingale\ncentral limit result when {(un\ni , vn\ni , Xn\ni , Yn\ni ) : i \u2208 N} are i.i.d. (Assumption A (i)) and vn\ni \u22a5 Xn\ni | Y n\ni\n(Assumption A (iii)). This allows us to show the weak convergence \u02dcUn\n0 \u21d2 \u02dcU0 in ( D, J1) and\n(\u02dcZ\nn\n, \u02dcR\nn\n, \u02dcV n\n0 ) \u21d2 (\u02dcZ, \u02dcR, \u02dcV0) in ( DK(K+1)+1, W J1). Since {un\ni } and {(vn\ni , Xn\ni , Yn\ni )} are independent\n(Assumption A (ii)), we can obtain the desired joint convergence (e.g., see Whitt [68, Theorem\n11.4.4] which we give as Lemma 9).\nBuilding off of our diffusion limit, we can strengthen the convergence to the uniform topology\nusing standard tools (e.g., see Lemma 6 and Lemma 7), and conduct a sample path analysis where\nwe construct copies of ( \u02dcUn\n0 , \u02dcZ\nn\n, \u02dcR\nn\n, \u02dcV n\n0 ) and ( \u02dcU0, \u02dcZ, \u02dcR, \u02dcV0) that are identical in distribution with\ntheir original counterparts and converge almost surely under a common probability space. Abusing\nnotation, we use the same notation for the newly construced processes.\nLemma 4 (Uniform convergence). Suppose that Assumptions A, B, and H hold. Then, there exist\nstochastic processes ( \u02dcUn\n0 , \u02dcZ\nn\n, \u02dcR\nn\n, \u02dcV n\n0 ), \u2200 n \u2265 1 and ( \u02dcU0, \u02dcZ, \u02dcR, \u02dcV0) defined on a common probability\nspace (\u2126copy, Fcopy, Pcopy) such that ( \u02dcUn\n0 , \u02dcZ\nn\n, \u02dcR\nn\n, \u02dcV n\n0 ), \u2200 n \u2265 1 and ( \u02dcU0, \u02dcZ, \u02dcR, \u02dcV0) are identical in\ndistribution with their original counterparts and\n( \u02dcUn\n0 , \u02dcZ\nn\n, \u02dcR\nn\n, \u02dcV n\n0 ) \u2192 ( \u02dcU0, \u02dcZ, \u02dcR, \u02dcV0) in (DK(K+1)+2, \u2225 \u00b7 \u2225), Pcopy-a.s.. (A.2)\n33",
            "source": "prompt",
            "quality_score": 0.0,
            "metadata": {
              "content_type": [
                "Other"
              ],
              "difficulty_level": 4,
              "retrieval_hints": [
                "What are the proofs related to diffusion limits?",
                "How are heavy traffic lower bounds established?"
              ],
              "summary": "This section contains appendices detailing various proofs related to diffusion limits and heavy traffic lower bounds in queueing theory."
            }
          },
          {
            "chunk_id": "prompt_33",
            "title": "__auto__",
            "text": "We defer a detailed proof to Section A.3 since it is a basic consequence of the Skorokhod repre-\nsentation theorem [7, Theorem 6.7]. Since the diffusion limits ( \u02dcU0, \u02dcZ, \u02dcR, \u02dcV 0) are multidimensional\nBrownian motions, the copied processes of ( \u02dcUn\n0 , \u02dcZ\nn\n, \u02dcR\nn\n, \u02dcV\nn\n0 ) jointly converge to a continuous limit\nalmost surely. We obtain the result by noting that convergence inJ1 to a deterministic and continu-\nous limit is equivalent to uniform convergence on compact intervals (e.g., see Glynn [24, Proposition\n4] stated in Lemma 7).\nSample path analysis allows us to leverage properties of uniform convergence and significantly\nsimplifies our analysis. All subsequent results and their proofs in the appendix, will be established\non the copied processes in the common probability space (\u2126 copy, Fcopy, Pcopy) with probability one,\ni.e., Pcopy-a.s., and all of the convergence results will be understood to hold in theuniform norm \u2225\u00b7\u2225.\nMoreover, since these newly constructed processes are identical in distribution with their original\ncounterparts, all subsequent results regarding almost sure convergence for the copied processes\ncan be converted into corresponding weak convergence results for the original processes; see more\ndiscussion in Theorems 2 and 3.\nTo show the above result, we first introduce a uniform integrability condition that allows us to\napply the martigale FCLT.\nAssumption H (Uniform integrability). For any system n \u2208 N, we assume that\n(i) En[(un\n1 )2] < \u221e, En[(vn\n1 )2] < \u221e, En[(Xn\n1 )2] < \u221e, and there exists fuctions gu and gv such that\ngu(x) \u2192 0, gv(x) \u2192 0 as x \u2192 \u221eand for any n \u2208 N and x \u2208 R,\nEn[(un\n1 )21 {un\n1 > x}] \u2264 gu(x), En[(vn\n1 )21 {vn\n1 > x}] \u2264 gv(x);\n(ii) There exist constants \u03b1u \u2208 (0, \u221e) and \u03b1v,k \u2208 (0, \u221e) for any k \u2208 [K] such that\n\u03b1n\nu := En[(un\n1 )2] \u2192 \u03b1u, \u03b1 n\nv,k := En[(vn\n1 )2|Y n\n1k = 1] \u2192 \u03b1v,k\nas n \u2192 \u221e.\nFor completeness, we review the martingale FCLT and Skorohod representation result before prov-\ning the main results of Section 2.\nA.1 Review of basic results\nWe review classical results on the martingale FCLT and the Skorohod construction.\nA.1.1 Martigale Functional Central Limit Theorem\nOur proof of Lemma 3 primarily relies on the martingale FCLT [45, Theorem 8.1]. We define the\nmaximum jump and the optional quadratic variation of processes and review the martingale FCLT\nin Lemma 5.\nLet D[0,\u221e) := D([0, \u221e), R) be the set of right-continuous with left limits (RCLL) functions\n[0, \u221e) \u2192 R, and Dk\n[0,\u221e) := D([0, \u221e), Rk) be the product space D[0,\u221e) \u00d7 \u00b7\u00b7\u00b7 \u00d7 D[0,\u221e) for k \u2208 N.\nWith a slight abuse of notations, we also use J1 to denote be the standard Skorohod J1 topology\non D[0,\u221e) and W J1 to denote the product J1 topology on Dk\n[0,\u221e).\nDefinition 5 (Maximum jump). For any function x \u2208 D[0,\u221e), the maximum jump of x up to time\nt is represented as\nJ(x, t) := sup{|x(s) \u2212 x(s\u2212)| : 0 < s\u2264 t}, t > 0. (A.3)\n34",
            "source": "prompt",
            "quality_score": 0.0,
            "metadata": {
              "content_type": [
                "Other"
              ],
              "difficulty_level": 4,
              "retrieval_hints": [
                "What are the proofs related to diffusion limits?",
                "How are heavy traffic lower bounds established?"
              ],
              "summary": "This section contains appendices detailing various proofs related to diffusion limits and heavy traffic lower bounds in queueing theory."
            }
          },
          {
            "chunk_id": "prompt_34",
            "title": "__auto__",
            "text": "Definition 6 (Optional quadratic variation) . Let M1 and M2 be two martingales in D[0,\u221e) with\nrespect to a filtration F \u2261 {Ft : t \u2265 0} satisfying M1(0) = M2(0) = 0 . The optional quadratic\nvariation between M1 and M2 is defined as\n[M1, M2](t) = lim\nm\u2192\u221e\n\u221eX\ni=1\n\u0000\nM1(tm,i) \u2212 M1(tm,i\u22121)\n\u0001\u0000\nM2(tm,i) \u2212 M2(tm,i\u22121)\n\u0001\n, t > 0, (A.4)\nwhere tm,i = min(t, i2\u2212m).\nPang et al. [45, Theorem 3.2] shows that [ M1, M2](t) is well-defined for any martingales pairs\n(M1, M2) satisfying conditions outlined in Definition 6.\nLemma 5 (Multidimensional martingale FCLT). For n \u2265 1, let Mn \u2261 (Mn\n1 , . . . , Mn\nk ) be a martin-\ngale in (Dk\n[0,\u221e), W J1) with respect to a filtration Fn \u2261 {Fn,t : t \u2265 0} satisfying Mn(0) = (0, . . . ,0).\nIf both of the following conditions hold\n(i) the expected maximum jump is asymptotically negligible: limn\u2192\u221e E[J(Mn\ni , T)] = 0 , \u2200 i \u2208\n[k], \u2200 T \u2265 0;\n(ii) there exists a positive semidefinite symmetric matrix A = {aij}i,j\u2208[k] \u2208 Rk\u00d7k such that for\nany 1 \u2264 i, j\u2264 k and t >0, [Mn\ni , Mn\nj ](t) \u21d2 aijt in R as n \u2192 \u221e,\nthen, we have that\nMn \u21d2 M in (Dk\n[0,\u221e), W J1) as n \u2192 \u221e,\nwhere M is a k-dimensional Brownian motion with mean vector and covariance matrix being\nE[M(t)] = (0, . . . ,0) and E[M(t)M\u22a4(t)] = At, t \u2265 0.\nA.1.2 Skorohod representation\nRecall the definition of random elements on a metric space ( S, m) [68, Page 78].\nDefinition 7 (Random Element). For a separable metric space (S, m), we say that X is a random\nelement of (S, m) if X is a measurable mapping from some underlying probability space (\u2126, F, P)\nto (S, B(S)), where B(s) is the Borel \u03c3-field induced by (S, m).\nThe well-known Skorohod representation theorem [7, Theorem 6.7] gives the following.\nLemma 6 (Skorohod representation) . Let {Xn}n\u22651 and X be random elements of a separable\nmetric space (S, m). If Xn \u21d2 X in (S, m), then there exists other random elements {Xn\ncopy}n\u22651 and\nXcopy of (S, m), defined on a common probability space (\u2126, F, P), such that (i) Xn\ncopy\nd= Xn, \u2200 n \u2265 1\nand Xcopy\nd= X; (ii) limn\u2192+\u221e m(Xn\ncopy, Xcopy) = 0 P-almost surely.\nLet dJ1(\u00b7, \u00b7) be the J1 metric (Skorohod metic) defined on D := D([0, 1], R), the set of RCLL\nfunctions [0, 1] \u2192 R [68, Page 79]. Moreover, for the product space Dk := D\u00d7\u00b7\u00b7\u00b7\u00d7D , let dp(\u00b7, \u00b7) be\nthe product metric defined by dp(x, y) := PK\ni=1 dJ1(xi, yi), \u2200 x, y \u2208 Dk [68, Page 83]. It is known\nthat both (D, dJ1(\u00b7, \u00b7)) and (Dk, dp(\u00b7, \u00b7)) are separable metric spaces withJ1 topology and W J1 (weak\nJ1) topology respectively [68, Sections 3.3, 11.4, and 11.5]. Then, according to Lemma 6, for weakly\nconverging random elements, we can obtain copies that converges almost surely. This enables us\nto conduct sample path analysis. Specifically, if the limiting random element is continuous almost\nsurely, we can utilize the following theorem from [24, Proposition 4] to conduct analysis under\nuniform norm convergence, which can streamline our analysis significantly.\n35",
            "source": "prompt",
            "quality_score": 0.0,
            "metadata": {
              "content_type": [
                "Other"
              ],
              "difficulty_level": 4,
              "retrieval_hints": [
                "What are the proofs related to diffusion limits?",
                "How are heavy traffic lower bounds established?"
              ],
              "summary": "This section contains appendices detailing various proofs related to diffusion limits and heavy traffic lower bounds in queueing theory."
            }
          },
          {
            "chunk_id": "prompt_35",
            "title": "__auto__",
            "text": "Lemma 7. For a sequence of functions Xn \u2208 D, convergence to a continuous function, say X \u2208 C,\nin the J1 metric dJ1(\u00b7, \u00b7) is equivalent to convergence in uniform norm \u2225 \u00b7 \u2225, i.e.,\nlim\nn\u2192\u221e\ndJ1(Xn, X) = 0 \u21d4 lim\nn\u2192\u221e\n\u2225Xn \u2212 X\u2225 = 0.\nA.2 Proof of Lemma 3\nFirst, we define arrival and service processes of predicted classes on which we apply the martigale\nFCLT to establish their weak convergence.\nDefinition 8 (Arrival and service processes of predicted classes I) . Given a classifier f\u03b8 and a\nsequence of queueing systems, we define the following for a given system n and time t \u2208 [0, n]:\n(i) (Counting process) for any real class k \u2208 [K] and predicted class l \u2208 [K], let Zn\nkl(t) be the total\nnumber of jobs from real class k and predicted as class l, among the first \u230at\u230b jobs arriving in\nthe system, i.e.,\nZn\nkl(t) :=\n\u230at\u230bX\ni=1\nY n\nikY n\nil, \u2200 t \u2208 [0, n];\nMoreover, let \u02dcZ\nn\n= { \u02dcZ\nn\nkl}k,l\u2208[K] be the corresponding diffusion-scaled process, defined as\n\u02dcZ\nn\nkl(t) = n\u22121\n2\nh\u230ant\u230bX\ni=1\nY n\nikY n\nil \u2212 pn\nkqn\nkl \u00b7 nt\ni\n, \u2200 t \u2208 [0, 1];\n(ii) (Cumulative service time) for any predicted class l \u2208 [K], let Rn\nl be the total service time\nrequested by jobs predicted as class l, among the first \u230at\u230b jobs arriving in the system, i.e.,\nRn\nl (t) :=\n\u230at\u230bX\ni=1\nY n\nilvn\ni , \u2200 t \u2208 [0, n].\nMoreover, let \u02dcR = { \u02dcRl}l\u2208[K] be the corresponding diffusion-scaled process, defined as\n\u02dcR\nn\nl (t) = n\u22121\n2\nh\u230ant\u230bX\ni=1\nY n\nilvn\ni \u2212\nKX\nk=1\npn\nk\n\u00b5n\nk\nqn\nkl \u00b7 nt\ni\n, \u2200 t \u2208 [0, 1].\nWe define Zn\nkl and Rn\nl on [0 , n], and \u02dcZ\nn\nkl and \u02dcR\nn\nl on [0 , 1] for analysis simplicity, and these\nprocesses can be naturally extended to [0 , +\u221e) to apply the martingale FCLT in Lemma 5. In\naddition, we introduce the following rescaled and centered processes \u02d8Un\n0 (t) and ( \u02d8Z\nn\n, \u02d8R\nn\n, \u02d8V n\n0 ) for\nanalysis purposes.\nDefinition 9 (Arrival and service processes of predicted classes II) . Given a classifier f\u03b8 and a\nsequence of queueing systems, we define the rescaled and centered processes for a given system n\nand time t \u2208 [0, 1] as followings:\n\u02d8Un\n0 (t) = n\u22121\n2\n\u230ant\u230bX\ni=1\n(un\ni \u2212 (\u03bbn)\u22121), \u02d8V n\n0 (t) = n\u22121\n2\n\u230ant\u230bX\ni=1\nh\nvn\ni \u2212\nKX\nk=1\npn\nk\n\u00b5n\nk\ni\n,\n\u02d8Z\nn\nkl(t) = n\u22121\n2\n\u230ant\u230bX\ni=1\n[Y n\nikY n\nil \u2212 pn\nkqn\nkl], \u2200 k, l\u2208 [K], \u02d8R\nn\nl (t) = n\u22121\n2\n\u230ant\u230bX\ni=1\nh\nY n\nilvn\ni \u2212\nKX\nk=1\npn\nk\n\u00b5n\nk\nqn\nkl\ni\n, \u2200 l \u2208 [K].\n36",
            "source": "prompt",
            "quality_score": 0.0,
            "metadata": {
              "content_type": [
                "Other"
              ],
              "difficulty_level": 4,
              "retrieval_hints": [
                "What are the proofs related to diffusion limits?",
                "How are heavy traffic lower bounds established?"
              ],
              "summary": "This section contains appendices detailing various proofs related to diffusion limits and heavy traffic lower bounds in queueing theory."
            }
          },
          {
            "chunk_id": "prompt_36",
            "title": "__auto__",
            "text": "One can check that \u02d8Un\n0 , \u02d8V n\n0 , \u02d8Z\nn\n, \u02d8R\nn\nare closely related to \u02dcUn\n0 , \u02dcV n\n0 , \u02dcZ\nn\n, \u02dcR\nn\nby noting that for any\nt \u2208 [0, 1],\n\u02dcUn\n0 (t) = \u02d8Un\n0 (t) + n\u22121\n2 (\u03bbn)\u22121(\u230ant\u230b \u2212nt), \u02dcV n\n0 (t) = \u02d8V n\n0 (t) + n\u22121\n2\nKX\nk=1\npn\nk\n\u00b5n\nk\n(\u230ant\u230b \u2212nt),\n\u02dcZ\nn\nkl(t) = \u02d8Z\nn\nkl(t) + n\u22121\n2 pn\nkqn\nkl(\u230ant\u230b \u2212nt), \u02dcR\nn\nl (t) = \u02d8R\nn\nl (t) + n\u22121\n2\nKX\nk=1\npn\nk\n\u00b5n\nk\nqn\nkl(\u230ant\u230b \u2212nt).\nUnder Assumptions A and H, we establish the weak convergence of \u02d8Un\n0 (t) and ( \u02d8Z\nn\n, \u02d8R\nn\n, \u02d8V n\n0 )\nusing the martingale FCLT in Lemma 5.\nLemma 8 (Individual weak convergence). Suppose that Assumptions A, B, and H hold. Then, there\nexist Brownian motions \u02d8U0 and (\u02d8Z, \u02d8R, \u02d8V0) such that (i) \u02d8Un\n0 \u21d2 \u02d8U0 in (D, J1); (ii) (\u02d8Z\nn\n, \u02d8R\nn\n, \u02d8V n\n0 ) \u21d2\n(\u02d8Z, \u02d8R, \u02d8V0) in (DK(K+1)+1, W J1).\nWe defer a detailed proof of the lemma to Section A.2.1.\nThe following processes are all well-defined deterministic functions on [0 , 1]\nn\u22121\n2 (\u03bbn)\u22121(\u230ant\u230b \u2212nt), n \u22121\n2\nKX\nk=1\npn\nk\n\u00b5n\nk\n(\u230ant\u230b \u2212nt), n \u22121\n2 pn\nkqn\nkl(\u230ant\u230b \u2212nt), n \u22121\n2\nKX\nk=1\npn\nk\n\u00b5n\nk\nqn\nkl(\u230ant\u230b \u2212nt).\nAssumption B and n\u22121/2 supt\u2208[0,1](\u230ant\u230b \u2212nt) \u2192 0 imply that all of them converge to 0 in ( D, J1).\nUsing the jointly weak convergence with a deterministic limit [68, Theorem 11.4.5], continuity of\naddition [68, Theorem 4.1] by almost-sure continuity of all limits, and the continuous mapping\ntheorem, it follows that there exist Brownian motions \u02dcU0 and ( \u02dcZ, \u02dcR, \u02dcV0) such that (i) \u02dcUn\n0 \u21d2 \u02dcU0 in\n(D, J1); (ii) ( \u02dcZ\nn\n, \u02dcR\nn\n, \u02dcV n\n0 ) \u21d2 (\u02dcZ, \u02dcR, \u02dcV0) in (DK(K+1)+1, W J1).\nSince {un\ni } and {(vn\ni , Xn\ni , Yn\ni )} are independent (Assumption A (ii)), we can use the following\nresult [68, Theorem 11.4.4] to obtain our desired jointly weak convergence in Lemma 3.\nLemma 9 (Joint weak convergence for independent random elements) . Let Xn and Yn be inde-\npendent random elements of separable metric spaces (S\u2032, m\u2032) and (S\u2032\u2032, m\u2032\u2032) for each n \u2265 1. Then,\nthere is joint convergence in distribution\n(Xn, Yn) \u21d2 (X, Y) in S\u2032 \u00d7 S\u2032\u2032\nif and only if Xn \u21d2 X in S\u2032 and Yn \u21d2 Y in S\u2032\u2032.\nA.2.1 Proof of Lemma 8\nTo utilize the martingale FCLT (Lemma 5), we extend\u02d8Un\n0 and (\u02d8Z\nn\n, \u02d8R\nn\n, \u02d8V n\n0 ) to D[0,\u221e) and DK(K+1)+1\n[0,\u221e) ,\nrespectively, and establish individual weak convergence for these extended stochastic processes. We\ncan get the desired result by restricting the extended stochastic processes to the time interval [0, 1].\nWe establish weak convergence of the extended \u02d8Un\n0 and ( \u02d8Z\nn\n, \u02d8R\nn\n, \u02d8V n\n0 ) separately. To show the\nformer, note that {un\ni : i \u2265 1} are i.i.d. random variables with mean ( \u03bbn)\u22121 by Assumptions A.\nEvidently,{\u02d8Un\n0 : n \u2208 N} is a martingale with respect to the natural filtration and satisfies\u02d8Un\n0 (0) = 0.\nIt thus suffices to validate the conditions (i) and (ii) of Lemma 5. To verify condition (i), use the\nshorthand \u2206n\ni := |un\ni \u2212 (\u03bbn)\u22121| to write\nEn[J( \u02d8Un\n0 , t)2] = n\u22121En\u0002\nmax\n1\u2264i\u2264\u230ant\u230b\n(\u2206n\ni )2\u0003\n\u2264 En\u0002\nmax\n1\u2264i\u2264\u230ant\u230b\n(\u2206n\ni )21\n\b\n(\u2206n\ni )2 \u2265 \u221an\n\t\u0003\n+ 1\u221an.\n37",
            "source": "prompt",
            "quality_score": 0.0,
            "metadata": {
              "content_type": [
                "Other"
              ],
              "difficulty_level": 4,
              "retrieval_hints": [
                "What are the proofs related to diffusion limits?",
                "How are heavy traffic lower bounds established?"
              ],
              "summary": "This section contains appendices detailing various proofs related to diffusion limits and heavy traffic lower bounds in queueing theory."
            }
          },
          {
            "chunk_id": "prompt_37",
            "title": "__auto__",
            "text": "From uniform integrability (Assumption H), we have En[J( \u02d8Un\n0 , t)] \u2264\n\u0000\nEn\u0002\n|J( \u02d8Un\n0 , t)|2\u0003\u00011/2 \u2192 0. To\nverify condition (ii), first truncate the triangular array {|un\ni \u2212 (\u03bbn)\u22121|2 : i \u2208 N, n\u2208 N} uniformly\nwith a constant using the uniform integrability (Assumption H), and apply the triangular weak law\nof large numbers (WLLN) [18, Theorem 2.2.6] on the truncated array, with a choice of bn := n in\nthat theorem, to obtain\n[ \u02d8Un\n0 , \u02d8Un\n0 ](t) = n\u22121\n\u230ant\u230bX\ni=1\n(un\ni \u2212 \u03bb\u22121\nn )2 p\n\u2192 cut where cu := lim\nn\u2192\u221e\nVar(un\n1 ) = \u03b1u \u2212 (\u03bb)\u22122.\nWe now show the weak convergnece of Gn := ( \u02d8Z\nn\n, \u02d8R\nn\n, \u02d8V n\n0 ). We have Gn(0) = 0 and by\nAssumption A, {(Y n\ni , Xn\ni , vn\ni ) : i \u2208 N} are i.i.d. and Xn\ni is independent of vn\ni given Y n\ni . Therefore,\nby conditioning on Y n\ni , we have that for all i \u2265 1,\nEn[Y n\nikY n\nil] = pn\nkqn\nkl, En[Y n\nilvn\ni ] =\nKX\nk=1\npn\nk\n\u00b5n\nk\nqn\nkl, En[vn\ni ] =\nKX\nk=1\npn\nk\n\u00b5n\nk\n,\nwhich indicates that Gn is a martingale with respect to the natural filtration. To apply Lemma 5\ntowards Gn, we now validate its conditions (i) and (ii). Using a similar argument as above, uniform\nintegrability yields condition (i) of Lemma 5\nEn[|J( \u02d8V n\n0 , t)|] \u2192 0, En[J( \u02d8Z\nn\nkl, t)] \u2192 0, En[J( \u02d8R\nn\nl , t)] \u2192 0 (A.5)\nfor all k, l\u2208 [K]. Similarly, the triangular WLLN gives condition (ii)\n[ \u02d8V n\n0 , \u02d8V n\n0 ](t) \u21d2 cvt, [ \u02d8Zn\nkl, \u02d8Zn\nrs](t) \u21d2 c(k,l),(r,s)t, [ \u02d8Rn\nl , \u02d8Rn\ns ](t) \u21d2 cl,st,\n[ \u02d8V n\n0 , \u02d8Zn\nkl](t) \u21d2 c0,k,lt, [ \u02d8V n\n0 , \u02d8Rn\nl ](t) \u21d2 c0,lt, [ \u02d8Zn\nkl, \u02d8Rn\ns ](t) \u21d2 ck,l,st,\nwhere\ncv :=\nKX\nk=1\npk\u03b1v,k \u2212 (\nKX\nk=1\npk/\u00b5k)2 c(k,l),(r,s) :=\nn pkqkl(1 \u2212 pkqkl) if ( k, l) = (r, s)\n\u2212pkqklprqrs if (k, l) \u0338= (r, s)\ncl,s :=\n\uf8f1\n\uf8f4\uf8f4\uf8f2\n\uf8f4\uf8f4\uf8f3\nKP\nk=1\npkqkl\u03b1v,k \u2212\n\u0000 KP\nk=1\npkqkl\n\u00b5k\n\u00012 if l = s\n\u2212\n\u0000 KP\nk=1\npkqkl\n\u00b5k\n\u0001\n(\nKP\nk=1\npkqks\n\u00b5k\n\u0001\nif l \u0338= s\nc0,k,l :=\nKX\nk=1\npkqkl\n\u00b5k\n\u2212\n\u0010 KX\nk=1\npk\n\u00b5k\n\u0011\u0010 KX\nk=1\npkqkl\n\u0011\nc0,l :=\nKX\nk=1\npkqkl\u03b1v,k \u2212\n\u0010 KX\nk=1\npk\n\u00b5k\n\u0011\u0010 KX\nk=1\npkqkl\n\u00b5k\n\u0011\nck,l,s :=\n\uf8f1\n\uf8f4\uf8f4\uf8f2\n\uf8f4\uf8f4\uf8f3\nKP\nk=1\npkqkl\n\u00b5k\n\u2212\n\u0000 KP\nk=1\npkqkl\n\u0001\n(\nKP\nk=1\npkqkl\n\u00b5k\n\u0001\nif l = s\n\u2212\n\u0000 KP\nk=1\npkqkl\n\u0001\n(\nKP\nk=1\npkqks\n\u00b5k\n\u0001\nif l \u0338= s\nA.3 Proof of Lemma 4\nFrom the Skorohod representation (Lemma 6), there exist stochastic processes defined on some com-\nmon probability space (\u2126copy, Fcopy, Pcopy), ( \u02dcUn\n0 , \u02dcZ\nn\n, \u02dcR\nn\n, \u02dcV\nn\n0 ), \u2200 n \u2265 1 and (\u02dcU0, \u02dcZ, \u02dcR, \u02dcV 0), such that\n( \u02dcUn\n0 , \u02dcZ\nn\n, \u02dcR\nn\n, \u02dcV\nn\n0 ) and ( \u02dcU0, \u02dcZ, \u02dcR, \u02dcV 0) are identical in distribution with their original counterparts\nand\n( \u02dcUn\n0 , \u02dcZ\nn\n, \u02dcR\nn\n, \u02dcV\nn\n0 ) \u2192 ( \u02dcU0, \u02dcZ, \u02dcR, \u02dcV 0) in ( DK(K+1)+2, W J1), Pcopy-a.s..\n38",
            "source": "prompt",
            "quality_score": 0.0,
            "metadata": {
              "content_type": [
                "Other"
              ],
              "difficulty_level": 4,
              "retrieval_hints": [
                "What are the proofs related to diffusion limits?",
                "How are heavy traffic lower bounds established?"
              ],
              "summary": "This section contains appendices detailing various proofs related to diffusion limits and heavy traffic lower bounds in queueing theory."
            }
          },
          {
            "chunk_id": "prompt_38",
            "title": "__auto__",
            "text": "Or equivalently, with probability one\ndp\n\u0000\n( \u02dcUn\n0 , \u02dcZ\nn\n, \u02dcR\nn\n, \u02dcV\nn\n0 ), ( \u02dcU0, \u02dcZ, \u02dcR, \u02dcV 0)\n\u0001\n\u2192 0,\nwhere dp(\u00b7, \u00b7) is the product J1 metric. By definition of dp(\u00b7, \u00b7), each coordinate of ( \u02dcUn\n0 , \u02dcZ\nn\n, \u02dcR\nn\n, \u02dcV\nn\n0 )\nconverges to the limiting process in ( D, J1) Pcopy-a.s.. Since ( \u02dcU0, \u02dcZ, \u02dcR, \u02dcV 0) is a multidimensional\nBrownian motion, ( \u02dcU0, \u02dcZ, \u02dcR, \u02dcV 0) is continuous Pcopy-a.s.. By Lemma 7, Pcopy-almost surely, every\ncoordinate of ( \u02dcU0, \u02dcZ, \u02dcR, \u02dcV 0) converges to the limiting process in (D, \u2225\u00b7\u2225 ). This completes our proof.\nB Proofs of results in Section 3.1\nWe show convergence diffusion-scaled versions of the exogenous processes associated with predicted\nclasses in Section B.1. Then, we provide a sequence of interim results required for us to prove\nProposition 1 in Section B.3.1.\nWe begin by extending Lemma 4 to include the arrival process. For any system n, let An\n0 (t) :=\nmax{m : Un\n0 (m) \u2264 t}, \u2200 t \u2208 [0, n] be the total number of jobs that arrive in the system up to time\nt, and\n\u02dcAn\n0 (t) = n\u22121/2\u0002\nAn\n0 (nt) \u2212 \u03bbnnt\n\u0003\n, t\u2208 [0, 1]. (B.1)\nBy definition, An\n0 (t) = max {j \u2208 N : Un\n0 (j) \u2264 t}. By Lemma 4, \u02dcU\nn\n0 \u2192 \u02dcU0 \u2208 C; since the limiting\nfunction is continuous, convergence in weak M2 topology is equivalent to convergence in uniform\nmetric [68, Corollary 12.11.1]. Using the asymptotic equivalence between counting and inverse\nprocesses with centering [68, Corollary 13.8.1], convergence of \u02dcA\nn\n0 follows from convergence of \u02dcU\nn\n0 .\nLemma 10 (Uniform convergence II). Suppose that Assumptions A, B, and H hold. Then, there\nexists a multidimensional Brownian motion ( \u02dcA0, \u02dcU0, \u02dcZ, \u02dcR, \u02dcV 0) such that\n( \u02dcAn\n0 , \u02dcUn\n0 , \u02dcZ\nn\n, \u02dcR\nn\n, \u02dcV\nn\n0 ) \u2192 ( \u02dcA0, \u02dcU0, \u02dcZ, \u02dcR, \u02dcV 0) in (DK(K+1)+3, \u2225 \u00b7 \u2225), Pcopy-a.s. (B.2)\nB.1 Convergence of arrival and service processes of predicted classes\nWe formally define the arrival and service processes associated predicted classes, and provide corre-\nsponding diffusion limits in Proposition 6. Given a classifier f\u03b8, suppose that Assumption B holds\nand consider system n operating in t \u2208 [0, n]. Recall un\nl,j and vn\nl,j are the interarrival and service\ntimes of the jth arriving job in predicted class l.\nDefinition 10 (Arrival and service processes of predicted classes II) .\n(i) (Arrival Process) Let An\nkl(t) := PAn\n0 (t)\ni=1 Y n\nikY n\nil be the number of jobs from real class k pre-\ndicted as class l among jobs arriving up to time t \u2208 [0, n], \u00afAn\nkl(t) := \u03bbnpn\nkqn\nklt and \u00afAkl(t) :=\n\u03bbpkqklt, t \u2208 [0, 1] be the first-order approximation processes, and \u02dcA\nn\nkl(t) = n\u22121/2[An\nkl(nt) \u2212\nn \u00afAn\nkl(t)] t \u2208 [0, 1] be the diffusion-scaled process. LetAn\nl (t) := PK\nk=1 An\nkl(t) = PAn\n0 (t)\ni=1 Y n\nil be the\nnumber of jobs predicted as class l among jobs arriving up to time t \u2208 [0, n], \u00afAn\nl (t) := \u03bbnpn\nl t\nand \u00afAl(t) := \u03bbplt, t \u2208 [0, 1] be first-order approximations, and \u02dcA\nn\nl (t) := PK\nk=1 \u02dcA\nn\nkl(t) =\nn\u22121/2\nh\nAn\nl (nt) \u2212n \u00afAn\nl (t)\ni\nwith t \u2208 [0, 1] be the diffusion-scaled process. Here, the occurrence of\npredicted class l is denoted by pn\nl := PK\nk=1 pn\nkqn\nkl and pl := PK\nk=1 pkqkl.\n39",
            "source": "prompt",
            "quality_score": 0.0,
            "metadata": {
              "content_type": [
                "Other"
              ],
              "difficulty_level": 4,
              "retrieval_hints": [
                "What are the proofs related to diffusion limits?",
                "How are heavy traffic lower bounds established?"
              ],
              "summary": "This section contains appendices detailing various proofs related to diffusion limits and heavy traffic lower bounds in queueing theory."
            }
          },
          {
            "chunk_id": "prompt_39",
            "title": "__auto__",
            "text": "(ii) (Sum of Interarrival Time) Let Un\nl (t) := P\u230at\u230b\nj=1 un\nl,j, t \u2208 [0, n] be the sum of interarrival\ntimes among the first \u230at\u230b jobs predicted as class l, \u00afUl(t) := ( \u03bbpl)\u22121t, t \u2208 [0, 1] be the first-\norder approximation, and \u02dcU\nn\nl (t) = n\u22121/2\u0002\nUn\nl (nt) \u2212 n \u00afUn\nl (t)\n\u0003\n, t \u2208 [0, 1] be the corresponding\ndiffusion-scaled process where \u00afUn\nl (t) := (\u03bbnpn\nl )\u22121t.\n(iii) (Sum of Service Time) Let V n\nl (t) := P\u230at\u230b\nj=1 vn\nl,j, t\u2208 [0, n] be the sum of service times among the\nfirst \u230at\u230b jobs predicted as class l, \u00afV n\nl (t) := (\u00b5n\nl )\u22121t and \u00afV l(t) := (\u00b5l)\u22121t, t\u2208 [0, 1] be the first-\norder approximation and \u02dcV\nn\nl (t) = n\u22121/2\nh\nV n\nl (nt) \u2212 n \u00afV n\nl (t)\ni\n, t \u2208 [0, 1], be the corresponding\ndiffusion-sclaed process. Here, (\u00b5l)\u22121 := PK\nk=1\npkqkl\npl\n1\n\u00b5k\nand (\u00b5n\nl )\u22121 := PK\nk=1\npn\nk qn\nkl\npn\nl\n1\n\u00b5n\nk\nare the\nexpected service times of an arbitrary job predicted as class l.\n(iv) (Service Process) Let Sn\nl (t) := max{j \u2208 N : V n\nl (j) \u2264 t}, t \u2208 [0, n] be the number of predicted\nclass l jobs served during [0, t] time units, \u00afSn\nl (t) := \u00b5n\nl t and \u00afSl(t) := \u00b5lt, t \u2208 [0, 1] be the\nfirst-order approximation, and \u02dcS\nn\nl := n\u22121/2[Sn\nl (nt) \u2212 n \u00afSn\nl (t)], t \u2208 [0, 1] be the corresponding\ndiffusion-scaled process.\nFor simplicity, we also use the vector processes \u02dcA\nn\n= ( \u02dcA\nn\nl )l, \u02dcU\nn\n= ( \u02dcU\nn\nl )l, \u02dcS\nn\n= ( \u02dcS\nn\nl )l, and \u02dcV\nn\n=\n( \u02dcV\nn\nl )l to denote the second-order/diffusion-scaled processes.\nProposition 6 plays a major role in our analysis of the endogenous processes in Section B.3. We\nuse the little-o notation on(1) to denote uniform convergence over t \u2208 [0, 1] as n \u2192 +\u221e.\nProposition 6 (Convergence of exogenous processes of predicted classes) . Given a classifier f\u03b8,\nsuppose Assumptions A, B and H hold. There is a Brownian motion ( \u02dcA, \u02dcU, \u02dcS, \u02dcV) such that\n( \u02dcA\nn\n, \u02dcU\nn\n, \u02dcS\nn\n, \u02dcV\nn\n) \u2192 ( \u02dcA, \u02dcU, \u02dcS, \u02dcV), (B.3)\nand for any predicted class l \u2208 [K]\nAn\nl (nt) = n \u00afAn\nl (t) + n1/2 \u02dcA\nn\nl (t) + on(n1/2),\nUn\nl (nt) = n \u00afUn\nl (t) + n1/2 \u02dcU\nn\nl (t) + on(n1/2),\nSn\nl (nt) = n \u00afSn\nl (t) + n1/2 \u02dcS\nn\nl (t) + on(n1/2),\nV n\nl (nt) = n \u00afV n\nl (t) + n1/2 \u02dcV\nn\nl (t) + on(n1/2),\n(B.4)\nn\u22121/2 sup\n1\u2264j\u2264An\nl (n)\nun\nl,j \u2192 0, n \u22121/2 sup\n1\u2264j\u2264An\nl (n)\nvn\nl,j \u2192 0. (B.5)\nProof Recalling that \u02dcA0, \u02dcZkl are Brownian motions (B.2), we begin by showing the limit\n\u02dcA\nn\nkl \u2192 \u02dcAkl := \u02dcZkl \u25e6 \u03bbe + pkqkl\n\u02dcA0, \u02dcA\nn\nl \u2192 \u02dcAl :=\nKX\nk=1\n\u02dcAkl =\nKX\nk=1\n\u02dcZkl \u25e6 \u03bbe + pl\n\u02dcA0,\n\u02dcU\nn\nl \u2192 \u02dcUl := \u2212\n\u0010\n\u03bb\nKX\nk=1\npkqkl\n\u0011\u22121\n\u02dcAl\n\u0010\u0000\n\u03bb\nKX\nk=1\npkqkl\n\u0001\u22121e\n\u0011\n.\nRecall from Definition 8 and Definition 10 that An\nkl = Zn\nkl \u25e6 An\n0 and\n\u02dcA\nn\nkl(t) = n\u22121/2[An\nkl(nt) \u2212 \u03bbnpn\nkqn\nklnt] = \u02dcZ\nn\nkl(n\u22121An\n0 (nt)) + pn\nkqn\nkl\n\u02dcAn\n0 (t).\n40",
            "source": "prompt",
            "quality_score": 0.0,
            "metadata": {
              "content_type": [
                "Other"
              ],
              "difficulty_level": 4,
              "retrieval_hints": [
                "What are the proofs related to diffusion limits?",
                "How are heavy traffic lower bounds established?"
              ],
              "summary": "This section contains appendices detailing various proofs related to diffusion limits and heavy traffic lower bounds in queueing theory."
            }
          },
          {
            "chunk_id": "prompt_40",
            "title": "__auto__",
            "text": "Since n\u22121An\n0 (n\u00b7) \u2192 \u03bbe, continuity of the composition function [68, Theorem 13.2.1] and the con-\ntinuous mapping theorem yields\n\u02dcA\nn\nkl \u2192 \u02dcZkl \u25e6 \u03bbe + pkqkl\n\u02dcA0 and \u02dcA\nn\nl \u2192 \u02dcAl.\nSince all limit have continuous sample paths, convergence in weakM2 topology is equivalent to uni-\nform convergence [68, Corollary 12.11.1]. Asymptotic equivalence of counting and inverse processes\n(with centering) gives convergence of \u02dcU\nn\nl [68, Corollary 13.8.1].\nUsing a nearly identical argument, we show convergence of \u02dcS\nn\nl and \u02dcV\nn\nl\n\u02dcV\nn\nl \u2192 \u02dcV l := \u02dcRl \u25e6 (pl)\u22121e + pl(\u00b5l)\u22121 \u02dcMl,\n\u02dcS\nn\nl \u2192 \u02dcSl := \u2212\u00b5l\n\u02dcV l \u25e6 \u00b5le = \u2212\u00b5l\n\u02dcRl \u25e6 (pl)\u22121\u00b5le \u2212 pl\n\u02dcMl \u25e6 \u00b5le,\nwhere Mn\nl (t) is the total number of job arriving in the system until arrival of \u230at\u230b jobs predicted as\nl \u2208 [K] and \u02dcM\nn\nl (t) is the corresponding diffusion-scaled process,\nMn\nl (t) := max\nn\nm \u2265 0 :\nmX\ni=1\nY n\nil \u2264 t\no\n= max\nn\nm \u2265 0 :\nKX\nk=1\nZn\nkl(m) \u2264 t\no\n, \u2200 t \u2208 [0, n],\n\u02dcM\nn\nl := n\u22121/2[Mn\nl (nt) \u2212 (pn\nl )\u22121nt], \u2200 t \u2208 [0, 1].\n(B.6)\n(Recall pn\nl = PK\nk=1 pn\nkqn\nkl.) Mn\nl is closely related to PK\nk=1 \u02dcZkl and can be understood as a counting\nprocess with \u201cinterarrival times\u201d being {Y n\nil : i \u2265 1}.\nRepresent the service partial sum V n\nl as a composition of Rn\nl with the counting process Mn\nl\nV n\nl (t) = Rn\nl (Mn\nl (t)) =\nMn\nl (t)X\ni=1\nY n\nilvn\ni , \u2200 t \u2208 [0, n] (Definitions 8 and 10) .\nSince \u02dcZ\nn\nkl \u2192 \u02dcZkl \u2208 C, a similar argument as before gives\n\u02dcM\nn\nl \u2192 \u02dcMl := \u2212p\u22121\nl\n\u0010 KX\nk=1\n\u02dcZkl\n\u0011\n\u25e6 p\u22121\nl e \u2208 C.\nFrom the continuous mapping theorem, we have the convergence of \u02dcV\nn\nl and \u02dcS\nn\nl .\nB.2 Dominance of p-FCFS and work-conserving policies\nThe results on the endogenous processes in Proposition 1 and the lower bound in Theorem 2 will be\nobtained assuming p-FCFS and work-conserving policies. We justify focusing on the set of p-FCFS\nand work-conserving policies.\np-FCFS Given a queueing system n and a feasible policy, we can derive an associated feasible\np-FCFS policy by swapping the service orders within each predicted class when the class has no\npreviously preempted job. We show that the latter policy has stochastically smaller cumulative\ncost function \u02dcJn(t) for all t \u2208 [0, 1]. To do so, we analyze the distribution of the cost function\nunder a modified data generating process governed by a new probability measure Qn such that\n41",
            "source": "prompt",
            "quality_score": 0.0,
            "metadata": {
              "content_type": [
                "Other"
              ],
              "difficulty_level": 4,
              "retrieval_hints": [
                "What are the proofs related to diffusion limits?",
                "How are heavy traffic lower bounds established?"
              ],
              "summary": "This section contains appendices detailing various proofs related to diffusion limits and heavy traffic lower bounds in queueing theory."
            }
          },
          {
            "chunk_id": "prompt_41",
            "title": "__auto__",
            "text": "the distribution of \u02dcJn\n\u03c0n remains the same as the original one under Pn. The idea is to define the\nclasses of jobs that govern the cost functions and service time distributions to be invariant under\npermutation within each predicted class, and use the convexity argument on the cost functions.\nWe assume that under Qn, {(un\ni , Xn\ni , Yn\ni , Yn\ni ) : i \u2208 N} are generated in the same way as in\nSection 2, but service times are generated differently. We introduce {( \u02c6Yn\njl, vn\njl) : j \u2208 N} that\nare indexed according to the order of being served rather than the order of arrivals within each\npredicted class l \u2208 [K]. For any job that is served as the jth distinct job within predicted class l\nin system n, the service time is realized as vn\njl in a tuple ( \u02c6Yn\njl, vn\njl), where \u02c6Yn\njl := ( \u02c6Y n\njl,1, . . . ,\u02c6Y n\njl,K )\ndenotes the one-hot encoding that determines the distribution of vn\njl as well as the cost function.\nIn the sequel, we employ the subscripts i and j to signify indexing according to the arrival and\nservice order within each predicted class, respectively.\nWe assume that for any queueing system n and predicted class l \u2208 [K],\n(i) { \u02c6Yn\njl, vn\njl : j \u2208 N} are i.i.d. random variables;\n(ii) { \u02c6Yn\njl, vn\njl : j \u2208 N} are independent of {(un\ni , Xn\ni , Yn\ni , Yn\ni ) : i \u2208 N}.\nNote that when swapping service orders between jobs within each predicted class, (\u02c6Yn\njl, vn\njl) remains\nunchanged in each sample path in Qn\u2014a key property to be utilized in our proof. To connect with\nthe original data generating process under Pn, we define the distribution of ( \u02c6Yn\n1l, vn\n1l) as\nQn[ \u02c6Y n\n1l,k = 1, vn\n1l \u2264 x] := Pn[Y n\n1k = 1, vn\n1 \u2264 x | Y n\n1l = 1], (B.7)\nfor any k \u2208 [K], x\u2208 R, where Pn[Y n\n1k = 1 , vn\n1 \u2264 x | Y n\n1l = 1] =\npn\nk qn\nklPK\nr=1 pnr qn\nrl\nPn[vn\n1 \u2264 x|Y n\n1k = 1]\nby conditional independence between vn\n1 and Y n\n1l given Y n\n1k in Assumption A. Moreover, we use a\nmodified cumulative cost function \u02c6Jn\n\u03c0n(t; Qn), where for any job that is served as the jth distinct\njob within predicted class l, the cost is incurred according to its \u201canalytical class label\u201d \u02c6Yn\njl and\ndefined by Cn\nk: \u02c6Y n\njl,k=1(\u00b7).\nLemma 11 (p-FCFS). Given a classifier f\u03b8 and a sequence of feasible policies {\u03c0n}, suppose that\nAssumptions A B, H, and C hold. Then, for any queueing system n, there exists a feasible p-FCFS\npolicy \u03c0n,p-FCFS such that \u02dcJn\n\u03c0n,p-FCFS(t; Qn) \u2264st \u02dcJn\n\u03c0n(t; Qn), \u2200 t \u2208 [0, 1].\nProof Our proof uses a similar idea alluded in the proof of [40, Theorem 2] and provides a\nrigorous justification. Given a feasible policy \u03c0n in system n \u2208 N, we can define an associated\np-FCFS policy, say \u03c0\u2032\nn, by applying the following basic operation: if there exists the jth arriving\njob in predicted class l \u2208 [K] that starts to be served by \u03c0n before the ith arriving job in the\nsame predicted class with Un\nl (i) < Un\nk(j) and i being the smallest such index, then we swap service\norders of the two jobs. It suffices to show that Pn[ \u02dcJn\n\u03c0\u2032n\n(t; Qn) > x] \u2264 Pn[ \u02dcJn\n\u03c0n(t; Qn) > x] for all\nt \u2208 [0, 1], x\u2208 R.\nWe first claim that for all t \u2208 [0, 1], \u02dcJn\n\u03c0n(t; Qn) under Pn has the same marginal distribution as\nthat of \u02c6Jn\n\u03c0n(t; Qn) under Qn. That is,\nPn[ \u02dcJn\n\u03c0n(t; Qn) > x] = Qn[ \u02c6J\u03c0n(t; Qn) > x], \u2200 x \u2208 R. (B.8)\nThe reason is that under Pn and Qn, the actual service time and the true/analytical class label\nof a job that determines the cost function to be applied are not known until the job starts to be\n42",
            "source": "prompt",
            "quality_score": 0.0,
            "metadata": {
              "content_type": [
                "Other"
              ],
              "difficulty_level": 4,
              "retrieval_hints": [
                "What are the proofs related to diffusion limits?",
                "How are heavy traffic lower bounds established?"
              ],
              "summary": "This section contains appendices detailing various proofs related to diffusion limits and heavy traffic lower bounds in queueing theory."
            }
          },
          {
            "chunk_id": "prompt_42",
            "title": "__auto__",
            "text": "served. Moreover, given arrival times {Un\nl (i) : i \u2208 N} in predicted class l \u2208 [K], service times and\ntrue/analytical class labels of waiting jobs are i.i.d. as (B.7) under the two probability measures.\nThe latter implies that given the same realization of {Un\nl (i) : i \u2208 N, l\u2208 [K]}, the conditional\ndistributions of \u02dcJ\u03c0n(\u00b7; Qn) and \u02c6J\u03c0n(\u00b7; Qn) are identical.\nBy (B.8), it suffices to show that \u03c0\u2032\nn induced from \u03c0n by the basic operation satisfies\nQn\u0002 \u02c6Jn\n\u03c0\u2032n\n(t; Qn) \u2264 \u02c6Jn\n\u03c0n(t; Qn), \u2200 t \u2208 [0, 1]\n\u0003\n= 1. (B.9)\nTo prove (B.9), fix a sample path under Qn in system n. Suppose that at some time nt\u2032 \u2208 [0, n],\nthere exist two jobs, i1 and i2, that arrived as the i1th and i2th job in predicted class l \u2208 [K],\nrespectively, with Un\nl (i1) < Un\nl (i2), and have not been served at all. Suppose that \u03c0n chooses to\nserve i2 at time nt as the j2th distinct job served in predicted class l, and starts to serve i1 later as\nthe j1th distinct job in that class with j1 > j2. Let \u2206 vn\nl (j2, j1) := Pj1\u22121\nr=j2+1 vn\nrl be the summation\nof service times for jobs in predicted class l that are served between i1 and i2. Also, suppose\n\u02c6Y n\nj1,l,k1 = \u02c6Y n\nj2,l,k2 = 1 for some k1, k2 \u2208 [K]. Note that \u2206 vn\nl (j2, j1), vn\nj2,l, vn\nj1,l, \u02c6Y n\nj1,l, and \u02c6Y n\nj2,l are\nidentical regardless of which job is chosen for service at time nt\u2032. Similarly, under the conditions\non preemption in Section 3.1, waiting times of jobs incurred by preemption during their service also\nremain the same independently of the job chosen for service at time nt\u2032. Let \u2206 wn\nl (j2, j1) be the\nsummation of waiting times incurred by preemption on jobs served between i1 and i2 in predicted\nclass l, and let wn\nj1,l and wn\nj2,l be the waiting times by preemption on i1 and i2, respectively.\nNow we are ready to show (B.9). We first show that changing service orders of j1 and j2\nimproves the cumulative cost at t = 1. Specifically, the change \u02c6Jn\n\u03c0\u2032n\n(1; Qn) \u2212 \u02c6Jn\n\u03c0n(1; Qn) would be\nh\nCn\nk2\n\u0000\nt\u2032 \u2212 Un\nl (i1) + wn\nj2,l + vn\nj2,l\n\u0001\n\u2212 Cn\nk2\n\u0000\nt\u2032 \u2212 Un\nl (i2) + wn\nj2,l + vn\nj2,l\n\u0001i\n\u2212\nh\nCn\nk1\n\u0000\nt\u2032 \u2212 Un\nl (i1) + wn\nj2,l + vn\nj2,l + \u2206wn\nl (j2, j1) + \u2206vn\nl (j2, j1) + wn\nj1,l + vn\nj1,l\n\u0001\n\u2212 Cn\nk1\n\u0000\nt\u2032 \u2212 Un\nl (i2) + wn\nj2,l + vn\nj2,l + \u2206wn\nl (j2, j1) + \u2206vn\nl (j2, j1) + wn\nj1,l + vn\nj1,l\n\u0001i\n\u2264 0,\nwhere the inequality follows from convexity of Cn\nk1, Cn\nk2 and Un\nl (i1) < Un\nl (i2), similarly to the\nproof [63, Proposition 1]. In fact, one can observe that the cost reduction holds true for all t \u2208 [0, 1]\nsuch that both jobs i1 and i2 are present in the system at time nt, and thus (B.9) follows. This\ncompletes our proof.\nWork-Conserving For all system n and any feasible policy \u03c0n, we can always create a work-\nconserving counterpart policy by having the server during an idle time to serve any waiting job,\nif available. Since preemption is allowed without incurring additional costs, the server can pause\nservice and come back to the preempted job later, ensuring that the cumulative cost does not\nincrease as stated in the following lemma; see further discussion in [63, Section 2].\nLemma 12 (Work-Conserving). Given a classifier f\u03b8 and a sequence of feasible policy {\u03c0n}, sup-\npose that Assumptions A and C hold. Then, for any queueing system n, there exists a feasible\nwork-conserving policy \u03c0n,work-conserving such that\n\u02dcJn\n\u03c0n,work-conserving(t; Qn) \u2264 \u02dcJn\n\u03c0n(t; Qn), \u2200 t \u2208 [0, 1], Pn-a.s..\n43",
            "source": "prompt",
            "quality_score": 0.0,
            "metadata": {
              "content_type": [
                "Other"
              ],
              "difficulty_level": 4,
              "retrieval_hints": [
                "What are the proofs related to diffusion limits?",
                "How are heavy traffic lower bounds established?"
              ],
              "summary": "This section contains appendices detailing various proofs related to diffusion limits and heavy traffic lower bounds in queueing theory."
            }
          },
          {
            "chunk_id": "prompt_43",
            "title": "__auto__",
            "text": "B.3 Convergence of the endogenous processes of predicted classes\nTo prove Proposition 1, we formally define processes that are endogenous to scheduling policies for\npredicted classes.\nDefinition 11 (Endogenous processes). (i) (Total workload process) Let Ln\nl (t) be the total ser-\nvice time requested by all jobs predicted as class l and arriving by time t \u2208 [0, n], and \u02dcL\nn\nl (t)\nbe the corresponding diffusion-scaled process\nLn\nl (t) =\nAn\n0 (t)X\ni=1\nY n\nilvn\ni , t \u2208 [0, n], \u02dcL\nn\nl (t) = n\u22121/2\nh\nLn\nl (nt) \u2212 \u03bbn\nKX\nk=1\npn\nk\n\u00b5n\nk\nqn\nkl \u00b7 nt\ni\n, t \u2208 [0, 1].\n(ii) (Cumulative total input process) Let Ln\n+(t) = P\nl Ln\nl (t), t\u2208 [0, n] be the cumulative total input\nprocess and \u02dcLn\n+(t) := PK\nl=1 \u02dcL\nn\nl (t), t \u2208 [0, 1] be the corresponding diffusion-scaled process, i.e.,\n\u02dcLn\n+(t) = n\u22121/2\nh\nLn\n+(nt) \u2212 \u03bbn\nKX\nk=1\npn\nk\n\u00b5n\nk\n\u00b7 nt\ni\n, \u2200 t \u2208 [0, 1].\n(iii) (Policy process) Let Tn\nl (t) be total amount of time during [0, t] that the server allocates to jobs\nfrom predicted class l, and \u02dcT\nn\nl (t) be the corresponding diffusion-scaled process\n\u02dcT\nn\nl (t) = n\u22121/2\nh\nTn\nl (nt) \u2212 \u03bbn\nKX\nk=1\npn\nk\n\u00b5n\nk\nqn\nkl \u00b7 nt\ni\n, t \u2208 [0, 1].\n(iv) (Remaining workload process) Let Wn\nl (t) be the remaining service time requested by jobs pre-\ndicted as class l and present\u2014waiting for service or being served\u2014in the system at time\nt \u2208 [0, n]\nWn\nl (t) = Ln\nl (t) \u2212 Tn\nl (t), t \u2208 [0, n]. (B.10)\nand \u02dcW\nn\nl (t) := n\u22121/2Wn\nl (nt), \u2200 t \u2208 [0, 1] be the corresponding diffusion scaled process.\n(v) (Total remaining workload process) Let Wn\n+(t) = P\nl Wn\nl (t) be the total remaining workload\nprocess and \u02dcWn\n+(t) := n\u22121/2 PK\nl=1 Wn\nl (nt), \u2200 t \u2208 [0, 1] be the corresponding diffusion scaled\nprocess.\n(vi) (Queue length process) Let Nn\nl (t) be the total number of jobs that are predicted as class l and\npresent\u2014waiting for service or being served\u2014in the system at time t \u2208 [0, n], and Nn\nkl(t) be\nthe total number of true class k jobs that are predicted as class l and present in the system\nat time t \u2208 [0, n]. Let \u02dcN\nn\nl (t) := n\u22121/2Nn\nl (nt), \u02dcN\nn\nkl(t) := n\u22121/2Nn\nkl(nt), \u2200 t \u2208 [0, 1] be the\ncorresponding scaled processes.\n(vii) (Sojourn time process) Let \u03c4n\nlj be the sojourn time\u2014the time span between arrival and service\ncompletion\u2013of the jth job of predicted class l. Let \u03c4n\nl (t) = \u03c4n\nl,An\nl (t), \u2200 t \u2208 [0, n] be the sojourn\ntime process where \u03c4n\nl (t) denotes the sojourn time of the latest job predicted as class l and\narriving by time t and \u02dc\u03c4n\nl (t) := n\u22121/2\u03c4n\nl (nt), \u2200 t \u2208 [0, 1] be the corresponding scaled process.\nNote that \u03c4n\nl (Un\nl (i)) = \u03c4n\nl,i and \u03c4n\nl only exhibits jumps at arrival times {Un\nl (i)}\u221e\ni=1 of jobs\npredicted as class l. By definition, \u03c4n\nl is also RCLL. Since Ln\nl is an exogenous process, according to\n44",
            "source": "prompt",
            "quality_score": 0.0,
            "metadata": {
              "content_type": [
                "Other"
              ],
              "difficulty_level": 4,
              "retrieval_hints": [
                "What are the proofs related to diffusion limits?",
                "How are heavy traffic lower bounds established?"
              ],
              "summary": "This section contains appendices detailing various proofs related to diffusion limits and heavy traffic lower bounds in queueing theory."
            }
          },
          {
            "chunk_id": "prompt_44",
            "title": "__auto__",
            "text": "Eq. (B.10), we can also characterize the policy process Tn\nl , or equivalently, the scheduling policies,\nby the remaining workload process Wn\nl . The following results hold under p-FCFS feasible policies:\nNn\nl (t) = An\nl (t) \u2212 Sn\nl (Tn\nl (t)), \u2200 t \u2208 [0, n];\n\u03c4n\nl (t) = inf{s \u2265 0 : Wn\nl (t) \u2264 Tn\nl (t + s) \u2212 Tn\nl (t)}, \u2200 t \u2208 [0, n];\nWn\nl (t) = Tn\nl (t + \u03c4n\nl (t)) \u2212 Tn\nl (t), \u2200 t \u2208 [0, n].\n(B.11)\nWe show the convergence of the scaled input process\u02dcL\nn\nl , which will be used to prove convergence\nof the workload Wn\n+ in Section B.3.1.\nLemma 13 (Convergence of \u02dcL\nn\nl and \u02dcLn\n+). Given a classifier f\u03b8, a sequence of queueing systems,\nand a sequence of feasible policies {\u03c0n}, suppose that Assumptions A, B and H hold. Then, for any\npredicted class l \u2208 [K], we have that\n\u02dcL\nn\nl \u2192 \u02dcLl := \u02dcRl \u25e6 \u03bbe +\nKX\nk=1\npk\n\u00b5k\nqkl\n\u02dcA0, \u02dcLn\n+ \u2192 \u02dcL+ := \u02dcV0 \u25e6 \u03bbe +\nKX\nk=1\npk\n\u00b5k\n\u02dcA0\nas n \u2192 \u221e, where e is the identity function on [0, 1]. Also, for any system n and time t \u2208 [0, 1],\nLn\nl (nt) = \u03bbn\nKX\nk=1\npn\nk\n\u00b5n\nk\nqn\nkl \u00b7 nt + n1/2 \u02dcL\nn\nl (t) + o(n1/2); Ln\n+(nt) = \u03bbn\nKX\nk=1\npn\nk\n\u00b5n\nk\n\u00b7 nt + n1/2 \u02dcLn\n+(t) + o(n1/2).\nProof Note that Ln\nl = Rn\nl \u25e6 An\n0 by Definition 11. Therefore, we have\n\u02dcL\nn\nl (t) = n\u22121/2\nh\nRn\nl (An\n0 (nt)) \u2212\nKX\nk=1\npn\nk\n\u00b5n\nk\nqn\nkl \u00b7 An\n0 (nt)\ni\n+\nKX\nk=1\npn\nk\n\u00b5n\nk\nqn\nkl \u00b7 n\u22121/2\nh\nAn\n0 (nt) \u2212 \u03bbn \u00b7 nt\ni\n= \u02dcR\nn\nl (n\u22121An\n0 (nt)) +\nKX\nk=1\npn\nk\n\u00b5n\nk\nqn\nkl \u00b7 \u02dcAn\n0 (t).\nRecall \u02dcAn\n0 (t) \u2192 \u02dcA0(t) by Lemma 10 and n\u22121An\n0 (n\u00b7) \u2192 \u03bbe by Proposition 6. Since \u03bbe is continuous,\ncontinuity of the composition mapping [68, Theorem 13.2.1] and the continuous mapping theorem\nyields \u02dcL\nn\nl (t) \u2192 \u02dcRl \u25e6 \u03bbe + pl(\u00b5l)\u22121 \u02dcA0. Convergence of \u02dcLn\n+ is a direct consequence of continuous\nmapping theorem and \u02dcLn\n+ = PK\nl=1 \u02dcL\nn\nl by Definition 11.\nB.3.1 Proof of Proposition 1\nWe establish Proposition 1 based on Proposition 6 and Lemma 13. Our approach is similar to\nthe proof of [63, Proposition 2], and we complement the latter with additional details in the\nproof. Since {\u03c0n} is work-conserving, the remaining workload process Wn\n+ can be written as\nWn\n+ = \u03d5(Ln\n+ \u2212e) [68], where \u03d5 is the one-sided reflection mapping. By Lemma 13 and heavy-traffic\n45",
            "source": "prompt",
            "quality_score": 0.0,
            "metadata": {
              "content_type": [
                "Other"
              ],
              "difficulty_level": 4,
              "retrieval_hints": [
                "What are the proofs related to diffusion limits?",
                "How are heavy traffic lower bounds established?"
              ],
              "summary": "This section contains appendices detailing various proofs related to diffusion limits and heavy traffic lower bounds in queueing theory."
            }
          },
          {
            "chunk_id": "prompt_45",
            "title": "__auto__",
            "text": "conditions (Assumption B), for any t \u2208 [0, 1]\n(Ln\n+ \u2212 e)(nt) =\n\u0010\n\u03bbn\nKX\nk=1\npn\nk\n\u00b5n\nk\n\u2212 1\n\u0011\n\u00b7 nt + n1/2 \u02dcL\nn\n+(t) + o(n1/2)\n= n1/2\nh\n\u02dcLn\n+(t) + n1/2\u0000\n\u03bbn\nKX\nk=1\npn\nk\n\u00b5n\nk\n\u2212 1\n\u0001\nt\ni\n+ o(n1/2)\n= n1/2 \u02dcLn\n+(t) + o(n1/2),\nwhere we used n1/2\u0000\n\u03bbn PK\nk=1\npn\nk\n\u00b5n\nk\n\u2212 1\n\u0001\n= on(1) in the final line. Combining with the relation\nWn\n+ = \u03d5(Ln\n+ \u2212 e), we get\nn\u22121/2Wn\n+(nt) = n\u22121/2\u03d5(Ln\n+ \u2212 e)(nt) = \u03d5(n\u22121/2(Ln\n+ \u2212 e)(nt))\n= \u03d5(\u02dcLn\n+(t) + on(1)) = \u03d5(\u02dcLn\n+(t)) + on(1),\nwhere the first line follows from definition of \u03d5, and the last line results from Lipschitz property of\n\u03d5 with the uniform metric [68, Lemma 13.5.1]. Since \u02dcWn\n+(t) := n\u22121/2Wn\n+(nt) in Definition 11, the\nconvergence \u02dcWn\n+ \u2192 \u03d5(\u02dcL+) follows from analysis above and Lemma 13.\nNext, we consider \u02dcW\nn\nl , \u02dcN\nn\nl , and \u02dc\u03c4n\nl . Notice that \u02dcW\nn\nl \u2265 0, PK\nl=1 \u02dcW\nn\nl \u2192 \u03d5(\u02dcL+), and \u03d5(\u02dcL+) is a\ncontinous function on [0 , 1]. Therefore, it is clear that lim sup n \u2225 \u02dcW\nn\nl \u2225 < +\u221e, \u2200 l \u2208 [K]. For \u02dcT\nn\nl ,\nby Definition 11 and Lemma 13, we have that\n\u02dcT\nn\nl (t) = n\u22121/2\nh\nTn\nl (nt) \u2212 \u03bbn\nKX\nk=1\npn\nk\n\u00b5n\nk\n\u00b7 nt\ni\n= n\u22121/2\nh\nLn\nl (nt) \u2212 \u03bbn\nKX\nk=1\npn\nk\n\u00b5n\nk\n\u00b7 nt\ni\n\u2212 n\u22121/2Wn\nl (nt) = \u02dcL\nn\nl (t) + \u02dcW\nn\nl (t),\n(B.12)\nwhere the second line follows from Tn\nl (nt) = Ln\nl (nt) \u2212 Wn\nl (nt) by Definition 11. Since \u02dcL\nn\nl \u2192 \u02dcLl by\nLemma 13, one can check that for any l \u2208 [K], \u02dcT\nn\nl converges if and only if \u02dcW\nn\nl converges. Also,\nlim supn \u2225 \u02dcT\nn\nl \u2225 < +\u221e, \u2200 l \u2208 [K].\nRecalling the relation (B.11), we have Nn\nl (nt) = An\nl (nt) \u2212Sn\nl (Tn\nl (nt)). Using Proposition 6, we\ncan rewrite \u02dcN\nn\nl (t)\n\u02dcN\nn\nl (t) = n\u22121/2[An\nl (nt) \u2212 Sn\nl (Tn\nl (nt))]\n= n1/2 \u00afAn\nl (t) + \u02dcA\nn\nl (t) \u2212 n1/2 \u00afSn\nl (n\u22121Tn\nl (nt)) \u2212 \u02dcS\nn\nl (n\u22121Tn\nl (nt)) + o(1)\nNote that \u00afAn\nl (t) = \u03bbnpn\nl t, \u00afSn\nl (t) = \u00b5n\nl t, and\nn\u22121Tn\nl (nt) = \u03bbn\nKX\nk=1\npn\nkqn\nkl\n\u00b5n\nk\n\u00b7 t + n\u22121/2 \u02dcT\nn\nl (t) + o(n\u22121/2), (B.13)\nwhere n\u22121/2 \u02dcT\nn\nl (t) = o(1) as lim supn \u2225 \u02dcT\nn\nl \u2225 < +\u221e. Therefore, \u02dcN\nn\nl (t) can be rewritten as\n\u02dcN\nn\nl (t) = n1/2\nh\n\u03bbnpn\nl \u00b7 t \u2212 \u00b5n\nl \u03bbn\nKX\nk=1\npn\nkqn\nkl\n\u00b5n\nk\n\u00b7 t\ni\n\u2212 \u00b5n\nl\n\u02dcT\nn\nl (t) + \u02dcA\nn\nl (t) \u2212 \u02dcS\nn\nl\n\u0010\n\u03bbn\nKX\nk=1\npn\nkqn\nkl\n\u00b5n\nk\n\u00b7 t + o(1)\n\u0011\n+ o(1)\n= \u2212 \u00b5n\nl\n\u02dcT\nn\nl (t) + \u02dcA\nn\nl (t) \u2212 \u02dcS\nn\nl\n\u0010\n\u03bbn\nKX\nk=1\npn\nkqn\nkl\n\u00b5n\nk\n\u00b7 t + o(1)\n\u0011\n+ o(1) (B.14)\n46",
            "source": "prompt",
            "quality_score": 0.0,
            "metadata": {
              "content_type": [
                "Other"
              ],
              "difficulty_level": 4,
              "retrieval_hints": [
                "What are the proofs related to diffusion limits?",
                "How are heavy traffic lower bounds established?"
              ],
              "summary": "This section contains appendices detailing various proofs related to diffusion limits and heavy traffic lower bounds in queueing theory."
            }
          },
          {
            "chunk_id": "prompt_46",
            "title": "__auto__",
            "text": "by definition of pn\nl and \u00b5n\nl . Since \u03bbn PK\nk=1\npn\nk qn\nkl\n\u00b5n\nk\n\u00b7 t \u2192 \u03bb PK\nk=1\npkqkl\n\u00b5k\n\u00b7 t \u2208 C, by continuity of\ncomposition [68, Theorem 13.2.1] and continuous mapping theorem, for any l \u2208 [K], \u02dcT\nn\nl converges\nif and only if \u02dcN\nn\nl converges, and lim supn \u2225 \u02dcN\nn\nl \u2225 < +\u221e, \u2200 l \u2208 [K].\nFinally, for \u02dc\u03c4n\nl , once again by (B.11), we have that\n\u02dcW\nn\nl (t) = n\u22121/2[Tn\nl (nt + \u03c4n\nl (nt)) \u2212 Tn\nl (nt)], \u2200 t \u2208 [0, n].\nAccording to the previous result (B.13), we have\n\u02dcW\nn\nl (t) = \u03bbn\nKX\nk=1\npn\nkqn\nkl\n\u00b5n\nk\n\u00b7 \u02dc\u03c4n\nl (t) + \u02dcT\nn\nl (t + n\u22121\u03c4n\nl (nt)) \u2212 \u02dcT\nn\nl (t) + o(n1/2). (B.15)\nFor any predicted classl \u2208 [K], lim supn \u2225 \u02dcW\nn\nl \u2225 < +\u221e and lim supn \u2225 \u02dcT\nn\nl \u2225 < +\u221e, so that lim supn \u2225\u02dc\u03c4n\nl \u2225 <\n+\u221e and n\u22121\u02dc\u03c4n\nl = o(1). Moreover, for any predicted class l \u2208 [K], \u02dc\u03c4n\nl converges if and only if \u02dcW\nn\nl\nconverges.\nB.4 Diffusion limits of the classical queueing model\nWe extend the classical queueing model in Van Mieghem [63] and Mandelbaum and Stolyar [40] in\nthe presence of misclassification errors. Key convergence results analogous to Lemma 4, Proposi-\ntion 6, and Proposition 1 can be shown similarly to our proofs. However, Pc\u00b5-rule in this framework\nbecomes optimal only among p-FCFS policies, leading to a weaker result than Theorem 3 wherein\nthe optimality was established over all feasible policies.\nB.4.1 Diffusion limit in the classical framework\nWe explain a new data generating process given external arrivals from K real classes as in [63, 40].\nFor k \u2208 [K] and n \u2208 N, i.i.d random vectors {(un\nki, Xn\nki, vn\nki) : i \u2208 N} are generated where un\nki be\nan i.i.d interarrival time of the ith arriving job of real class k in system n with a constant arrival\nrate \u03bbn\nk := En[un\nk1] > 0. The tuple ( Xn\nki, vn\nki) is generated independently of un\nki where Xn\nki \u2208 Rd\nrepresents the feature vector of the job, and vn\nki indicates the time required to serve the job. Let\n(\u00b5n\nk)\u22121 := En[vn\nk1] be the expected service time of a class- k job. Let An\nk(t) = max {m : Un\nk (m) \u2264\nt}, t\u2208 [0, n] be the arrival counting process of real class k.\nFor each k \u2208 [K], the predicted class of a real class k job is defined by the one-hot vector Y n\nki :=\nf\u03b8(Xn\nki) = (Y n\nki(1), ..., Yn\nki(K)). The classification probabilities are defined as qn\nkl := Pn[Y n\nk1(l) = 1]\nfor k, l\u2208 [K]. We assume that vn\nki is independent of Xn\nki, implying vn\nki \u22a5 Y n\nki. The data generating\nprocesses and the corresponding heavy traffic conditions are summarized as the following.\nAssumption I (Alternative data generating processes) . For any system n \u2208 N,\n(i) the sequences of random vectors {(un\nki, vn\nki, Xn\nki) : i \u2208 N} are independent over k \u2208 [K];\n(ii) {(un\nki, vn\nki, Xn\nki) : i \u2208 N} is a sequence of i.i.d random vectors for each class k \u2208 [K];\n(iii) {un\nki : i \u2208 N}, {vn\nki : i \u2208 N}, and {Xn\nki : i \u2208 N} are independent for each class k \u2208 [K].\n47",
            "source": "prompt",
            "quality_score": 0.0,
            "metadata": {
              "content_type": [
                "Other"
              ],
              "difficulty_level": 4,
              "retrieval_hints": [
                "What are the proofs related to diffusion limits?",
                "How are heavy traffic lower bounds established?"
              ],
              "summary": "This section contains appendices detailing various proofs related to diffusion limits and heavy traffic lower bounds in queueing theory."
            }
          },
          {
            "chunk_id": "prompt_47",
            "title": "__auto__",
            "text": "Assumption J (Heavy traffic condition). Given a classifier f\u03b8 and a sequence of queueing systems,\nthere exist \u03bbk, \u00b5k \u2208 (0, \u221e) and qkl \u2208 [0, 1] for k, l\u2208 [K] such that PK\nk=1 qkl > 0, \u2200 l \u2208 [K],PK\nk=1\n\u03bbk\n\u00b5k\n= 1, and as n \u2192 \u221e, for all k, l\u2208 [K]\nn1/2\u0000\n\u03bbn\nk \u2212 \u03bbk\n\u0001\n\u2192 0, n 1/2\u0000\n\u00b5n\nk \u2212 \u00b5k\n\u0001\n\u2192 0, n 1/2\u0000\nqn\nkl \u2212 qkl\n\u0001\n\u2192 0. (B.16)\nDiffusion limit To derive the diffusion limit in the classical model, the key processes in Defini-\ntion 8 are modified to\nZn\nkl(t) :=\n\u230at\u230bX\ni=1\nY n\nki(l), R n\nkl(t) :=\n\u230at\u230bX\ni=1\nY n\nki(l)vn\nki, t \u2208 [0, n], \u2200k, l\u2208 [K].\nNote that Rn\nkl is now defined for each pair of k, l\u2208 [K]. Then, using Assumptions H, I, J, the\nconvergence results analogous to Lemma 3 and Lemma 4 can be obtained using the martingale\nFCLT (Lemma 5) as in Section A.2 and Section A.3. Building off of the initial diffusion limit, we\ncan show convergence of the processes of predicted classes as in Proposition 6 and Proposition 1\nusing similar techniques. Specifically, let arrival processes associated with predicted classes be\nAn\nkl(t) := PAn\nk (t)\ni=1 Y n\nki(l), An\nl (t) := PK\nk=1 An\nkl(t), t \u2208 [0, n] for k, l\u2208 [K], and adapt the definitions\nof the other processes (Definition 10, Definition 11) and their characterizations analogously. For\nexample, similarly to the proof of Proposition 6, V n\nl will have to be represented as a composition\nto apply the random time change technique:\nV n\nl (t) =\nKX\nk=1\nRn\nkl\n\u0000\n(An\nk \u25e6 Un\nl )(t)\n\u0001\n=\nKX\nk=1\nAn\nk (Un\nl (t))X\ni=1\nY n\nki(l)vn\nki, t\u2208 [0, n].\nB.4.2 Stochastic dominance of the P c\u00b5-rule under the classical queueing model\nWe demonstrate that the stochastic dominance of p-FCFS policies in Lemma 11 doesnot hold in the\nclassical queueing model. The idea is that service times of waiting jobs in a predicted class are not\ngenerally i.i.d with respect to the usual filtration [63, 40] that policies are adapted to (Definition 1),\nexcept for a special case of independent Poisson arrivals, and thus our proof of Lemma 11 is not\napplicable. Consequently, the distributional lower bound of P c\u00b5-rule in (3.5) and the optimality in\nTheorem 3 would only hold over p-FCFS policies rather than all feasible policies.\nTo be concrete, consider a two-class system n where {un\n1i} and {un\n2i} take values of either 100\nor 150 and 1 or 3, respectively. Let service times {vn\n1i} and {vn\n2i} be either 2 or 6 and 1\n2 or 3\n2,\nrespectively, and qn\nkl = 1\n2 for all k, l= 1, 2. Suppose predicted class 1 has two waiting jobs with the\narrival time of the jth arriving job Un\n1,j, j= 1, 2. First, consider Un\n1,1 = 100, Un\n1,2 = 103. Given the\nknowledge of the arrival rates andUn\n1,1, Un\n1,2, service times of the jobs are not identically distributed\nbecause the first job has positive probabilities to be either of real class 1 or 2 but the second job\ncan only be from class 2. Next, consider Un\n1,1 = 100, Un\n1,2 = 150. If service time of the first job is\nobserved to be 2 or 6, the first and second job must be of real class 1 and 2, respectively. If service\ntime of the first job turns out to be 1\n2 or 3\n2, the second job can be of real class 1 with positive\nprobability. Thus, the service times of the jobs in predicted class 1 are not independent.\n48",
            "source": "prompt",
            "quality_score": 0.0,
            "metadata": {
              "content_type": [
                "Other"
              ],
              "difficulty_level": 4,
              "retrieval_hints": [
                "What are the proofs related to diffusion limits?",
                "How are heavy traffic lower bounds established?"
              ],
              "summary": "This section contains appendices detailing various proofs related to diffusion limits and heavy traffic lower bounds in queueing theory."
            }
          },
          {
            "chunk_id": "prompt_48",
            "title": "__auto__",
            "text": "B.5 Proof of Lemma 1\nUsing the shorthand fn\nkl(s) := Cn\nk (\u03c4n\nl (ns)) = Cn\nk (n1/2\u02dc\u03c4n\nl (ns)), fkl(s) := Ck(\u02dc\u03c4l(s)) d \u03ben\nkl(\u00b7) :=\nd\n\u0000\nn\u22121An\nkl(n\u00b7)\n\u0001\n(\u00b7), and d\u03bekl(\u00b7) := d \u00afAkl(\u00b7), triangle inequalities gives\nsup\nt\u2208[0,1]\n| \u02dcJn\n\u03c0n(t; Qn) \u2212 \u02dcJ\u03c0(t; Q)| = sup\nt\u2208[0,1]\n\f\f\f\nKX\nk=1\nKX\nl=1\nZ t\n0\nfn\nkl(s)d\u03ben\nkl(s) \u2212\nX\nk\nX\nl\nZ t\n0\nfkl(s)d\u03bekl(s)\n\f\f\f\n\u2264\nKX\nk=1\nKX\nl=1\nsup\nt\u2208[0,1]\nZ t\n0\n\f\ffn\nkl(s) \u2212 fkl(s)\n\f\fd\u03ben\nkl(s) + sup\nt\u2208[0,1]\n\f\f\f\nZ t\n0\nfkl(s)d\u03ben\nkl(s) \u2212\nZ t\n0\nfkl(s)d\u03bekl(s)\n\f\f\f.\n(B.17)\nThe first term of (B.17) \u2192 0 since fn\nkl(s) \u2192 fkl(s) by Assumption C and lim sup n,t \u03ben\nkl([0, t]) =\n\u03bekl([0, 1]) < +\u221e by Proposition 6. For the second term of (B.17), by Proposition 6 and generalized\nLebesgue convergence theorem [51, Page 270], it is clear that\nRt\u2032\n0 fkl(s)d\u03ben\nkl(s)\u2212\nRt\u2032\n0 fkl(s)d\u03bekl(s) \u2192 0\nas n \u2192 +\u221e for any fixed t\u2032 \u2208 [0, 1]. To achieve uniform convergence, we partition [0 , 1] into\nM intervals 0 = a0 < a1 < \u00b7\u00b7\u00b7 < aM = 1 with ai \u2212 ai\u22121 = 1 /M. Then, for any fixed M,\nmax1\u2264i\u2264M |\nRai\n0 fkl(s)d\u03ben\nkl(s) \u2212\nRai\n0 fkl(s)d\u03bekl(s)| \u21920 as n \u2192 +\u221e. Using \u2225fkl(s)\u2225 < +\u221e and\nsup\n|t1\u2212t2|\u22641/M\n\f\f\f\nZ t2\nt1\nfkl(s)d\u03ben\nkl(s)\u2212\nZ t2\nt1\nfkl(s)d\u03bekl(s)\n\f\f\f \u2264 \u2225fkl\u2225 sup\n|t1\u2212t2|\u22641/M\n\f\f\f\nZ t2\nt1\nd\u03ben\nkl(s)\n\f\f\f+\n\f\f\f\nZ t2\nt1\nd\u03bekl(s)\n\f\f\f \u2192 0\nas M, n\u2192 +\u221e by Proposition 6, we can show the second term of (B.17) also \u2192 0 as n \u2192 +\u221e.\nThis completes our proof.\nC Proof of heavy traffic lower bound (Theorem 2)\nIn addition to the proof of Theorem 2, we provide rigorous justifications for Van Mieghem [63,\nProposition 6] in Section C.7 in the case when \u02dcW+ is a reflected Brownian motion.\nC.1 Overview\nSince the queue based on the predicted classes contains a mixture of true classes due to misclassi-\nfication, we must characterize its asymptotic compositions in order to analyze the queueing cost.\nFor k, l\u2208 [K], let Nn\nkl(t), t \u2208 [0, n] be the number of true class k jobs that are predicted as class\nl and remain in system n at time t, and let \u02dcN\nn\nkl(t) := n\u22121/2Nn\nkl(t) denote its the diffusion-scaled\nversion. (See Section B.3 for the formal definition.)\nProposition 7 (Proportion of true class labels) . Given a classifier f\u03b8 and a sequence of queueing\nsystems, suppose that Assumptions A, B and H hold. Under any work-conserving p-FCFS policy,\nwe have that for any k, l\u2208 [K] and t \u2208 [0, 1],\n\u02dcN\nn\nkl(t) =\npn\nkqn\nklPK\nr=1 pnr qn\nrl\n\u02dcN\nn\nl (t) + on(1). (C.1)\nFor any predicted class l \u2208 [K], Proposition 7 states the unobservable (scaled) queue length of\ntrue class k jobs, \u02dcN\nn\nkl, is proportional to the overall queue length \u02dcN\nn\nl . Moreover, the proportion is\nasymptotically \u201cstable\u201d in the sense that\npn\nk qn\nklPK\nr=1 pnr qn\nrl\nconverges to a constant under Assumption B.\n49",
            "source": "prompt",
            "quality_score": 0.0,
            "metadata": {
              "content_type": [
                "Other"
              ],
              "difficulty_level": 4,
              "retrieval_hints": [
                "What are the proofs related to diffusion limits?",
                "How are heavy traffic lower bounds established?"
              ],
              "summary": "This section contains appendices detailing various proofs related to diffusion limits and heavy traffic lower bounds in queueing theory."
            }
          },
          {
            "chunk_id": "prompt_49",
            "title": "__auto__",
            "text": "Since the actual cost incurred by a job is governed by the job\u2019s true class label, the decomposi-\ntion (C.1) enables to approximate the aggregated cost incurred by jobs in predicted class l \u2208 [K]\naccording to their true class labels (see Eq. (C.10) to come for details).\nNext, we use Proposition 1 to reveal asymptotic relationships between endogenous processes\nsuch as \u02dcW\nn\nl and \u02dcN\nn\nl (e.g., see Lemma 16 in Section C). Combining this with the decomposi-\ntion (C.1), we establish a link between the actual cost incurred in the presence of misclassification\nerrors and the exogenous component \u02dcW\nn\n+ (see Eq. (C.11) to come). Our analysis allows us to\nidenfify a lower bound as a workload allocation over the predicted classes as we characterize in\nProposition 2.\nDiscussion of proof The proof of Proposition 7 is nontrivial, but once we arrive at the decompo-\nsition (C.1), it sheds light on the construction of the Pc\u00b5 rule (1.4). The main challenge in deriving\nthe cost functions (1.3) used in the P c\u00b5 rule (1.4) is the proof of Proposition 7. We decompose\nthe stochastic fluctuation \u02dcN\nn\nkl into fluctuations of other processes, including the service process \u02dcS\nn\nl\nand the classification partial sum process, \u02dcZ\nn\nkl. Since service times and the true/predicted class\nlabels are correlated in our model, it is not a priori clear how the corresponding fluctuations in \u02dcS\nn\nl\nand \u02dcZ\nn\nkl jointly influence that of \u02dcN\nn\nkl. The derivation of (C.1) requires articulating the stochastic\nfluctuation of \u02dcN\nn\nkl. Toward this goal, we provide a novel characterization of the service completion\nin the predicted classes from the perspective of the common stream of arrivals in Eq. (C.18). The\nproof of the proposition is provided in Section C.5.\nThe o(n\u22121/2) rates in Assumption B are the exact rate required to prove Theorem 2. Proposi-\ntion 7 relies on Proposition 1, which builds on the convergence rate in Assumption B. Importantly,\nthe same rate is necessary for a key relationship between \u02dcW\nn\nl and \u02dcN\nn\nl in Lemma 16. In Section E.1,\nwe explain how this rate condition also leads to a crucial equivalence between the age and sojourn\ntime processes, laying the foundation of the optimality of the P c\u00b5-rule in Theorem 3 to come.\nComparision to the analysis of Van Mieghem [63] Plugging Qn = I into Theorem 2, we\nrecover the classical result under perfect classification in Van Mieghem [63, Proposition 6]. In\naddition to its generality discussed above, our proof corrects an important and missing condition\nin Van Mieghem [63, Proposition 6] even in the classical setting when all true classes are known.\nAs we noted above, the o(n\u22121/2) rates for \u00b5n\nk, pn\nk, qn\nkl \u2200 k, l\u2208 [K] in our Assumption B are\nessential for proving Theorem 2. We found that the same convergence rate is also required for the\ncounterparts in Van Mieghem [63] (e.g., \u00afV n\nk in their notation), but was omitted in the result.\nIn the classical setting and beyond, we need the optimal workload allocation h that solves (3.4)\nto be continuous with respect to the total workload \u02dcW+(t), t\u2208 [0, 1]. As this argument was omitted\nin Van Mieghem [63], we give it in Proposition 15.\nIn the proof of Theorem 2, we partition the time interval [0 , 1] to bound the accrued cost\nover each small subinterval, and the approximation errors due to the finite partitioning is handled\naccordingly (see Eq. (C.5)). In the proof of Van Mieghem [63, Proposition 6], however, the partition\nis chosen by a different method than ours, and the author claims that the partition size, hence the\napproximation error, can be arbitrarily small without justification. When the workload is a general\nreflected process as in Van Mieghem [63]\u2019s setting, we found this claim to be challenging to prove.\nAs a result, we provide a rigorous justification for their claim with respect to the reflected Brownian\nmotion \u02dcW+ in Section C.7.\n50",
            "source": "prompt",
            "quality_score": 0.0,
            "metadata": {
              "content_type": [
                "Other"
              ],
              "difficulty_level": 4,
              "retrieval_hints": [
                "What are the proofs related to diffusion limits?",
                "How are heavy traffic lower bounds established?"
              ],
              "summary": "This section contains appendices detailing various proofs related to diffusion limits and heavy traffic lower bounds in queueing theory."
            }
          },
          {
            "chunk_id": "prompt_50",
            "title": "__auto__",
            "text": "C.2 Detailed proof of heavy traffic lower bound (Theorem 2)\nWe begin by proving (3.3). We analyze \u02dcJn\n\u03c0n(t; Qn) for a fixed t \u2208 [0, 1]. By definition,\n\u02dcJn\n\u03c0n(t; Qn) = n\u22121\nKX\nl=1\nKX\nk=1\nZ nt\n0\nCn\nk (\u03c4n\nl (s)) dAn\nkl(s).\nFor a fixed \u03b5 >0, partition [0 , 1] into 0 = t0 < t1 < . . . < tM = 1 such that sup i(ti+1 \u2212 ti) = \u03b5,\nwhere M is a constant dependent on \u03b5. Let d \u03ben\nkl,i := dAn\nkl\nAn\nkl(nti+1)\u2212An\nkl(nti) be a probability measure\nover [nti, nti+1], convexity of Cn\nk and Jensen\u2019s inequality yields\n\u02dcJn\n\u03c0n(t; Qn) = n\u22121\nKX\nl=1\nKX\nk=1\nX\ni\nZ nti+1\nnti\nCn\nk (\u03c4n\nl (s))dAn\nkl(s)\n= n\u22121 X\nk\nX\nl\nX\ni\n[An\nkl(nti+1) \u2212 An\nkl(nti)]E\u03ben\nkl,i[Cn\nk (\u03c4n\nl )]\n\u2265 n\u22121 X\nk\nX\nl\nX\ni\n[An\nkl(nti+1) \u2212 An\nkl(nti)]Cn\nk (E\u03ben\nkl,i[\u03c4n\nl ]).\n(C.2)\nBy connecting E\u03ben\nkl,i[\u03c4n\nl ] with the workload process, we can show the following claim. Recallon(1) \u2192\n0 uniformly over t \u2208 [0, 1].\nClaim 14.\n\u02dcJn\n\u03c0n(t; Qn) \u2265 n\u22121 X\nk\nX\nl\nX\ni\n[An\nkl(nti+1) \u2212 An\nkl(nti)]Cn\nk (E\u03ben\nkl,i[\u03c4n\nl ]) (C.3)\n=\nX\nk\nX\nl\nX\ni\n[\u03bbpkqkl(ti+1 \u2212 ti) + on(1)] \u00b7 Cn\nk\n\u0010\nn1/2\nh\n[\u03c1l(ti+1 \u2212 ti)]\u22121\nZ ti+1\nti\n\u02dcW\nn\nl (s)ds + on(1)\ni\u0011\n.\nSince Cn\nk (n1/2\u00b7) \u2192 Ck(\u00b7) and C\u2032\nk is bounded on the compact set [0, 2 lim sup\u2225 \u02dcW+\u2225/\u03c1l], the right\nhand side of inequality (C.3) can be rewritten\nX\ni\n(ti+1 \u2212 ti)\nX\nk\nX\nl\n\u03bbpkqklCk\n\u0010 1\nti+1 \u2212 ti\nZ ti+1\nti\n\u02dcW\nn\nl (s)/\u03c1l ds\n\u0011\n+ on(1)\n\u2265\nX\ni\n(ti+1 \u2212 ti)\nX\nk\nX\nl\n\u03bbpkqklCk\n\u0010\n[h(yn\ni )]l/\u03c1l\n\u0011\n+ on(1)\n(C.4)\nwhere h(\u00b7) is the solution to Opt( r) (3.4) and\nyn\ni :=\nX\nl\n1\nti+1 \u2212 ti\nZ ti+1\nti\n\u02dcW\nn\nl (s) ds = 1\nti+1 \u2212 ti\nZ ti+1\nti\n\u02dcWn\n+(s)ds.\nBy \u02dcWn\n+ \u2192 \u02dcW+ and the continuity of \u02dcW+ in Proposition 1, applying the mean value theorem for\nintegrals yields the existence of \u03bei \u2208 [ti, ti+1] such that\nyn\ni = 1\nti+1 \u2212 ti\nZ ti+1\nti\n\u02dcW\nn\n+(s)ds = 1\nti+1 \u2212 ti\nZ ti+1\nti\n\u02dcW+(s)ds + on(1) = \u02dcW+(\u03bei) + on(1). (C.5)\nWe use continuity of h(\u00b7) to complete the proof of (3.3). For any r \u2265 0, although Opt( r) can\npotentially have multiple optimal solutions, it suffices to study properties of one specific optimal\nsolution.\n51",
            "source": "prompt",
            "quality_score": 0.0,
            "metadata": {
              "content_type": [
                "Result/Finding"
              ],
              "difficulty_level": 4,
              "retrieval_hints": [
                "What is the proof of the heavy traffic lower bound?",
                "How is the workload process connected to the theorem?",
                "What are the properties of the optimal solution?"
              ],
              "summary": "The chunk provides a detailed proof of the heavy traffic lower bound, analyzing the behavior of a specific function under certain conditions and establishing connections to workload processes."
            }
          },
          {
            "chunk_id": "prompt_51",
            "title": "__auto__",
            "text": "Lemma 15 (Properties of the optimal allocation). Given a classifier f\u03b8, suppose Assumptions A, B, C,\nand H hold. Let h(0) = 0 and for any r >0, let h(r) be the solution to the following equations\n\u00b5lC\u2032\nl\n\u0010xl\n\u03c1l\n\u0011\n= \u00b5mC\u2032\nm\n\u0010xm\n\u03c1m\n\u0011\n, \u2200 l, m\u2208 [K];\nKX\nl=1\nxl = r; xl \u2265 0, \u2200 l \u2208 [K]. (C.6)\nThen, i) for any r >0, there exists a unique solution, ii) h : [0, \u221e) \u2192 RK is continuous, iii) for\nany r \u2265 0, h(r) is an optimal solution to Opt (r) (3.4).\nSee Section C.3 for the proof.\nBy Lemma 15 and uniform continuity of h and Ck on compact sets (Assumption C),\nlim inf\nn\n\u02dcJn\n\u03c0n(t; Qn) \u2265 lim inf\nn\nX\ni\n(ti+1 \u2212 ti)\nX\nk\nX\nl\n\u03bbpkqklCk\n\u0010\n[h(yn\ni )]l/\u03c1l\n\u0011\n=\nX\ni\n(ti+1 \u2212 ti)\nX\nk\nX\nl\n\u03bbpkqklCk\n\u0010\u0002\nh\n\u0000 \u02dcW+(\u03bei)\n\u0001\u0003\nl/\u03c1l\n\u0011\n.\nNote that the function\u03bbpkqklCk([h( \u02dcW+(\u00b7))]l/\u03c1l) is continuous and thus Riemann integrable. Letting\n\u03b5 \u2192 0 results in (3.3):\nlim inf\nn\n\u02dcJn\n\u03c0n(t; Qn) \u2265\nKX\nk=1\nKX\nl=1\nZ t\n0\n\u03bbpkqklCk\n\u0010\u0002\nh\n\u0000 \u02dcW+(s)\n\u0001\n]l\n\u03c1l\n\u0011\nds.\nTo show (3.5), consider feasible p-FCFS policies{\u03c0\u2032\nn}. For all n \u2208 N, the original processes under Pn\nsatisfy Pn[ \u02dcJn\n\u03c0\u2032n\n(t; Qn) > x] = Pcopy[ \u02dcJn\n\u03c0\u2032n\n(t; Qn) > x], \u2200 x \u2208 R, t \u2208 [0, 1], according to the Skorohod\nrepresentation. By Fatou\u2019s lemma, for any x \u2208 R, t\u2208 [0, 1], we have that\nlim inf\nn\nPn[ \u02dcJn\n\u03c0\u2032n\n(t; Qn) > x] = lim inf\nn\nPcopy[ \u02dcJn\n\u03c0\u2032n\n(t; Qn) > x] \u2265 EPcopy[lim inf\nn\nI{ \u02dcJn\n\u03c0\u2032n\n(t; Qn) > x}].\nAs lim infn\u2192\u221e \u02dcJn\n\u03c0\u2032n\n(t; Qn) \u2265 \u02dcJ\u2217(t; Q) Pcopy-a.s. by (3.3), we have that\nEPcopy[lim inf\nn\nI{ \u02dcJn\n\u03c0\u2032n\n(t; Qn) > x}] \u2265 EPcopy[I{lim inf\nn\n\u02dcJn\n\u03c0\u2032n\n(t; Qn) > x}] \u2265 Pcopy[ \u02dcJ\u2217(t; Q) > x].\nCombining equations above yields (3.5) for any feasible p-FCFS policies. We can further ex-\ntend (3.5) to any feasible policies using Lemma 11. This completes our proof.\nProof of Claim 14 Since n\u22121An\nkl(n\u00b7) \u2192 \u00afAkl by Proposition 6,\nn\u22121[An\nkl(nti+1) \u2212 An\nkl(nti)] = \u00afAkl(ti+1) \u2212 \u00afAkl(ti) + on(1) = \u03bbpkqkl(ti+1 \u2212 ti) + on(1). (C.7)\nApply the convergence (C.7) to rewrite E\u03ben\nkl,i[\u03c4n\nl ]\nE\u03ben\nkl,i[\u03c4n\nl ] = n\u22121\u0000\nn\u22121[An\nkl(nti+1) \u2212 An\nkl(nti)]\n\u0001\u22121\nZ nti+1\nnti\n\u03c4n\nl dAn\nkl,\n= n\u22121\u0002\n[\u03bbpkqkl(ti+1 \u2212 ti)]\u22121 + on(1)\n\u0003Z nti+1\nnti\n\u03c4n\nl dAn\nkl,\n(C.8)\nwhere the last line holds since ( x + \u2206x)\u22121 = x\u22121 \u2212 \u2206x + o(\u2206x).\nWe approximate\nRnb\nna \u03c4n\nl dAn\nkl using a variant of Little\u2019s Law that we prove in Section C.4.\n52",
            "source": "prompt",
            "quality_score": 0.0,
            "metadata": {
              "content_type": [
                "Result/Finding"
              ],
              "difficulty_level": 4,
              "retrieval_hints": [
                "What is the proof of the heavy traffic lower bound?",
                "How is the workload process connected to the theorem?",
                "What are the properties of the optimal solution?"
              ],
              "summary": "The chunk provides a detailed proof of the heavy traffic lower bound, analyzing the behavior of a specific function under certain conditions and establishing connections to workload processes."
            }
          },
          {
            "chunk_id": "prompt_52",
            "title": "__auto__",
            "text": "Proposition 8 (Little\u2019s law). Given a classifier f\u03b8, suppose Assumptions A, B, and H hold. Then,\nfor any 0 \u2264 a < b\u2264 1\nn\u22123/2\n\u00afAn\nkl(b) \u2212 \u00afAn\nkl(a)\nZ nb\nna\n\u03c4n\nl dAn\nkl \u2212 1\n\u00afAn\nkl(b) \u2212 \u00afAn\nkl(a)\nZ b\na\n\u02dcN\nn\nkl(t)dt = o(1), \u2200 k, l\u2208 [K], (C.9a)\nn\u22123/2\n\u00afAn\nl (b) \u2212 \u00afAn\nl (a)\nZ nb\nna\n\u03c4n\nl dAn\nl \u2212 1\n\u00afAn\nl (b) \u2212 \u00afAn\nl (a)\nZ b\na\n\u02dcN\nn\nl (t)dt = o(1), \u2200 l \u2208 [K]. (C.9b)\nIf there further exist limits \u02dc\u03c4n\nl \u2192 \u02dc\u03c4l \u2208 Cand \u02dcN\nn\nl \u2192 \u02dcNl \u2208 C, then \u03bbpl\u02dc\u03c4l = \u02dcNl.\nApplying the proposition n\u22123/2 Rnb\nna \u03c4n\nl dAn\nkl \u2212\nRb\na\n\u02dcN\nn\nkl(t)dt = on(1)O(|b \u2212 a|) to Eq. (C.8),\nE\u03ben\nkl,i[\u03c4n\nl ] = n1/2\u0002\n[\u03bbpkqkl(ti+1 \u2212 ti)]\u22121 + on(1)\n\u0003\u0010Z ti+1\nti\n\u02dcN\nn\nkl(s)ds + on(1)O(ti+1 \u2212 ti)\n\u0011\n= n1/2\nh\n[\u03bbkpkqkl(ti+1 \u2212 ti)]\u22121\nZ ti+1\nti\n\u02dcN\nn\nkl(s)ds + on(1) + on(1)O(\u03b5)\ni\n,\n(C.10)\nsince supi(ti+1 \u2212 ti) = O(\u03b5) and lim supn \u2225 \u02dcNkl\u2225 \u2264lim supn \u2225 \u02dcNl\u2225 < \u221e by Proposition 1.\nTo rewrite\nRb\na\n\u02dcN\nn\nkl(s)ds in terms of the workload, recall the key relation \u02dcN\nn\nkl =\npn\nk qn\nklP\nr pnr qn\nrl\n\u02dcN\nn\nl +on(1)\ngiven in Proposition 7 (see Section C.5 for its proof). We can further approximate the queue length\nprocess \u02dcN\nn\nl using the service rate \u00b5l and the remaining workload process \u02dcW\nn\nl .\nLemma 16 (Relation between \u02dcW\nn\nl and \u02dcN\nn\nl ). Given a classifier f\u03b8, suppose Assumptions A, B,\nand H hold. Then, for p-FCFS policies \u00b5l\n\u02dcW\nn\nl \u2212 \u02dcN\nn\nl \u2192 0 for all l \u2208 [K].\nSee Section C.6 for the proof. Applying Proposition 7 and Lemma 16,\nZ b\na\n\u02dcN\nn\nkl(s)ds =\nZ b\na\n\u00b5l\npkqklP\nr prqrl\n\u02dcW\nn\nl (s)ds + on(1)O(|b \u2212 a|).\nPlugging this into the expression (C.10) for E\u00b5n\nkl,i[\u03c4n\nl ]\nE\u03ben\nkl,i[\u03c4n\nl ] = n1/2\nh\n[\u03bbkpkqkl(ti+1 \u2212 ti)]\u22121\n\u0010Z ti+1\nti\n\u00b5l\npkqklP\nr prqrl\n\u02dcW\nn\nl (s)ds + on(1)O(ti+1 \u2212 ti)\n\u0011\n+ on(1)\ni\n= n1/2\nh\n[\u03c1l(ti+1 \u2212 ti)]\u22121\nZ ti+1\nti\n\u02dcW\nn\nl (s)ds + on(1)\ni\n,\n(C.11)\nwhere we use the shorthands pl = P\nr prqrl and \u03c1l =\n\u03bbpl\n\u00b5l\nin the final line.\nC.3 Proof of Lemma 15\nFor any l \u2208 [K], Assumption C implies C\u2032\nl is continuous and strictly increasing. Hence,\ng(x) := x +\nKX\nl=2\n\u03c1l \u00b7 (C\u2032\nl)\u22121\n\u0010\u00b51\n\u00b5l\nC\u2032\n1(\u03c1\u22121\n1 x)\n\u0011\n(C.12)\nis continuous and strictly increasing with g(0) = 0, g(r) \u2265 r. Let x1(r) be a unique solution to\ng(x) = r and\nxl(r) := \u03c1l \u00b7 (C\u2032\nl)\u22121\n\u0010\u00b51\n\u00b5l\nC\u2032\n1(\u03c1\u22121\n1 x1)\n\u0011\n, \u2200 l \u2265 2.\n53",
            "source": "prompt",
            "quality_score": 0.0,
            "metadata": {
              "content_type": [
                "Result/Finding"
              ],
              "difficulty_level": 4,
              "retrieval_hints": [
                "What is the proof of the heavy traffic lower bound?",
                "How is the workload process connected to the theorem?",
                "What are the properties of the optimal solution?"
              ],
              "summary": "The chunk provides a detailed proof of the heavy traffic lower bound, analyzing the behavior of a specific function under certain conditions and establishing connections to workload processes."
            }
          },
          {
            "chunk_id": "prompt_53",
            "title": "__auto__",
            "text": "Evidently, h(r) = (x1(r), . . . , xK(r)) is a unique solution to Eq. (C.6). To see (ii), note that x1(r)\nis continuous with x1(r) = 0 since g\u22121 is continuous. For (iii), for r = 0, h(0) = 0 is clearly an\noptimal solution to Opt(0). When r >0, we verify h(r) satisfies the KKT conditions for Opt( r).\nThis is evident from the fact that C\u2032\nl(0) = (C\u2032\nl)\u22121(0) = 0 and C\u2032\nl and (C\u2032\nl)\u22121 are strictly increasing\n(Assumption C).\nC.4 Proof of Proposition 8\nOur proof for Eqs. (C.9a) and (C.9b) is similar to the proof for Van Mieghem [63, Proposition 4].\nTo show Eqs. (C.9a), consider the cumulative cost during t \u2208 [a, b] where each job incurs a unit\ncost per unit time spent in the system. We study three different cost charging schemes\nCostn\n1 (a, b) = 1\n\u00afAn\nkl(b) \u2212 \u00afAn\nkl(a)\nAn\nkl(nb)X\ni=An\nkl(na)\n\u03c4n\nli,\nCostn\n2 (a, b) = 1\n\u00afAn\nkl(b) \u2212 \u00afAn\nkl(a)\nZ nb\nna\nNn\nkl(t)dt,\nCostn\n3 (a, b) = 1\n\u00afAn\nkl(b) \u2212 \u00afAn\nkl(a)\nAn\nkl(nb)\u2212Nn\nkl(nb)X\ni=An\nkl(na)\n\u03c4n\nli.\nCostn\n1 (a, b) charges the entire cost at the job\u2019s arrival, Cost n\n3 (a, b) at the job\u2019s departure, and\nCostn\n2 (a, b) continuously. It is easy to verify\nCostn\n3 (a, b) \u2264 Costn\n2 (a, b) \u2264 Costn\n1 (a, b),\nand\nn\u22123/2(Costn\n1 (a, b) \u2212 Costn\n3 (a, b)) = n\u22123/2\n\u00afAn\nkl(b) \u2212 \u00afAn\nkl(a)\nAn\nkl(nb)X\ni=An\nkl(nb)\u2212Nn\nkl(nb)+1\n\u03c4n\nli\n\u2264 n\u22121/2\n\u00afAn\nkl(b) \u2212 \u00afAn\nkl(a)\u2225 \u02dcN\nn\nkl\u2225\u2225\u02dc\u03c4n\nl \u2225 \u21920,\nsince \u00afAn\nkl \u2192 \u00afAkl by Assumption B, and \u2225 \u02dcN\nn\nkl\u2225 and \u2225\u02dc\u03c4n\nl \u2225 are bounded (Proposition 1). Conclude\non(1) = n\u22123/2\n\u00afAn\nkl(b) \u2212 \u00afAn\nkl(a)\nZ nb\nna\n\u03c4n\nl dAn\nkl \u2212 n\u22123/2\n\u00afAn\nkl(b) \u2212 \u00afAn\nkl(a)\nZ nb\nna\nNn\nkl(t)dt\n= n\u22123/2\n\u00afAn\nkl(b) \u2212 \u00afAn\nkl(a)\nZ nb\nna\n\u03c4n\nl dAn\nkl \u2212 1\n\u00afAn\nkl(b) \u2212 \u00afAn\nkl(a)\nZ b\na\n\u02dcN\nn\nkl(t)dt.\nThe proof for Eq. (C.9b) can be established similarly and we omit the details.\nFor the second result, further assume \u02dc\u03c4n\nl \u2192 \u02dc\u03c4l for all l \u2208 [K]. To see \u03bbpl\u02dc\u03c4l = \u02dcNl, it suffices to\nshow \u03bbpl\u02dc\u03c4l(t) = \u02dcNl(t). Recall that by Eq. (C.9b),\nn\u22123/2\n\u00afAn\nl (b) \u2212 \u00afAn\nl (a)\nZ nb\nna\n\u03c4n\nl dAn\nl \u2212 1\n\u00afAn\nl (b) \u2212 \u00afAn\nl (a)\nZ b\na\n\u02dcN\nn\nl (t)dt = on(1), \u2200 l \u2208 [K].\nFor simplicity, for fixed [a, b], let \u03ben\nl be the Lebesgue-Stieltjes measure on [0, 1] induced byn\u22121An\nl (n\u00b7)\n54",
            "source": "prompt",
            "quality_score": 0.0,
            "metadata": {
              "content_type": [
                "Result/Finding"
              ],
              "difficulty_level": 4,
              "retrieval_hints": [
                "What is the proof of the heavy traffic lower bound?",
                "How is the workload process connected to the theorem?",
                "What are the properties of the optimal solution?"
              ],
              "summary": "The chunk provides a detailed proof of the heavy traffic lower bound, analyzing the behavior of a specific function under certain conditions and establishing connections to workload processes."
            }
          },
          {
            "chunk_id": "prompt_54",
            "title": "__auto__",
            "text": "and \u03bel be the Lebesgue-Stieltjes measure on [0 , 1] induced by \u00afAl(\u00b7). It is easy to verify\nn\u22123/2\nZ nb\nna\n\u03c4n\nl (t)dAn\nl (t) =\nZ b\na\n\u02dc\u03c4n\nl d\u03ben\nl .\nSince \u03ben\nl \u2192 \u03bel and \u2225\u02dc\u03c4n\nl \u2225 \u2264lim supn \u2225\u02dc\u03c4n\nl \u2225 < +\u221e eventually (Proposition 1), generalized Lebesgue\nconvergence [51, Page 270] implies\nn\u22123/2\nZ nb\nna\n\u03c4n\nl (t)dAn\nl (t) \u2192\nZ b\na\n\u02dc\u03c4l(t)d \u00afAl(t) =\nZ b\na\n\u03bbpl\u02dc\u03c4l(t)dt. (C.13)\nNext, we analyze the second term of Eq. (C.9b). Dominated convergence gives\n1\n\u00afAn\nl (nb) \u2212 \u00afAn\nl (na)\nZ b\na\n\u02dcN\nn\nl (t)dt \u2192 1\n\u00afAl(b) \u2212 \u00afAl(a)\nZ b\na\n\u02dcNl(t)dt. (C.14)\nCombining Eqs. (C.9b), (C.13), and (C.14) yields that for all [ a, b] \u2282 [0, 1],\n1\n\u00afAl(b) \u2212 \u00afAl(a)\nZ b\na\n\u03bbpl\u02dc\u03c4l(t)dt = 1\n\u00afAl(b) \u2212 \u00afAl(a)\nZ b\na\n\u02dcNl(t)dt. (C.15)\nNote that \u00afAl(t) = \u03bbplt. Hence, for fixed t \u2208 [0, 1], inserting a = t, b= t + \u2206t into Eq. (C.15) gives\n1\n\u00afAl(t + \u2206t) \u2212 \u00afAl(t)\nZ t+\u2206t\nt\n\u02dcNl(s)ds = 1\n\u03bbpl\n\u00b7 1\n\u2206t\nZ t+\u2206t\nt\n\u02dcNl(s)ds \u2192 1\n\u03bbpl\n\u02dcNl(t), (C.16)\nas \u2206t \u2192 0, where the convergence follows from continuity of \u02dcNl and the mean value theorem for\ndefinite integrals. Similarly, one can show as \u2206 t \u2192 0,\n1\n\u00afAl(t + \u2206t) \u2212 \u00afAl(t)\nZ t+\u2206t\nt\n\u03bbpl\u02dc\u03c4l(s)ds \u2192 \u02dc\u03c4l(t). (C.17)\nCombining Eqs. (C.15), (C.16), and (C.17) yields the desired result \u03bbpl\u02dc\u03c4l = \u02dcNl, \u2200 l \u2208 [K].\nC.5 Proof of Proposition 7\nRecalling the definition (B.6), for any nt \u2208 [0, n]\nNn\nkl(nt) = An\nkl(nt) \u2212\n(Mn\nl \u25e6Sn\nl \u25e6Tn\nl )(nt)X\ni=1\nY n\nikY n\nil = An\nkl(nt) \u2212 Zn\nkl\n\u0010\n(Mn\nl \u25e6 Sn\nl \u25e6 Tn\nl )(nt)\n\u0011\n.\nBy Lemma 4, Proposition 6, and Eq. (B.13),\nZn\nkl(nt) = npn\nkqn\nklt + n1/2 \u02dcZ\nn\nkl(t) + o(n1/2),\nSn\nl (nt) = n\u00b5n\nl t + n1/2 \u02dcS\nn\nl (t) + o(n1/2),\nTn\nl (nt) = n\u03bbnpn\nl (\u00b5n\nl )\u22121t + n1/2 \u02dcT\nn\nl (t) + o(n1/2).\nRecalling \u2225 \u02dcT\nn\nl \u2225 < +\u221e by Proposition 1, ( Sn\nl \u25e6 Tn\nl )(nt) can be reformulated as\n(Sn\nl \u25e6 Tn\nl )(nt) = \u00b5n\nl Tn\nl (nt) + n1/2 \u02dcS\nn\nl (n\u22121Tn\nl (nt)) + o(n1/2)\n= n\u03bbnpn\nl t + n1/2\u00b5n\nl\n\u02dcT\nn\nl (t) + n1/2 \u02dcS\nn\nl (\u03bbnpn\nl (\u00b5n\nl )\u22121t + n\u22121/2 \u02dcT\nn\nl (t) + o(n\u22121/2)) + o(n1/2)\n=n\u03bbnpn\nl t + n1/2\u00b5n\nl\n\u02dcT\nn\nl (t) + n1/2 \u02dcS\nn\nl (\u03bbnpn\nl (\u00b5n\nl )\u22121t + o(1)) + o(n1/2).\n55",
            "source": "prompt",
            "quality_score": 0.0,
            "metadata": {
              "content_type": [
                "Result/Finding"
              ],
              "difficulty_level": 4,
              "retrieval_hints": [
                "What is the proof of the heavy traffic lower bound?",
                "How is the workload process connected to the theorem?",
                "What are the properties of the optimal solution?"
              ],
              "summary": "The chunk provides a detailed proof of the heavy traffic lower bound, analyzing the behavior of a specific function under certain conditions and establishing connections to workload processes."
            }
          },
          {
            "chunk_id": "prompt_55",
            "title": "__auto__",
            "text": "Therefore, we can rewrite ( Mn\nl \u25e6 Sn\nl \u25e6 Tn\nl )(nt) as\n(Mn\nl \u25e6 Sn\nl \u25e6 Tn\nl )(nt) = n\u03bbnt + n1/2(pn\nl )\u22121\u00b5n\nl\n\u02dcT\nn\nl (t) + n1/2(pn\nl )\u22121 \u02dcS\nn\nl (\u03bbnpn\nl (\u00b5n\nl )\u22121t + o(1))\n+ n1/2 \u02dcM\nn\nl (\u03bbnpn\nl t + o(1)) + o(n1/2).\n(C.18)\nSince An\nkl(nt) = \u03bbnpn\nkqn\nklnt + n1/2 \u02dcA\nn\nkl(t) according to the proof of Proposition 6 and Zn\nkl(nt) =\npn\nkqn\nklnt + n1/2 \u02dcZ\nn\nkl(t) by Definition 10, combining equations above yields\n\u02dcN\nn\nkl(t) = \u02dcA\nn\nkl(t) \u2212\npn\nkqn\nkl\npn\nl\nh\n\u00b5n\nl\n\u02dcT\nn\nl (t) + \u02dcS\nn\nl (\u03bbnpn\nl (\u00b5n\nl )\u22121t + o(1))\ni\n\u2212 pn\nkqn\nkl\n\u02dcM\nn\nl (\u03bbnpn\nl t + o(1)) \u2212 \u02dcZ\nn\nkl(\u03bbnt + o(1)) + o(1).\nMoreover, the proof of Proposition 6 implies\n\u02dcS\nn\nl \u2192 \u02dcSl, \u02dcA\nn\nkl \u2192 \u02dcAkl := \u02dcZkl \u25e6 \u03bbe + pkqkl\n\u02dcA0, \u02dcM\nn\nl \u2192 \u02dcMl := \u2212p\u22121\nl\n\u0010 KX\nk=1\n\u02dcZkl\n\u0011\n\u25e6 p\u22121\nl e.\nSince the limiting process is continuous, by continuity of composition [68, Theorem 13.2.1] and\ncontinuous mapping theorem, we have that\n\u02dcS\nn\nl (\u03bbnpn\nl (\u00b5n\nl )\u22121t + o(1)) = \u02dcS\nn\nl (\u03bbnpn\nl (\u00b5n\nl )\u22121t) + o(1), \u02dcA\nn\nkl \u2212 \u02dcZ\nn\nkl(\u03bbn \u00b7 +o(1)) = pn\nkqn\nkl\n\u02dcA\nn\n0 + o(1),\n\u02dcM\nn\nl (\u03bbnpn\nl \u00b7 +o(1)) = \u2212(pn\nl )\u22121\n\u0010 KX\nk=1\n\u02dcZ\nn\nkl(\u03bbn\u00b7)\n\u0011\n+ o(1).\nThus, we can further rewrite \u02dcN\nn\nkl(t) as\npn\nkqn\nkl\n\u02dcA\nn\n0 (t) \u2212\npn\nkqn\nkl\npn\nl\nh\n\u00b5n\nl\n\u02dcT\nn\nl (t) + \u02dcS\nn\nl (\u03bbnpn\nl (\u00b5n\nl )\u22121t)\ni\n+\npn\nkqn\nkl\npn\nl\nKX\nk=1\n\u02dcZ\nn\nkl(\u03bbnt) + o(1)\n=\n\u02dcA\nn\nl (t) \u2212 PK\nk=1 \u02dcZ\nn\nkl(\u03bbnt)\npn\nl\npn\nkqn\nkl \u2212\npn\nkqn\nkl\npn\nl\nh\n\u00b5n\nl\n\u02dcT\nn\nl (t) + \u02dcS\nn\nl (\u03bbnpn\nl (\u00b5n\nl )\u22121t)\ni\n+\npn\nkqn\nkl\npn\nl\nKX\nk=1\n\u02dcZ\nn\nkl(\u03bbnt) + o(1)\n=\npn\nkqn\nkl\npn\nl\nh\n\u02dcA\nn\nl (t) \u2212 \u00b5n\nl\n\u02dcT\nn\nl (t) \u2212 \u02dcS\nn\nl (\u03bbnpn\nl (\u00b5n\nl )\u22121t)\ni\n+ o(1),\nwhere the second line follows from the identity \u02dcA\nn\nl (t) =\nKP\nk=1\n\u02dcZ\nn\nkl(\u03bbnt)+ pn\nl\n\u02dcAn\n0 (t)+ on(1) we derived in\nthe proof of Proposition 6. Then, by (B.14), we have the desired result \u02dcN\nn\nkl(t) =\npn\nk qn\nkl\npn\nl\n\u02dcN\nn\nl (t) +o(1).\nC.6 Proof of Lemma 16\nFor any nt \u2208 [0, n], let vn\nl (nt) be the amount of service, if any, already given to the oldest predicted\nclass l job present in the system at time nt. By definition, t \u2208 [0, 1],\n\u02dcW\nn\nl (t) = n\u22121/2\u0002\nV n\nl (An\nl (nt)) \u2212 V n\nl\n\u0000\nAn\nl (nt) \u2212 Nn\nl (nt)\n\u0001\n\u2212 vn\nl (nt)\n\u0003\n= n1/2\u0002\u00afV n\nl (n\u22121An\nl (nt)) \u2212 \u00afV n\nl\n\u0000\nn\u22121An\nl (nt) \u2212 n\u22121Nn\nl (nt)\n\u0001\u0003\n+\n\u0002\u02dcV\nn\nl (n\u22121An\nl (nt)) \u2212 \u02dcV\nn\nl\n\u0000\nn\u22121An\nl (nt) \u2212 n\u22121Nn\nl (nt)\n\u0001\u0003\n+ o(1) \u2212 n\u22121/2vn\nl (nt),\n(C.19)\n56",
            "source": "prompt",
            "quality_score": 0.0,
            "metadata": {
              "content_type": [
                "Result/Finding"
              ],
              "difficulty_level": 4,
              "retrieval_hints": [
                "What is the proof of the heavy traffic lower bound?",
                "How is the workload process connected to the theorem?",
                "What are the properties of the optimal solution?"
              ],
              "summary": "The chunk provides a detailed proof of the heavy traffic lower bound, analyzing the behavior of a specific function under certain conditions and establishing connections to workload processes."
            }
          },
          {
            "chunk_id": "prompt_56",
            "title": "__auto__",
            "text": "where the second equality follows from Proposition 6, and o(\u00b7) is uniform over t \u2208 [0, 1]. We can\nrewrite the first term by noting \u00afV n\nl (t) = (\u00b5n\nl )\u22121t and n1/2(\u00b5n\nl \u2212 \u00b5l) = on(1) by Assumption B\nn1/2[ \u00afV n\nl (n\u22121An\nl (nt)) \u2212 \u00afV n\nl (n\u22121An\nl (nt) \u2212 n\u22121Nn\nl (nt))]\n= n1/2[ \u00afV l(n\u22121An\nl (nt)) \u2212 \u00afV l(n\u22121An\nl (nt) \u2212 n\u22121Nn\nl (nt))] + on(1)\n= n\u22121/2\u00b5\u22121\nl Nn\nl (nt) + on(1) = \u00b5\u22121\nl \u02dcN\nn\nl (t) + on(1).\nIt remains to bound the second term in Eq. (C.19). Notice that since \u02dcV\nn\nl = \u02dcV l + on(1) where\n\u02dcV l is uniformly continuous on compact intervals by Proposition 6 and lim sup n \u2225 \u02dcN\nn\nl \u2225 < +\u221e by\nProposition 1,\n\u02dcV\nn\nl (n\u22121An\nl (nt)) \u2212 \u02dcV\nn\nl (n\u22121An\nl (nt) \u2212 n\u22121Nn\nl (nt))\n= \u02dcV l(n\u22121An\nl (nt)) \u2212 \u02dcV l(n\u22121An\nl (nt) \u2212 n\u22121Nn\nl (nt)) + on(1) = on(1).\nC.7 Complementary proof for Proposition 6 in Van Mieghem [63]\nCompared to the proof of Van Mieghem [63, Proposition 6], we adopt a different partition of the time\ninterval [0, 1] to derive Eq. (C.5) using the mean-value theorem. To show the analogous result [63,\nEq. (94)], Van Mieghem picks a partition using stopping times of \u02dcW+ to ensure sufficiently small\nvariation of \u02dcW+ over each subinterval. Without justification, Van Mieghem [63] claims the partition\nsize is small enough ( O(\u03b5)).\nDespite best efforts, we found proving this claim difficult when the workload \u02dcW+ is a general\nreflected process. When \u02dcW+ is a relection Brownian motion, we give a proof that the partition size\nis still supi(ti+1 \u2212ti) = O(\u03b5) in Lemma 17 below; hence (C.5) would follow even if {ti} is chosen as\nthe stopping times as by Van Mieghem [63]. Our proof exploits the almost sure non-differentiablity\nof sample paths of reflected Brownian motions. (Alternatively, our previous proof provides a simple\njustification for [63, Eq. (94)] using our mean value theorem result (C.5).)\nLemma 17 (Stopping times of \u02dcW+). Given \u03b5 >0, consider the sequence of stopping times {ti(\u03b5) :\ni \u2208 N} of \u02dcW+\nt1(\u03b5) = min{1, inf{0 < t\u2264 1 : | \u02dcW+(t) \u2212 \u230a\u02dcW+(0)/\u03b5\u230b\u03b5| \u2265\u03b5}},\nti+1(\u03b5) = min{1, inf{ti(\u03b5) < t\u2264 1 : | \u02dcW+(t) \u2212 \u02dcW+(ti(\u03b5))| \u2265\u03b5}}.\nThen, we have that\nlim\n\u03b5\u21920\nsup\ni\n(ti+1(\u03b5) \u2212 ti(\u03b5)) = 0\nProof We prove by contradiction and will show that if Lemma 17 does not hold, then there\nexists [a, b] \u2282 [0, 1] such that b \u2212 a >0 and \u02dcW+ is a constant on [ a, b]. We argue that the latter\nleads to a contraction using that \u02dcW+ is a reflected Brownian motion as shown in Proposition 1. If\n\u02dcW+(t) = 0 for t \u2208 [a, b], then the associated Brownian motion must be monotonically decreasing on\n[a, b] because of the definition of the reflection mapping [68], but this is a zero probability event [43].\nIf \u02dcW+(t) = c for some positive constant c and t \u2208 [a, b], it is contradictory to the nondifferentiability\nof Brownian motion [43].\nSuppose for the purpose of contradiction that there exists some \u03b4 >0, a sequence of \u03b5k \u2192 0,\nand a sequence of {ik}\u221e\nk=1 satisfying\ntik+1(\u03b5k) \u2212 tik(\u03b5k) \u2265 \u03b4, and | \u02dcW+(t) \u2212 \u02dcW+(tik(\u03b5k))| \u2264\u03b5k, \u2200 t \u2208 [tik(\u03b5k), tik(\u03b5k) + \u03b4] \u2282 [0, 1].\n57",
            "source": "prompt",
            "quality_score": 0.0,
            "metadata": {
              "content_type": [
                "Result/Finding"
              ],
              "difficulty_level": 4,
              "retrieval_hints": [
                "What is the proof of the heavy traffic lower bound?",
                "How is the workload process connected to the theorem?",
                "What are the properties of the optimal solution?"
              ],
              "summary": "The chunk provides a detailed proof of the heavy traffic lower bound, analyzing the behavior of a specific function under certain conditions and establishing connections to workload processes."
            }
          },
          {
            "chunk_id": "prompt_57",
            "title": "__auto__",
            "text": "Let I(k) = [tik(\u03b5k), tik(\u03b5k) +\u03b4] \u2282 [0, 1] for all k \u2265 1. We claim that there exists b \u2212 a \u2265 \u03b40 > 0 and\na subsequence {kl}\u221e\nl=1 such that [a, b] \u2282 I(kl) for all l \u2265 1. Let M = \u23082/\u03b4\u2309 . Partition [0 , 1] into\n0 = a0 < a1 < \u00b7\u00b7\u00b7 < aM = 1\nwith ar+1 \u2212 ar = \u03b4/2 > 0, possibly except the last interval. Evidently, there exists some r0 \u2208\n{0, 1, ..., M\u2212 1} such that [ ar0, ar0+1] \u2229 I(k) \u0338= \u2205, for infinitely many k\u2019s; otherwise PM\u22121\nm=0 #{k :\n[am, am+1] \u2229 I(k) \u0338= \u2205, k\u2208 N} < +\u221e, so that PM\u22121\nm=0 #{k : [am, am+1] \u2229 I(k) \u0338= \u2205, k\u2208 N} \u2265#{k :\nk \u2208 N+} = \u221e gives a contradiction.\nWe next construct the aforementioned interval [a, b] and subsequence {kl}\u221e\nl=1. Since [ar0, ar0+1]\u2229\nI(k) \u0338= \u2205 for infinitely many k, at least one of the following statement hold:\n(i) there exists a subsequence {kl}\u221e\nl=1 such that tikl\n(\u03b5kl) > ar0 for all l;\n(ii) there exists a subsequence {kl}\u221e\nl=1 such that tikl\n(\u03b5kl) + \u03b4 < ar0+1 for all l;\n(iii) there exists a subsequence {kl}\u221e\nl=1 such that tikl\n(\u03b5kl) \u2264 ar0 < ar0+1 \u2264 tikl\n(\u03b5kl) + \u03b4 for all l.\nFor the case of (i), by definition we have that for all l, ar0 < tikl\n(\u03b5kl) \u2264 ar0+1 since I(kl) \u2229\n[ar0, ar0+1] \u0338= \u2205. Therefore, for all l, we have that ar0 +\u03b4 < tikl\n(\u03b5kl)+ \u03b4 \u2264 ar0+1 +\u03b4. In other words,\n[ar0+1, ar0 + \u03b4] \u2282 Ikl, \u2200 l \u2265 1. Hence, we can set a = ar0+1, b= ar0 + \u03b4, where b \u2212 a \u2265 \u03b4/2. For (ii)\nand (iii), we can construct a and b similarly and we skip the details here.\nThen, by [a, b] \u2282 I(kl), we have that supa\u2264t,t\u2032\u2264b | \u02dcW+(t) \u2212 \u02dcW+(t\u2032)| \u22642\u03b5kl, \u2200 l \u2265 1, which implies\nthat \u02dcW+(t) is a constant on [ a, b]. This completes our proof.\nD Proof of Proposition 13\nRecalling the strong convexity of Cl,\nCl(y) \u2265 Cl(x) + C\u2032\nl(x)(y \u2212 x) + m\n2 (y \u2212 x)2, \u2200 x, y,\u2200 l \u2208 [K].\nfor some m >0, we use the following constants\n\u00b5min = min\nl\u2208[K]\n\u00b5l, \u00b5 max = max\nl\u2208[K]\n\u00b5l, \u03c1 min = min\nl\u2208[K]\n\u03c1l, \u03c1 max = max\nl\u2208[K]\n\u03c1l,\n\u03b10 :=\n\u03c1min\n3(K \u2212 1)\u03c1max\n, \u03b2 0 :=\n\u00b5min\u03b10\n2 , \u03b3 0 := \u03b10\n1 \u2212 \u03c1min\n.\n(D.1)\nSince C\u2032\nl is uniformly continuous on the compact set [0 , lim supn \u2225\u02dcan\nl \u2225] where lim supn \u2225\u02dcan\nl \u2225 < +\u221e\naccording to Proposition 12, we have the following result.\nLemma 18 (Continuity of C\u2032\nl). Given a classifier f\u03b8, suppose that Assumption C holds. For any\n\u03b5 >0, there exists \u03b41(\u03b5), \u03b42(\u03b5) > 0 such that for any a1, a2 \u2208 [0, lim supn \u2225\u02dcan\nl \u2225],\n(i) if |a2 \u2212 a1| \u2264\u03b41(\u03b5), then |C\u2032\nl(a2) \u2212 C\u2032\nl(a1)| < \u03b5\n8\u00b5max\n, \u2200 l \u2208 [K];\n(ii) if |a2 \u2212 a1| \u2264\u03b42(\u03b5), then |C\u2032\nl(a2) \u2212 C\u2032\nl(a1)| < m\u03b20\n2\u00b5max\n\u03b41(\u03b5), \u2200 l \u2208 [K].\n58",
            "source": "prompt",
            "quality_score": 0.0,
            "metadata": {
              "content_type": [
                "Result/Finding"
              ],
              "difficulty_level": 4,
              "retrieval_hints": [
                "What is the proof of the heavy traffic lower bound?",
                "How is the workload process connected to the theorem?",
                "What are the properties of the optimal solution?"
              ],
              "summary": "The chunk provides a detailed proof of the heavy traffic lower bound, analyzing the behavior of a specific function under certain conditions and establishing connections to workload processes."
            }
          },
          {
            "chunk_id": "prompt_58",
            "title": "__auto__",
            "text": "Our proof is separated into three propositions. Below, we suppose Assumptions A, B, C, D,\nand H hold. For any \u03b5 >0, let \u03b41(\u03b5), \u03b42(\u03b5) be constants defined in Lemma 18 and define \u03b4n\n1 (\u03b5) :=\nn\u22121/2\u03b41(\u03b5), \u03b4n\n2 (\u03b5) := n\u22121/2\u03b42(\u03b5). Partition the time interval [0 , n] into subintervals of length no\nmore than n\u03b4n\n1 (\u03b5). Letting N(\u03b5) be large enough so the below propositions hold for n \u2265 N(\u03b5), our\ndesired result follows by using an inductive argument over these subintervals.\nSee Section D.2 for the proof of the first proposition.\nProposition 9 (Max difference of the P c\u00b5 indices at endpoints: Case I) . Let t1 \u2208 [0, 1 \u2212 \u03b4n\n1 (\u03b5)] be\nsuch that maxl,m\u2208[K] |In\nl (t1) \u2212 In\nm(t1)| < \u03b5and all predicted classes are selected by the P c\u00b5-rule in\n[nt1, n(t1 + \u03b4n\n1 (\u03b5))]. Then, there exists N(\u03b5) > 0 such that for any n > N(\u03b5)\nmax\nl1,l2\u2208[K]\n|In\nl1(t1 + \u03b4n\n1 (\u03b5)) \u2212 In\nl2(t1 + \u03b4n\n1 (\u03b5))| < \u03b5.\nWe prove the second proposition in Section D.3.\nProposition 10 (Max difference of the P c\u00b5-rule indices at endpoints: Case II) . Let t1 \u2208 [0, 1 \u2212\n\u03b4n\n1 (\u03b5)] be such that maxl,m\u2208[K] |In\nl (t1) \u2212 In\nm(t1)| < \u03b5and some predicted class is NOT selected for\nservice under the P c\u00b5-rule in [nt1, n(t1 + \u03b4n\n1 (\u03b5))]. Then, there exists N(\u03b5) > 0 such that for any\nn > N(\u03b5)\n(i) (No Idling) if there is no server idle time in [nt1, n(t1 + \u03b4n\n1 (\u03b5))], then there exists sn\n1 \u2208 [t1 +\n\u03b30\u03b4n\n1 (\u03b5), t1 + \u03b4n\n1 (\u03b5)] such that maxl1,l2\u2208[K] |In\nl1(sn\n1 ) \u2212 In\nl2(sn\n1 )| < \u03b5;\n(ii) (Idling) if server idling occurs in [nt1, n(t1 +\u03b4n\n1 (\u03b5))], then maxl1,l2\u2208[K] |In\nl1(t1 +\u03b4n\n1 (\u03b5))\u2212In\nl2(t1 +\n\u03b4n\n1 (\u03b5))| < \u03b5.\nFinally, see Section D.4 for the proof of the third proposition.\nProposition 11 (Max difference of the P c\u00b5-rule indices within intervals) . Let t1 \u2208 [0, 1] be such\nthat maxl,m\u2208[K]\n\f\fIn\nl (t1) \u2212 In\nm(t1)\n\f\f < \u03b5. Then, there exists N(\u03b5) > 0 such that for any n > N(\u03b5)\nmax\nl1,l2\u2208[K]\nsup\nt\u2208[t1,(t1+\u03b4n\n1 (\u03b5))\u22271]\n\f\fIn\nl1(t) \u2212 In\nl2(t)\n\f\f < 3\u03b5/2.\nD.1 Preliminaries\nFacts about limiting diffusion processes We use the following basic facts to analyze the\ndynamics of \u02dcan.\nLemma 19 (Continuity of \u02dcAl and \u02dcSl). There exists N(\u03b5) such that for n > N(\u03b5) and t1, t2 \u2208 [0, 1],\n(i) if |t2 \u2212 t1| < \u03b4n\n1 (\u03b5), then | \u02dcAl(t2) \u2212 \u02dcAl(t1)| < \u03b10\u03b41(\u03b5)/3, \u2200 l \u2208 [K];\n(ii) if |t2 \u2212 t1| < \u03b4n\n1 (\u03b5), then |\u02dcSl(n\u22121Tn\nl (nt2)) \u2212 \u02dcSl(n\u22121Tn\nl (nt1))| < \u03b10\u03b41(\u03b5)/3, \u2200 l \u2208 [K].\nProof By Proposition 6, we have supt\u2208[0,1] | \u02dcAl(t+on(1))\u2212 \u02dcAl(t)| = on(1) by uniform continuity of\n\u02dcAl over a closed interval of which [0, 1] is a proper subset for all l \u2208 [K]. (i) is a direct consequence\nof |t2 \u2212 t1| = on(1). To see (ii), we have sup t\u2208[0,1] |\u02dcSl(t + on(1)) \u2212 \u02dcSl(t)| = on(1) similarly, and\nsupt\u2208[0,1] |n\u22121Tl(n(t + on(1))) \u2212 n\u22121Tl(nt)| = on(1) by (B.13).\n59",
            "source": "prompt",
            "quality_score": 0.0,
            "metadata": {
              "content_type": [
                "Result/Finding"
              ],
              "difficulty_level": 4,
              "retrieval_hints": [
                "What is the proof of the heavy traffic lower bound?",
                "How is the workload process connected to the theorem?",
                "What are the properties of the optimal solution?"
              ],
              "summary": "The chunk provides a detailed proof of the heavy traffic lower bound, analyzing the behavior of a specific function under certain conditions and establishing connections to workload processes."
            }
          },
          {
            "chunk_id": "prompt_59",
            "title": "__auto__",
            "text": "Lemma 20 (Relation between \u02dcan\nl and \u02dcT\nn\nl ). Given a classifier f\u03b8, suppose Assumptions A, B,\nand H hold. Under p-FCFS feasible policies,\n\u02dcan\nl (t) = n1/2t \u2212 n\u22121/2\u03c1\u22121\nl Tn\nl (nt) + \u03bb\u22121\nl \u02dcAl(t) \u2212 \u03bb\u22121\nl \u02dcSl(n\u22121Tn\nl (nt)) + on(1). (D.2)\nProof Recalling An\nl (nt) = n \u00afAn\nl (t)+ n1/2 \u02dcA\nn\nl (t)+ on(n1/2), Sn\nl (nt) = n \u00afSn\nl (t)+ n1/2 \u02dcS\nn\nl (t)+ on(n1/2)\n(Proposition 6),\n\u02dcN\nn\nl (t) = n1/2 \u00afAn\nl (t) + \u02dcA\nn\nl (t) \u2212 n1/2 \u00afSn\nl (n\u22121Tn\nl (nt)) \u2212 \u02dcS\nn\nl (n\u22121Tn\nl (nt)) + on(1)\n= n1/2 \u00afAl(t) + \u02dcAl(t) \u2212 n1/2 \u00afSl(n\u22121Tn\nl (nt)) \u2212 \u02dcSl(n\u22121Tn\nl (nt)) + on(1)\n= n1/2\u03bblt \u2212 n\u22121/2\u00b5lTn\nl (nt) + \u02dcAl(t) \u2212 \u02dcSl(n\u22121Tn\nl (nt)) + on(1),\n(D.3)\nwhere we used Nn\nl (nt) = An\nl (nt) \u2212 Sn\nl (Tn\nl (nt)), n1/2( \u00afAn\nl \u2212 \u00afAl) = on(1), n1/2( \u00afSn\nl \u2212 \u00afSl) = on(1)\nfrom Assumption B, and boundedness of n\u22121Tn\nl (n\u00b7) (B.13). Noting \u02dcan\nl (t) = \u03bb\u22121\nl \u02dcN\nn\nl (t) + on(1) by\nProposition 12, we have the desired result.\nAsymptotic Pc\u00b5 index For any predicted class l \u2208 [K] and t \u2208 [0, 1], the P c\u00b5 index and its\nasymptotic counterpart is\nIn\nl (t) := \u00b5n\nl \u00b7 n1/2(Cn\nl )\u2032(an\nl (nt)), \u00afIn\nl (t) := \u00b5l \u00b7 C\u2032\nl(\u02dcan\nl (t)) (D.4)\nTheir difference can be bounded by\n|\u00afIn\nl (t) \u2212 In\nl (t)| \u2264C\u2032\nl(\u02dcan\nl (t)) \u00b7 |\u00b5n\nl \u2212 \u00b5l| + \u00b5n\nl \u00b7 |n1/2(Cn\nl )\u2032(n1/2\u02dcan\nl (t)) \u2212 C\u2032\nl(\u02dcan\nl (t))|.\nNote that lim supn \u00b5n\nl < +\u221e from n1/2(\u00b5n\nl \u2212 \u00b5l) \u2192 0 (Assumption B), lim supn \u2225C\u2032\nl(\u02dcan\nl (\u00b7))\u2225 < +\u221e\nsince C\u2032\nl is continuous, and lim supn \u2225\u02dcan\nl \u2225 < +\u221e by Proposition 12. Since n1/2(Cn\nl )\u2032(n1/2\u00b7) \u2192 C\u2032\nl\nby Assumption C, we can conclude sup t\u2208[0,1] |\u00afIn\nl (t) \u2212 In\nl (t)| = on(1).\nLemma 21. There exists N(\u03b5) > 0 such that for any n \u2265 N(\u03b5),\nmax\nl\u2208[K]\nsup\nt\u2208[0,1]\n\f\f\u00afIn\nl (t) \u2212 In\nl (t)\n\f\f \u2264 min\nn \u03b5\n16, m\u03b20\n4 \u03b41(\u03b5)\no\n.\nBounding the difference between Pc\u00b5 indices When the difference of the scaled ages{\u02dcan\nl }l\u2208[K]\nis bounded, we demonstrate bounded differences of the indices over sufficiently small intervals.\nLemma 22 (Pc\u00b5 index: Continuity I). There exists N(\u03b5) > 0 such that for any n \u2265 N(\u03b5), l \u2208 [K],\nand 0 \u2264 t1 < t2 \u2264 1,\n(i) if \u02dcan\nl (t2) \u2212 \u02dcan\nl (t1) \u2264 \u03b41(\u03b5), then In\nl (t2) \u2212 In\nl (t1) \u2264 \u03b5\n4;\n(ii) if \u02dcan\nl (t2) \u2212 \u02dcan\nl (t1) \u2265 0, then In\nl (t2) \u2212 In\nl (t1) \u2265 max{\u2212\u03b5\n4, \u2212m\u03b20\u03b41(\u03b5)}.\nProof By Lemma 21, it suffices to show \u00afIn\nl (t2) \u2212 \u00afIn\nl (t1) \u2264 \u03b5/8 for (i) and \u00afIn\nl (t2) \u2212 \u00afIn\nl (t1) \u2265 0\nfor (ii). Noting C\u2032\nl is non-decreasing, we have\n\u00afIn\nl (t2) \u2212 \u00afIn\nl (t1) = \u00b5l[C\u2032\nl(\u02dcan\nl (t2)) \u2212 C\u2032\nl(\u02dcan\nl (t1))] \u2264 \u00b5l[C\u2032\nl(\u02dcan\nl (t1) + \u03b41(\u03b5)) \u2212 C\u2032\nl(\u02dcan\nl (t1))]\n60",
            "source": "prompt",
            "quality_score": 0.0,
            "metadata": {
              "content_type": [
                "Result/Finding"
              ],
              "difficulty_level": 4,
              "retrieval_hints": [
                "What is the proof of the heavy traffic lower bound?",
                "How is the workload process connected to the theorem?",
                "What are the properties of the optimal solution?"
              ],
              "summary": "The chunk provides a detailed proof of the heavy traffic lower bound, analyzing the behavior of a specific function under certain conditions and establishing connections to workload processes."
            }
          },
          {
            "chunk_id": "prompt_60",
            "title": "__auto__",
            "text": "which yields (i) by continuity of C\u2032\nl from Lemma 18. For (ii), non-decreasing C\u2032\nl again implies\n\u00afIn\nl (t2) \u2212 \u00afIn\nl (t1) = \u00b5l[C\u2032\nl(\u02dcan\nl (t2)) \u2212 C\u2032\nl(\u02dcan\nl (t1))] \u2265 0.\nNext, we bound the differences when the age process has a negative jump due to a job\u2019s departure\nfollowing service completion.\nLemma 23 (Size of a negative jump of P c\u00b5 index). There exists N(\u03b5) > 0 such that for n \u2265 N(\u03b5)\nsup\nt\u2208[0,1]\n|In\nl (t\u2212) \u2212 In\nl (t)| \u2264min\nn\u03b5\n4, m\u03b20\u03b41(\u03b5)\no\n.\nProof By Lemma 21, it suffices to show \u00afIn\nl (t\u2212)\u2212 \u00afIn\nl (t) \u2264 min{\u03b5\n8, m\u03b20\n2 \u03b41(\u03b5)}. \u02dcan\nl (t) \u0338= \u02dcan\nl (t\u2212) only\narises when a job from the predicted class l completes service and leaves the system at time t. By\ndefinition, the age process will incur a negative jump that corresponds to the interarrival time of\ntwo consecutive jobs. It follows from Proposition 6 that\n|\u02dcan\nl (t) \u2212 \u02dcan\nl (t\u2212)| \u2264n\u22121/2 sup\n1\u2264i\u2264An\nl (n)\nun\nli \u2264 min{\u03b41(\u03b5), \u03b42(\u03b5)}.\nfor all sufficently large n. Combining the above and continuity of C\u2032\nl from Lemma 18,\n|\u00afIn\nl (t) \u2212 \u00afIn\nl (t\u2212)| = \u00b5l|C\u2032\nl(\u02dcan\nl (t)) \u2212 C\u2032\nl(\u02dcan\nl (t\u2212))| \u2264min\nn\u03b5\n8, m\u03b20\n2 \u03b41(\u03b5)\no\n.\nD.2 Proof of Proposition 9\nWithout loss of generality, we fix \u03b5 > 0, n > N(\u03b5), and t1 \u2208 [0, 1 \u2212 \u03b4n\n1 (\u03b5)]. For simplicity, let\nt2 = t1 + \u03b4n\n1 (\u03b5). Choose any l1, l2 \u2208 [K]. By symmetry, it suffices to show that In\nl1(t2) \u2212I n\nl2(t2) < \u03b5.\nLet sn\n0 denote the largest (scaled) time point in [ t1, t2] at which the predicted class l2 is selected by\nPc\u00b5-rule\nsn\n0 := sup\n\u001a\nt | t \u2208 [t1, t2], In\nl2(t) = max\nl\u2208[K]\nIn\nl (t)\n\u001b\n.\nWe can obtain from the definition of P c\u00b5-rule that\nIn\nl1(t2) \u2212 In\nl2(t2) = [ In\nl1(t2) \u2212 In\nl1(sn\n0 )]| {z }\nby Lemmas 22 and 23, \u2264\u03b5/2\n+ [In\nl1(sn\n0 ) \u2212 In\nl2(sn\n0 )]| {z }\nby Pc\u00b5-rule, \u22640\n+ [In\nl2(sn\n0 ) \u2212 In\nl2(t2)]| {z }\nby Lemmas 22, \u2264\u03b5/2\n.\nThe second term satisfies In\nl1(sn\n0 ) \u2212 In\nl2(sn\n0 ) \u2264 0 since predicted class l2 is selected for service\nby Pc\u00b5-rule at time sn\n0 . The other two terms can be bounded by \u03b5/2 due to our selection of t2\nand continuity of P c\u00b5 index, as show in Lemmas 22 and 23. In particular, the first term can be\nbounded by\nIn\nl1(t2) \u2212 In\nl1(sn\n0 ) = [In\nl1(t2) \u2212 In\nl1((sn\n0 )\u2212)]| {z }\nby Lemma 22, \u2264\u03b5/4\n+ [In\nl1((sn\n0 )\u2212) \u2212 In\nl1(sn\n0 )]| {z }\nby Lemma 23, \u2264\u03b5/4\n\u2264 \u03b5/2,\nsince \u02dcan\nl1(t2) \u2212 \u02dcan\nl1(sn\n0 ) \u2264 n1/2(t2 \u2212 sn\n0 ) \u2264 \u03b41(\u03b5). Similarly, the third term satisfies\nIn\nl2(sn\n0 ) \u2212 In\nl2(t2) \u2264 \u03b5/2,\nby Lemma 23, since l2 is not served on the scaled interval [ sn\n0 , t2], and thus \u02dcan\nl2(t2) \u2212 \u02dcan\nl2(sn\n0 ) \u2265 0.\n61",
            "source": "prompt",
            "quality_score": 0.0,
            "metadata": {
              "content_type": [
                "Result/Finding"
              ],
              "difficulty_level": 4,
              "retrieval_hints": [
                "What is the proof of the heavy traffic lower bound?",
                "How is the workload process connected to the theorem?",
                "What are the properties of the optimal solution?"
              ],
              "summary": "The chunk provides a detailed proof of the heavy traffic lower bound, analyzing the behavior of a specific function under certain conditions and establishing connections to workload processes."
            }
          },
          {
            "chunk_id": "prompt_61",
            "title": "__auto__",
            "text": "D.3 Proof of Proposition 10\nLet t2 = t1 + \u03b4n\n1 (\u03b5). By symmetry, it suffices to show In\nl1(sn\n1 ) \u2212 In\nl2(sn\n1 ) < \u03b5for l1, l2 \u2208 [K]. First,\nconsider the scenario (ii) where idling occurs in [ nt1, nt2], i.e., P\nl Tn\nl (nt2) \u2212 P\nl Tn\nl (nt1) < n\u03b4n\n1 (\u03b5).\nSince we only consider work conserving policies, idling implies that there is no job in queue at some\ntime nsn\n2 \u2208 [nt1, nt2]. Consequently, the age of all predicted classes is zero \u02dc an\nl (sn\n2 ) = 0, \u2200 l \u2208 [K].\nThen,\nIn\nl1(t2) \u2212 In\nl2(t2) = [In\nl1(t2) \u2212 In\nl1(sn\n2 )]| {z }\nby Lemma 22, \u2264\u03b5/2\n+ [In\nl1(sn\n2 ) \u2212 In\nl2(sn\n2 )]| {z }\nby definition, =0\n+ [In\nl2(sn\n2 ) \u2212 In\nl2(t2)]| {z }\nby \u02dcan\nl2 (sn\n2 ) = 0, \u22640\n\u2264 \u03b5,\nsince In\nl2(t2) \u2265 0.\nThe case (i) where no idling occurs is more complicated. We begin by showing that the age and\nthe Pc\u00b5 index decrease sufficiently. See Section D.3.1 for the proof of the following result.\nLemma 24 (Sufficient descent in age process) . For all t1 \u2208 [0, 1 \u2212 \u03b4n\n1 (\u03b5)], assume\n(i) (Non-Selected Class) at least one predicted class, say ln\n0 , is not selected by P c\u00b5-rule in time\ninterval [nt1, n(t1 + \u03b4n\n1 (\u03b5))];\n(ii) (No Idling) P\nl Tn\nl (n(t1 + \u03b4n\n1 (\u03b5))) \u2212 P\nl Tn\nl (nt1) = n\u03b4n\n1 (\u03b5).\nThere exists N(\u03b5) such that for all n > N(\u03b5), there is a predicted class kn\n0 whose age process\ndecreases sufficiently: \u02dcan\nkn\n0\n(t1 + \u03b4n\n1 (\u03b5)) \u2212 \u02dcan\nkn\n0\n(t1) \u2264 \u22122\u03b10\u03b41(\u03b5).\nLet kn\n0 be the predicted class with \u02dcan\nkn\n0\n(t2) \u2212\u02dcan\nkn\n0\n(t1) \u2264 \u22122\u03b10\u03b41(\u03b5). Let sn\n1 denote the smallest scaled\ntime in [t1, t2] at which \u02dcan\nkn\n0\nexperience such decrease\nsn\n1 := inf{t | t \u2208 [t1, t2], \u02dcan\nkn\n0\n(t) \u2212 \u02dcan\nkn\n0\n(t1) \u2264 \u22122\u03b10\u03b41(\u03b5)}.\nIf predicted class l2 is selected for service by P c\u00b5-rule in [ nt1, nsn\n1 ], we can show In\nl1(sn\n1 ) \u2212\nIn\nl2(sn\n1 ) \u2264 \u03b5 by a similar analysis as the proof of Proposition 9. The crux of our proof lies in\nthe scenario where l2 is not selected in [ nt1, nsn\n1 ]. At sn\n1 , \u02dcan\nkn\n0\nhas a negative jump by a service\ncompletion in predicted class kn\n0 and the Pc\u00b5 index decreases sufficiently.\nLemma 25 (Sufficient descent in P c\u00b5 index). For any 0 \u2264 t1 < t2 \u2264 1, assume there exists some\npredicted class kn\n0 satisfying \u02dcan\nkn\n0\n(t2) \u2212 \u02dcan\nkn\n0\n(t1) \u2264 \u22122\u03b10\u03b41(\u03b5). There exists N(\u03b5) > 0 such that for\nany n \u2265 N(\u03b5), the P c\u00b5 index for this predicted class decreases sufficiently\nIn\nkn\n0\n(t2) \u2212 In\nkn\n0\n(t1) \u2264 \u22123m\u03b20\u03b41(\u03b5).\nProof By Lemma 21, it suffices to show\n\u00afIn\nkn\n0\n(t2) \u2212 \u00afIn\nkn\n0\n(t1) = \u00b5kn\n0\n\u0010\nC\u2032\nkn\n0\n(\u02dcan\nkn\n0\n(t2)) \u2212 C\u2032\nkn\n0\n(\u02dcan\nkn\n0\n(t1))\n\u0011\n\u2264 \u22124m\u03b20\u03b41(\u03b5).\nSince Ckn\n0\nis strongly convex,\n[C\u2032\nkn\n0\n(\u02dcan\nkn\n0\n(t2)) \u2212 C\u2032\nkn\n0\n(\u02dcan\nkn\n0\n(t1))][\u02dcan\nkn\n0\n(t2) \u2212 \u02dcan\nkn\n0\n(t1)] \u2265 m[\u02dcan\nkn\n0\n(t2) \u2212 \u02dcan\nkn\n0\n(t1)]2.\nThen, \u02dcan\nkn\n0\n(t2) \u2212 \u02dcan\nkn\n0\n(t1) \u2264 \u22122\u03b10\u03b41(\u03b5) yields\nC\u2032\nkn\n0\n(\u02dcan\nl (t2)) \u2212 C\u2032\nkn\n0\n(\u02dcan\nl (t1)) \u2264 m[\u02dcan\nkn\n0\n(t2) \u2212 \u02dcan\nkn\n0\n(t1)] \u2264 \u22122m\u03b10\u03b41(\u03b5),\n62",
            "source": "prompt",
            "quality_score": 0.0,
            "metadata": {
              "content_type": [
                "Result/Finding"
              ],
              "difficulty_level": 4,
              "retrieval_hints": [
                "What is the proof of the heavy traffic lower bound?",
                "How is the workload process connected to the theorem?",
                "What are the properties of the optimal solution?"
              ],
              "summary": "The chunk provides a detailed proof of the heavy traffic lower bound, analyzing the behavior of a specific function under certain conditions and establishing connections to workload processes."
            }
          },
          {
            "chunk_id": "prompt_62",
            "title": "__auto__",
            "text": "and\n\u00afIn\nkn\n0\n(t2) \u2212 \u00afIn\nkn\n0\n(t1) = \u00b5kn\n0\n[C\u2032\nkn\n0\n(\u02dcan\nkn\n0\n(t2)) \u2212 C\u2032\nkn\n0\n(\u02dcan\nkn\n0\n(t1))] \u2264 \u22122\u00b5minm\u03b10\u03b41(\u03b5) = \u22124m\u03b20\u03b41(\u03b5).\nBy Lemma 25, we have In\nkn\n0\n(sn\n1 ) \u2212 In\nkn\n0\n(t1) \u2264 \u22123m\u03b20\u03b41(\u03b5). Also, In\nl1((sn\n1 )\u2212) = In\nl1(sn\n1 ) because\npredicted class l1 is not served at sn\n1 . Consequently, there is no negative jump of the index and\nIn\nl1(sn\n1 ) = [ In\nl1(sn\n1 ) \u2212 In\nl1((sn\n1 )\u2212)]| {z }\nno negative jump at sn\n1 , =0\n+ [In\nl1((sn\n1 )\u2212) \u2212 In\nkn\n0\n((sn\n1 )\u2212)]\n| {z }\nby Pc\u00b5-rule, \u22640\n+ [In\nkn\n0\n((sn\n1 )\u2212) \u2212 In\nkn\n0\n(sn\n1 )]\n| {z }\nby Lemma 23, \u2264m\u03b20\u03b41(\u03b5)\n+ [In\nkn\n0\n(sn\n1 ) \u2212 In\nkn\n0\n(t1)]\n| {z }\n\u2264\u22123m\u03b20\u03b41(\u03b5)\n+In\nkn\n0\n(t1)\n\u2264 In\nkn\n0\n(t1) \u2212 m\u03b20\u03b41(\u03b5).\n(D.5)\nFor In\nl2(sn\n1 ), since l2 is NOT selected by the Pc\u00b5-rule in [nt1, nsn\n1 ], \u02dcan\nl2(sn\n1 )\u2212\u02dcan\nl2(t1) \u2265 0, which yields\nIn\nl2(sn\n1 ) \u2265 In\nl2(t1) \u2212 m\u03b20\u03b41(\u03b5) (D.6)\nby Lemma 22. By the condition in the proposition, subtracting (D.6) from (D.5) yields\nIn\nl1(sn\n1 ) \u2212 In\nl2(t2) \u2264 In\nkn\n0\n(t1) \u2212 In\nl2(t1) \u2264 \u03b5.\nTo show sn\n1 \u2265 t1 + \u03b30\u03b4n\n1 (\u03b5), recall from the choice of sn\n1 that\n\u02dcan\nkn\n0\n(sn\n1 ) \u2212 \u02dcan\nkn\n0\n(t1) \u2264 \u22122\u03b10\u03b41(\u03b5).\nThen, by Lemmas 19, 20, it is easy to verify that for sufficiently large n\nn(sn\n1 \u2212 t1) \u2265 Tn\nkn\n0\n(nsn\n1 ) \u2212 Tn\nkn\n0\n(nt1) \u2265 n1/2 \u00b7 \u03c1kn\n0\n[n1/2(sn\n1 \u2212 t1) + 2\u03b10\u03b41(\u03b5) \u2212 \u03b10\u03b41(\u03b5)]\n\u2265 n1/2 \u00b7 \u03c1min[n1/2(sn\n1 \u2212 t1) + \u03b10\u03b41(\u03b5)],\nwhere Tn\nkn\n0\n(nsn\n1 ) \u2212Tn\nkn\n0\n(nt1) \u2264 n(sn\n1 \u2212t1) follows from the definition of the policy process Tn\nkn\n0\n. This\nyields the desired result that sn\n1 \u2212 t1 \u2265 \u03b10\n1\u2212\u03c1min\n\u03b4n\n1 (\u03b5). Note that \u03b30 \u2208 (0, 1) because the critical load\ncondition P\nk \u03c1k = 1 in Assumption B implies that \u03c1min \u2264 1\nK and \u03c1max \u2265 1\nK .\nD.3.1 Proof of Lemma 24\nBy condition (i), it is clear that Tn\nln\n0\n(nt1 + n\u03b4n\n1 (\u03b5)) \u2212 Tn\nln\n0\n(nt1) = 0, since the predicted class ln\n0\nis not selected by P c\u00b5-rule in [ nt1, n(t1 + \u03b4n\n1 (\u03b5))]. Intuitively, the server is busy for serving other\npredicted classes, implying positive stochastic fluctuations of the policy processes dedicated to the\nother predicted classes, and there must be at least one predicted classes that absorbs the additional\nservice. In particular, we claim that there exists some predicted class kn\n0 such that\nTn\nkn\n0\n(n(t1 + n\u03b4n\n1 (\u03b5))) \u2212 Tn\nkn\n0\n(nt1) \u2265\n\u0010 \u03c1min\nK \u2212 1 + \u03c1kn\n0\n\u0011\n\u00b7 n\u03b4n\n1 (\u03b5). (D.7)\nFor simplicity, for all l \u2208 [K], let\n\u2206Tn\nl (nt1) := Tn\nl (n(t1 + n\u03b4n\n1 (\u03b5))) \u2212 Tn\nl (nt1), w n\nl := \u2206Tn\nl (nt1)/(n\u03b4n\n1 (\u03b5)),\n63",
            "source": "prompt",
            "quality_score": 0.0,
            "metadata": {
              "content_type": [
                "Result/Finding"
              ],
              "difficulty_level": 4,
              "retrieval_hints": [
                "What is the proof of the heavy traffic lower bound?",
                "How is the workload process connected to the theorem?",
                "What are the properties of the optimal solution?"
              ],
              "summary": "The chunk provides a detailed proof of the heavy traffic lower bound, analyzing the behavior of a specific function under certain conditions and establishing connections to workload processes."
            }
          },
          {
            "chunk_id": "prompt_63",
            "title": "__auto__",
            "text": "where \u2206Tn\nl (nt1) represents the service time allocated to predicted class l during [nt1, n(t1 +\u03b4n\n1 (\u03b5))],\nand wn\nl denotes its proportion in the time interval. According to conditions (i) and (ii) and\nAssumption B, it is easy to verify that\nX\nl\u0338=ln\n0\nwn\nl = 1,\nX\nl\u0338=ln\n0\n\u03c1l = 1 \u2212 \u03c1ln\n0\n\u2264 1 \u2212 \u03c1min.\nRearranging the terms, we can claim that there exists some predicted classkn\n0 satisfying wn\nkn\n0\n\u2212\u03c1kn\n0\n\u2265\n\u03c1min\nK\u22121, which is equivalent to (D.7).\nCombining (D.7) and Lemmas 19, 20, for sufficient large n\n\u02dcan\nkn\n0\n(t1 + \u03b4n\n1 (\u03b5)) \u2212 \u02dcan\nkn\n0\n(t1) = n1/2\u03b4n\n1 (\u03b5) \u2212 n\u22121/2\u03c1\u22121\nkn\n0\n\u2206Tn\nkn\n0\n(nt) + \u03b10\u03b41(\u03b5)\n\u2264 \u03b41(\u03b5) \u2212 \u03c1\u22121\nkn\n0\n\u0010 \u03c1min\nK \u2212 1 + \u03c1kn\n0\n\u0011\n\u00b7 \u03b41(\u03b5) + \u03b10\u03b41(\u03b5)\n\u2264 \u22123\u03b10\u03b41(\u03b5) + \u03b10\u03b41(\u03b5) = \u22122\u03b10\u03b41(\u03b5).\nD.4 Proof of Proposition 11\nFix t2 \u2208 [t1, (t1 + \u03b4n\n1 (\u03b5)) \u2227 1]. By symmetry, it suffices to show In\nl1(t2) \u2212 In\nl2(t2) < 3\u03b5/2 for any\nl1, l2 \u2208 [K]. When l2 is selected for service by Pc\u00b5-rule in [nt1, nt2], we can employ a similar analysis\nas in the proof of Proposition 9 to show In\nl1(t2) \u2212 In\nl2(t2) < \u03b5. For the other case, we have from\nLemma 22 that In\nl2(t2)\u2212I n\nl2(t1) \u2265 \u2212\u03b5/4, since \u02dcan\nl2(t2)\u2212\u02dcan\nl2(t1) \u2265 0. Also, once again by Lemma 22,\none can check In\nl1(t2) \u2212 In\nl1(t1) \u2264 \u03b5/4 since t2 \u2212 t1 \u2264 \u03b4n\n1 (\u03b5). Combining equations above yields the\ndesired result.\nE Proof of Theorem 3\nE.1 Overview of the proof\nOur goal is to show condition (4.3), from which Lemma 1 will imply Theorem 3.\nRelationships between (\u02dc\u03c4n\nl , \u02dcN\nn\nl , \u02dcT\nn\nl , \u02dcW\nn\nl ) and \u02dcan\nl Since the P c\u00b5-rule uses observable ages, we\nneed to connect \u02dcan\nl and the endogenous processes (\u02dc \u03c4n\nl , \u02dcN\nn\nl , \u02dcT\nn\nl , \u02dcW\nn\nl ), \u2200 l \u2208 [K]. We prove the\nequivalence between the original KKT conditions (4.3) and the modified version for age (4.4),\nprovided that either \u02dc\u03c4n\nl \u2192 \u02dc\u03c4l or \u02dcan\nl \u2192 \u02dcal. For predicted class l \u2208 [K], \u03bbl is the limiting arrival rate\n(see Definition 10).\nProposition 12 (Relationship between \u02dcan\nl and \u02dc\u03c4n\nl ). Given a classifier f\u03b8 and a sequence of queueing\nsystems, suppose that Assumptions A, B, and H hold. Under p-FCFS feasible policies, for any\npredicted class l \u2208 [K], (i) \u03bbl\u02dcan\nl \u2212 \u02dcN\nn\nl \u2192 0, (ii) maxl\u2208[K] lim supn \u2225\u02dcan\nl \u2225 < \u221e; (iii) {\u02dcan\nl }n converges iff\n{\u02dc\u03c4n\nl }n converges; (iv) their limits coincide: if there exist \u02dcal, \u02dc\u03c4l \u2208 Csuch that \u02dcan\nl \u2192 \u02dcal and \u02dc\u03c4n\nl \u2192 \u02dc\u03c4l,\nthen \u02dcal = \u02dc\u03c4l.\nThe proof of Proposition 12 requires the arrival rates of the predicted classes to converge to{\u03bbl}l\u2208[K]\nat rate o(n\u22121/2), for which the conditions in Assumption B are essential. We also characterize\nthe relationship between \u02dcan\nl and the policy process \u02dcT\nn\nl in Corollary 20, which allows for directly\nanalyzing the dynamics of the age process \u02dcan\nl .\n64",
            "source": "prompt",
            "quality_score": 0.0,
            "metadata": {
              "content_type": [
                "Result/Finding"
              ],
              "difficulty_level": 4,
              "retrieval_hints": [
                "What is the proof of the heavy traffic lower bound?",
                "How is the workload process connected to the theorem?",
                "What are the properties of the optimal solution?"
              ],
              "summary": "The chunk provides a detailed proof of the heavy traffic lower bound, analyzing the behavior of a specific function under certain conditions and establishing connections to workload processes."
            }
          },
          {
            "chunk_id": "prompt_64",
            "title": "__auto__",
            "text": "Convergence of the P c\u00b5 indices and the scaled age processes Since the P c\u00b5-rule serves\nthe job that has the highest index value, the gap between the class indices becomes small and the\nconvergence (4.4) holds.\nProposition 13 (Convergence of max difference of the Pc\u00b5 indices). Given a classifier f\u03b8, suppose\nthat Assumptions A, B, C, D, and H hold. Under the P c\u00b5-rule,\nsup\nt\u2208[0,1]\nmax\nl,m\u2208[K]\n\f\fIn\nl (t) \u2212 In\nm(t)\n\f\f \u2192 0. (E.1)\nBy the continuity of the inverse cost function (C\u2032\nl)\u22121, convergence of {\u02dcan\nl }l\u2208[K] follows (Lemma 26)\nand we have the desired final result.\nWe prove Proposition 13 in Section D. Specifically, we partition [0 , 1], the domain of the\ndiffusion-scaled processes, into intervals of size O(n\u22121/2) and show that max l,m\u2208[K] |In\nl (t) \u2212 In\nm(t)|\ndo not exhibit substantial growth within each interval if its size is chosen carefully. The main\ntechnical challenge is to demonstrate that such growth do not accumulate over time. Since\nmaxl,m\u2208[K] |In\nl (0) \u2212 In\nm(0)| = 0, we proceed via induction: for a fixed \u03b5 >0, we show that\n(i) at each endpoint t of every interval, maxl,m\u2208[K] |In\nl (t) \u2212 In\nm(t)| \u2264\u03b5 (Propositions 9 and 10);\n(ii) within each interval I, supt\u2208I maxl,m\u2208[K] |In\nl (t) \u2212 In\nm(t)| \u22643\u03b5/2 (Proposition 11).\nWe outline the proof for part (i) (part (ii) can be shown similarly). Given an interval [ t1, t2],\nBy symmetry it suffices to show In\nl (t2) \u2212 In\nm(t2) \u2264 \u03b5 for any l, m\u2208 [K]. First, for the case that\npredicted class m is selected by the P c\u00b5-rule at some time ns \u2208 [nt1, nt2], we use definition of the\nPc\u00b5-rule to bound such growth. In particular,\nIn\nl (t2) \u2212 In\nm(t2) \u2264 [In\nl (t2) \u2212 In\nl (s)]| {z }\nbounded increase, \u2264\u03b5/2\n+ [In\nl (s) \u2212 In\nm(s)]| {z }\nby the Pc\u00b5-rule, \u2264 0\n+ [ In\nm(s) \u2212 In\nm(t2)]| {z }\nbounded increase, \u2264\u03b5/2\n, (E.2)\nwhere the first and the last term are bounded by \u03b5/2 due to our choice of t2 \u2212 t1 = O(n\u22121/2) and\nthe smoothness of the cost functions in Assumption C, and the second term is non-positive since\npredicted class m is chosen by the P c\u00b5-rule at time ns.\nFor the other case that predicted class m is never selected by the P c\u00b5-rule during the interval\n[nt1, nt2], the analysis is more involved and requires development of novel analysis techniques. If the\nserver is idling at some ns \u2208 [nt1, nt2], our analysis is similar to (E.2) and the second term becomes\nzero since the P c\u00b5-rule is work-conserving. Otherwise, if there is no idling during [ nt1, nt2], then\nintuitively, the server is busy serving other K \u2212 1 predicted classes. By heavy traffic assumptionP\nl \u03c1l = 1 (Assumption B), there exists at least one predicted classkn\n0 that receives sufficient service\nfrom the server (See (D.7)) and incurs sufficient descent in the age process (Lemma 24) in [nt1, nt2].\nThen, by strong convexity of the Pc\u00b5 cost Ckn\n0\n(Assumption D), the Pc\u00b5 index of class kn\n0 , say In\nkn\n0\n,\nalso incurs sufficient descent (Lemma 25). Such descent in the Pc \u00b5 index enables us to bound the\ngrowth of In\nl and derive the desired result in Proposition 10.\nE.2 Comparison to the optimality result in Van Mieghem [63]\nPlugging Qn = I, our proof gives the optimality of the well-known Gc\u00b5-rule where true class labels\nare known [63]. In this special case, our analysis identifies missing arguments in Van Mieghem [63]\u2019s\noriginal proof and provides conditions under which his original claims hold. For example, we require\n65",
            "source": "prompt",
            "quality_score": 0.0,
            "metadata": {
              "content_type": [
                "Result/Finding"
              ],
              "difficulty_level": 4,
              "retrieval_hints": [
                "What is the proof of the heavy traffic lower bound?",
                "How is the workload process connected to the theorem?",
                "What are the properties of the optimal solution?"
              ],
              "summary": "The chunk provides a detailed proof of the heavy traffic lower bound, analyzing the behavior of a specific function under certain conditions and establishing connections to workload processes."
            }
          },
          {
            "chunk_id": "prompt_65",
            "title": "__auto__",
            "text": "arrival rates to converge at rate o(n\u22121/2), and use Assumption B on \u03bbn, pn\nk and qn\nkl, \u2200k, l\u2208 [K]\naccordingly. We find that the same convergence rate should have been assumed on the analogous\nprocess, \u00afAn\nk in Van Mieghem [63], in order to correctly connect the age and sojourn time processes.\nThe first missing piece is that the G c\u00b5-rule uses the ages of waiting jobs for scheduling,\nbut Van Mieghem [63] does not prove the Gc\u00b5-rule achieves optimality conditions defined in terms\nof the sojourn times [63, Eq (54)]. We show that scaled sojourn time processes converge to a\nlimit satisfying the optimality condition under the G c\u00b5-rule using Proposition 13, and thus con-\ndition (4.3) (extension of Van Mieghem [63, Eq (54)]) is satisfied. This missing justification was\nnontrivial (to us), and we hope our rigorous arguments provide analytical value to subsequent\nworks.\nSecond, we found the proof of Proposition 13 to be nontrivial. Our analysis of the index dy-\nnamics with the particular choice of the partition size of the time horizon entails carefully handling\nerrors of diffusion approximations for predicted classes (Proposition 1 and 6). We control the evo-\nlution of {\u02dcan\nl }l\u2208[K] under the P c\u00b5-rule, which requires formally establishing relationships between\n\u02dcan\nl , \u02dc\u03c4n\nl , and \u02dcT\nn\nl .\nIn particular, our proof of Proposition 13 identifies a previously unstated necessary condition:\nstrong convexity of the cost functions in Assumption D. The curvature ensures that if some predicted\nclass is not served and its index increases in a subinterval of the partition, then there is another\npredicted class kn\n0 that receives ample service so that the index In\nkn\n0\ndecreases enough (Lemma 25),\nimplying that the gap between the indices remains small. On the other hand, under the strict\nconvexity Van Mieghem [63] assumes, we were unable to show the desired convergence he claims\n(either [63, Eq (54)] or a more general version in Proposition 13).\nE.3 Comparison to the optimality result in Mandelbaum and Stolyar [40]\nSimilarly as in Van Mieghem [63], our analysis with perfect classification ( Qn = I) also identifies\nmissing pieces in the optimality proof by Mandelbaum and Stolyar [40] for the G c\u00b5-rule with\nsojourn time cost (called D-Gc\u00b5 in [40]) in single-server systems and provides conditions for the\nclaims to hold.\nFirst, similarly to [63], although Mandelbaum and Stolyar [40] suggests using age processes\nfor the D-Gc\u00b5 rule, they did not prove that their D-Gc\u00b5 rule satisfies optimality conditions they\nadopted, which are based on sojourn time processes and identical to (4.3) in the single-server case.\nSpecifically, we find that [40, Eq (66)] that connects D-Gc\u00b5 to the preceding analysis in [40] should\nhave been shown in terms of the queue length and age processes similarly to Proposition 12 (i).\nUsing an equivalence between the age and sojourn time processes analogous to Proposition 12 (iii)\nand (iv), the optimality of D-Gc\u00b5 could be obtained. Accordingly, the (faster) convergence rate of\no(n\u22121/2) on the arrival rates as in Assumption B would be also required in [40].\nOur analysis shows the optimality of the D-Gc\u00b5 in the single-server case requires weaker as-\nsumptions on cost functions than those adopted in Mandelbaum and Stolyar [40]. The optimality\nin [40, Theorem 2] is built on the attraction propery of the fluid-scaled queue length limit [40,\nTheorem 3]. In the single-server case, the key implications of the attraction property are the small\ngaps between the class indices over subintervals [40, Eqs. (55), (56)], which are analogous to Propo-\nsitions 9, 10, and 11. Mandelbaum and Stolyar [40, Theorem 3] require the cost functions to be\ntwice continuously differentiable (and strongly convex) in order for the workload and queue length\nlimits to be amenable to analysis in the multi-server setting. In contrast, our analysis directly\n66",
            "source": "prompt",
            "quality_score": 0.0,
            "metadata": {
              "content_type": [
                "Result/Finding"
              ],
              "difficulty_level": 4,
              "retrieval_hints": [
                "What is the proof of the heavy traffic lower bound?",
                "How is the workload process connected to the theorem?",
                "What are the properties of the optimal solution?"
              ],
              "summary": "The chunk provides a detailed proof of the heavy traffic lower bound, analyzing the behavior of a specific function under certain conditions and establishing connections to workload processes."
            }
          },
          {
            "chunk_id": "prompt_66",
            "title": "__auto__",
            "text": "identifies the dynamics of the age processes under the D-Gc\u00b5 in the single-server case, and prove\nthe counterpart propositions under the weaker conditions, namely Assumptions C and D.\nE.4 Detailed proof of Theorem 3\nWe begin by showing the convergence of the age process, whose proof we give in Section E.5.\nLemma 26 (Convergence of \u02dcan). Given a classifier f\u03b8, suppose that Assumptions A, B, C, D,\nand H hold. Under the P c\u00b5-rule, there exists \u02dca \u2208 CK such that \u02dcan \u2192 \u02dca in (DK, \u2225 \u00b7 \u2225) Pcopy-a.s..\nFrom the above lemma and Proposition 1, the relation between \u02dcan\nl and \u02dc\u03c4n\nl in Proposition 12 implies\nconvergence of \u02dc\u03c4n\nl \u2192 \u02dc\u03c4l, \u02dcan\nl \u2192 \u02dcal, \u02dcN\nn\nl \u2192 \u02dcNl, \u02dcT\nn\nl \u2192 \u02dcTl, and \u02dcW\nn\nl \u2192 \u02dcWl.\nIf \u02dc\u03c4l, \u02dcal \u2208 C, Proposition 12 implies \u02dc\u03c4l = \u02dcal. Since \u02dcal \u2208 Cby Lemma 26, it is easy to verify\n\u02dcNl, \u02dcTl, \u02dcWl \u2208 Cfrom the relation between \u02dcal and \u02dcNl in Proposition 12, relation (B.14) between \u02dcNl\nand \u02dcTl, and relation (B.10) between \u02dcTl and \u02dcWl. Using the relation (B.15) between \u02dc\u03c4l, \u02dcWl, and \u02dcTl,\none can check that \u02dc\u03c4l \u2208 C.\nBy Lemma 16 and Proposition 8, we have \u02dc\u03c4l = \u02dcWl/\u03c1l, \u2200 l \u2208 [K]. Proposition 13 then implies\n\u02dc\u03c4l = \u02dcWl/\u03c1l, \u2200 l \u2208 [K],\nX\nl\u2208[K]\n\u02dcWl = \u02dcW+, \u00b5 lC\u2032\nl(\u02dc\u03c4l) = \u00b5mC\u2032\nm(\u02dc\u03c4m), \u2200 l, m\u2208 [K]. (E.3)\nBy Proposition 15, it follows \u03c1l\u02dc\u03c4l = [ h( \u02dcW+)]l, \u2200 l \u2208 [K]. This yields \u02dcJn\nPc\u00b5(\u00b7; Qn) \u2192 \u02dcJ\u2217(\u00b7; Q)\nPcopy-a.s. according to Theorem 2 and Lemma 1.\nThe weak convergence on the original systems\u02dcJn\nPc\u00b5(\u00b7; Qn) \u21d2 \u02dcJ\u2217(\u00b7; Q) in (D, \u2225\u00b7\u2225) follows from [31,\nLemma 3.2, Lemma 3.7]. Moreover, for any x \u2208 R, t \u2208 [0, 1], by reverse Fatou\u2019s lemma and the\nPcopy-a.s. convergence of \u02dcJn\nPc\u00b5(\u00b7; Qn), we have\nlim sup\nn\nPn[ \u02dcJn\nPc\u00b5(t; Qn) > x] \u2264EPcopy[lim sup\nn\nI{ \u02dcJn\nPc\u00b5(t; Qn) > x}]\n=EPcopy[I{ \u02dcJ\u2217(t; Qn) > x}]\n=Pcopy[ \u02dcJ\u2217(t; Q) > x].\nCombining this with lim inf n Pn[ \u02dcJn\nPc\u00b5(t; Qn) > x] \u2265 Pcopy[ \u02dcJ\u2217(t; Q) > x] from Theorem 2 gives the\ndesired result: Pn[ \u02dcJn\nPc\u00b5(t; Qn) > x] \u2192 Pcopy[ \u02dcJ\u2217(t; Q) > x].\nE.5 Proof of Lemma 26\nBy Proposition 13 and Lemma 21, the P c\u00b5-rule gives max l,s\u2208[K] \u2225\u00b5lC\u2032\nl(\u02dcan\nl ) \u2212 \u00b5sC\u2032\nl(\u02dcan\ns )\u2225 \u21920.\nGiven s \u2208 [K], for any l \u2208 [K], since \u00b5l > 0 by Assumption A and Definition 10, we have\nC\u2032\nl(\u02dcan\nl )\u2212\n\u00b5s\n\u00b5l\nC\u2032\ns(\u02dcan\ns ) \u2192 0. Letting fs(\u00b7) := PK\nl=1 \u03c1l\u00b7(C\u2032\nl)\u22121\u0000\u00b5s\n\u00b5l\nC\u2032\ns(\u00b7)\n\u0001\n, note that PK\nl=1 \u03c1l\u02dcan\nl \u2212\n\u0000\nfs\u25e6\u02dcan\ns\n\u0001\n\u2192\n0 from continuity of (C\u2032\nl)\u22121 (Assumption C). Under p-FCFS feasible policies, Lemma 16 and Propo-\nsition 12 implies \u02dcW\nn\nl \u2212 \u03c1l\u02dcan\nl \u2192 0. Applying Proposition 1, there exists \u02dcW+ \u2208 C([0, 1], R) such thatPK\nl=1 \u03c1l\u02dcan\nl \u2192 \u02dcW+. Hence, fs \u25e6 \u02dcan\ns \u2192 \u02dcW+.\nSince fs is continuous and strictly increasing, f\u22121\ns is well-defined and also continuous. Conclude\n(f\u22121\ns , fs \u25e6 \u02dcan\ns ) \u2192 (f\u22121\ns , \u02dcW+) in C2 under the product topology induced by \u2225 \u00b7 \u2225. By the continuity of\ncomposition (e.g., [68, Theorem 13.2.1]), \u02dcan\ns = f\u22121\ns \u25e6\n\u0000\nfs \u25e6 \u02dcan\ns\n\u0001\n\u2192 \u02dcas := f\u22121\ns \u25e6 \u02dcW+ where \u02dcas \u2208 Cby\ncontinuity of f\u22121\ns and \u02dcW+. This completes our proof.\n67",
            "source": "prompt",
            "quality_score": 0.0,
            "metadata": {
              "content_type": [
                "Result/Finding"
              ],
              "difficulty_level": 4,
              "retrieval_hints": [
                "What is the proof of the heavy traffic lower bound?",
                "How is the workload process connected to the theorem?",
                "What are the properties of the optimal solution?"
              ],
              "summary": "The chunk provides a detailed proof of the heavy traffic lower bound, analyzing the behavior of a specific function under certain conditions and establishing connections to workload processes."
            }
          },
          {
            "chunk_id": "prompt_67",
            "title": "__auto__",
            "text": "E.6 Proof of Proposition 12\nWe show the asymptotically linear relationship (i) between \u02dcan\nl and \u02dcN\nn\nl . Other results immediately\nfollow from (i) and Propositions 1 and Proposition 8. We use a reformulation of the age process.\nClaim 27.\nan\nl (nt) = nt \u2212 Un\nl (An\nl (nt) \u2212 Nn\nl (nt) + 1) +on(n1/2). (E.4)\nSince Un\nl (nt) = n \u00afUn\nl (t) + n1/2 \u02dcU\nn\nl (t) + on(n1/2) by Proposition 6, we can further rewrite (E.4) as\n\u02dcan\nl (t) = n1/2[t \u2212 \u00afUn\nl (n\u22121(An\nl (nt) \u2212 Nn\nl (nt) + 1))]\u2212 \u02dcU\nn\nl (n\u22121(An\nl (nt) \u2212 Nn\nl (nt) + 1)) +on(1).\nRecall An\nl (nt) = n \u00afAn\nl (t) +n1/2 \u02dcA\nn\nl (t) +on(n1/2) by Proposition 6, \u02dcN\nn\nkl := n\u22121\n2 Nn\nkl by Definition 11,\nand lim supn \u2225 \u02dcN\nn\nkl\u2225 \u2264lim supn \u2225 \u02dcN\nn\nl \u2225 < +\u221e by Proposition 1. Evidently,\nn\u22121(An\nl (nt) \u2212 Nn\nl (nt) + 1) = \u00afAn\nl (t) + n\u22121/2 \u02dcA\nn\nl (t) \u2212 n\u22121/2 \u02dcN\nn\nk(t) + on(n\u22121/2)\n= \u00afAl(t) + n\u22121/2 \u02dcAl(t) \u2212 n\u22121/2 \u02dcN\nn\nk(t) + on(n\u22121/2) = \u00afAl(t) + on(1),\n\u02dcU\nn\nl (n\u22121(An\nl (nt) \u2212 Nn\nl (nt) + 1))\n(a)\n= \u02dcUl( \u00afAl(t) + on(1)) + on(1)\n(b)\n= \u2212 \u03bb\u22121\nl \u02dcAl(t + on(1)) + on(1)\n(c)\n= \u2212\u03bb\u22121\nl \u02dcAl(t) + on(1)\nwhere we used \u02dcU\nn\nl \u2192 \u02dcUl by Proposition 6 in step (a), \u02dcUl(t) = \u2212\u03bb\u22121\nl \u02dcAl(\u03bb\u22121\nl t) by the proof of\nProposition 6 in step (b), and the uniform continuity of \u02dcAl on compact intervals in step (c). Since\nn1/2( \u00afUn\nl \u2212 \u00afUl) = on(1) by Assumption B, and \u00afAl(t) = \u03bblt, \u00afUl(t) = \u03bb\u22121\nl t by Proposition 6\nn1/2[t \u2212 \u00afUn\nl (n\u22121(An\nl (nt) \u2212 Nn\nl (nt) + 1))] = n1/2t \u2212 n1/2 \u00afUl(n\u22121(An\nl (nt) \u2212 Nn\nl (nt) + 1)) +on(1)\n= \u2212 \u03bb\u22121\nl [ \u02dcAl(t) \u2212 \u02dcN\nn\nl (t)] + on(1).\nCollecting previous derivations, we have the desired result.\nProof of claim For fixed t \u2208 [0, 1], we first consider the case that An\nl (nt) = 0. Since there is no\narrival to the predicted class l at time nt, it is easy to verify that an\nl (nt) = 0, Nn\nl (nt) = 0, and\nnt \u2264 ul1. Therefore, we obtain that\n\f\f\fan\nl (nt) \u2212 [nt \u2212 Un\nl (An\nl (nt) \u2212 Nn\nl (nt) + 1)]\n\f\f\f = |0 \u2212 [nt \u2212 Un\nl (1)]| \u2264 |ul1| = on(n1/2),\nwhere the last equality follows from Propositon 6. When An\nl (nt) \u2265 1, An\nl (nt)\u2212Nn\nl (nt) jobs from the\npredicted class l have completed service and exited the queue. Under a p-FCFS policy, the oldest\ncustomer from the predicted class l at time nt corresponds to the [An\nl (nt)\u2212Nn\nl (nt)+1]th arrival of\npredicted class l. From the definition of an\nl (nt) as the time difference betweennt and the arrival time\nof the oldest job in predicted class l, the exact formulation an\nl (nt) = nt \u2212Un\nl (An\nl (nt) \u2212Nn\nl (nt) + 1)\nfollows. This completes our proof of (E.4).\nF Proofs for Section 6\nF.1 Proof for Proposition 4\nFrom Theorem 2, \u02dcJ\u2217(t; Q) =\nRt\n0\nPK\nl=1\nPK\nk=1 \u03bbpkqklCk(\u02dc\u03c4l(s))ds where {\u02dc\u03c4l}l\u2208[K] is characterized by\n\u02dc\u03c4l = \u02dcWl/\u03c1l, \u2200 l \u2208 [K],\nX\nl\n\u02dcWl = \u02dcW+, \u00b5 lC\u2032\nl(\u02dc\u03c4l) = \u00b5mC\u2032\nm(\u02dc\u03c4m), \u2200 l, m\u2208 [K]. (F.1)\n68",
            "source": "prompt",
            "quality_score": 0.0,
            "metadata": {
              "content_type": [
                "Result/Finding"
              ],
              "difficulty_level": 4,
              "retrieval_hints": [
                "What is the proof of the heavy traffic lower bound?",
                "How is the workload process connected to the theorem?",
                "What are the properties of the optimal solution?"
              ],
              "summary": "The chunk provides a detailed proof of the heavy traffic lower bound, analyzing the behavior of a specific function under certain conditions and establishing connections to workload processes."
            }
          },
          {
            "chunk_id": "prompt_68",
            "title": "__auto__",
            "text": "According to Assumption E, we can equivalently reformulate (F.1) as\n\u03c1l\u02dc\u03c4l(t; Q) = (\u03b2l(Q))\u22121\nPK\nm=1(\u03b2m(Q))\u22121\n\u02dcW+(t), \u03b2 l(Q) =\n\u00b5lcl\n\u03c1l\n, \u2200 t \u2208 [0, 1], \u2200 l \u2208 [K].\nFor any s \u2208 [0, t], the integrand PK\nl=1\nPK\nk=1 \u03bbpkqklCk(\u02dc\u03c4l(s)) can be written as\nKX\nl=1\nKX\nk=1\n\u03bbpkqkl\nck\n2\n1\n\u03c12\nl\n\u0010 \u02dcW+(s)\nPK\nm=1\n\u03b2l(Q)\n\u03b2m(Q)\n\u00112\n= 1\n2\n\u02dcW2\n+(s)\nKX\nl=1\n1\n\u03c12\nl\n\u0010 1\nPK\nm=1\n\u03b2l(Q)\n\u03b2m(Q)\n\u00112 KX\nk=1\n\u03bbpkqklck\n= 1\n2\n\u02dcW2\n+(s)\nKX\nl=1\n\u03b2l(Q)\u0000PK\nm=1\n\u03b2l(Q)\n\u03b2m(Q)\n\u00012 ,\nwhere the last equality holds since \u03b2l(Q) = \u00b5lcl/\u03c1l, cl =\nP\u03bbpkqklckP\u03bbpkqkl\nby definition. The summation\nterm can be further written as\nKX\nl=1\n\u03b2l(Q)\u0000PK\nm=1\n\u03b2l(Q)\n\u03b2m(Q)\n\u00012 =\nKX\nl=1\n\u03b2l(Q)\n\u0000Q\nr\u0338=l \u03b2r(Q)\n\u00012\n\u0000PK\nm=1\n\u03b2l(Q)\n\u03b2m(Q)\n\u00012\u0000Q\nr\u0338=l \u03b2r(Q)\n\u00012\n=\nKX\nl=1\n\u03b2l(Q)\n\u0000Q\nr\u0338=l \u03b2r(Q)\n\u00012\n\u0000PK\nm=1\nQ\nr\u0338=m \u03b2m(Q)\n\u00012 =\nQK\nr=1 \u03b2r(Q)PK\nm=1\nQ\nr\u0338=m \u03b2r(Q)\n= 1PK\nm=1(\u03b2m(Q))\u22121 .\nBy a similar approach to the proof of Lemma 26, the age process converges under the Naive\nGc\u00b5-rule, and by Lemma 1, the cumulative cost converges to\n\u02dcJNaive(t; Q) =\nKX\nl=1\nKX\nk=1\nZ t\n0\n\u03bbpkqklCk(\u02dc\u03c4l,Naive(s))ds,\nwhere {\u02dc\u03c4l,Naive}l\u2208[K] is the limit of the sojourn time process under the Naive G c\u00b5-rule. By similar\nanalysis as in the proof of Theorem 3, the limit {\u02dc\u03c4l,Naive}l\u2208[K] is characterized by\n\u02dc\u03c4l,Naive = \u02dcWl/\u03c1l, \u2200 l \u2208 [K],\nX\nl\n\u02dcWl = \u02dcW+, \u00b5 lC\u2032\nl(\u02dc\u03c4l) = \u00b5mC\u2032\nm(\u02dc\u03c4m), \u2200 l, m\u2208 [K].\nIn contrast with Eq. (E.3), each predicted class l \u2208 [K] is associated with the original cost function\nCl in the above characterization, which does not take into account misclassification errors in the\nmarginal cost rate of the class. It follows that\n\u03c1l\u02dc\u03c4l,Naive(t; Q) = (\u03b2l,Naive(Q))\u22121\nPK\nm=1(\u03b2m,Naive(Q))\u22121\n\u02dcW+(t), \u03b2 l,Naive(Q) =\n\u00b5lcl\n\u03c1l\n, \u2200 l \u2208 [K].\nCombining the equations above and noting \u03b2l(Q) = \u00b5lcl/\u03c1l, we have\n\u02dcJNaive(t; Q) =\nKX\nl=1\nKX\nk=1\nZ t\n0\n\u03bbpkqkl\nck\n2\u03c12\nl\n\u02dcW2\n+(s)\n\u0010 (\u03b2l,Naive(Q))\u22121\nPK\nm=1(\u03b2m,Naive(Q))\u22121\n\u00112\nds\n=\nKX\nl=1\n\u03b2l(Q)\n\u0000P\nm\n\u03b2l,Naive(Q)\n\u03b2m,Naive(Q)\n\u00012 \u00b7 1\n2\nZ t\n0\n\u02dcW2\n+(s)ds.\n(F.2)\n69",
            "source": "prompt",
            "quality_score": 0.0,
            "metadata": {
              "content_type": [
                "Result/Finding"
              ],
              "difficulty_level": 4,
              "retrieval_hints": [
                "What is the proof of the heavy traffic lower bound?",
                "How is the workload process connected to the theorem?",
                "What are the properties of the optimal solution?"
              ],
              "summary": "The chunk provides a detailed proof of the heavy traffic lower bound, analyzing the behavior of a specific function under certain conditions and establishing connections to workload processes."
            }
          },
          {
            "chunk_id": "prompt_69",
            "title": "__auto__",
            "text": "G Proof of results in Section 7\nG.1 Joint convergence of the AI-based triage system\nWe define the concerned processes below to analyze the AI triage system.\nDefinition 12 (Arrival processes of the AI-based triage system) . Given a classifier f\u03b8, filtering\nlevel zFL, the number of hired reviewers \u0393(zFL), and a sequence of queueing systems, suppose that\nAssumptions F and G hold. We define the following for any system n, reviewer r \u2208 \u0393(zFL), and\ntime t \u2208 [0, n]:\n(i) (Arrival process of the triage system) Let Un\n0 (t) := P\u230at\u230b\ni=1 un\ni be the partial sum of interarrival\ntimes among the first \u230at\u230b jobs arriving at the triage system, and An\n0 (t) be the number of jobs\nthat arrive at the triage system n up to time t. Moreover, let \u02dcUn\n0 (t), \u02dcAn\n0 (t) be the corresponding\ndiffusion-scaled process, defined as\n\u02dcUn\n0 (t) = n\u22121/2[Un\n0 (nt) \u2212 \u039b\u22121\nn \u00b7 nt], \u02dcAn\n0 (t) = n\u22121/2[An\n0 (nt) \u2212 \u039bn \u00b7 nt], \u2200 t \u2208 [0, 1];\n(ii) (Arrival process of jobs filtered out) For each class k \u2208 {1, 2}, let Un\nfl,k(t) be the partial sum\nof interarrival times among the first \u230at\u230b class k jobs that are filtered out, and An\nfl,k(t) be\nthe number of class k jobs that are filtered out by the filtering system up to time t, i.e.,\nAn\nfl,k(t) = PAn\n0 (t)\ni=1 I(f\u03b8(Xn\ni ) < zFL) \u00b7 Y n\nik, \u2200 k \u2208 {1, 2}. Moreover, let \u02dcUn\nfl,0(t) and \u02dcAn\nfl,k(t) be the\ncorresponding diffusion-scaled processes, defined as\n\u02dcUn\nfl,k(t) = n\u22121/2\nh\nUn\nfl,k(nt) \u2212 (\u039bnpn\nk(1 \u2212 gn\nk (zFL)))\u22121 \u00b7 nt\ni\n, \u2200 t \u2208 [0, 1], \u2200 k \u2208 {1, 2}\n\u02dcAn\nfl,k(t) = n\u22121/2\nh\nAn\nfl,k(nt) \u2212 \u039bnpn\nk(1 \u2212 gn\nk (zFL)) \u00b7 nt\ni\n, \u2200 t \u2208 [0, 1], \u2200 k \u2208 {1, 2};\n(iii) (Arrival process of the queueing system) Let Un\nps,0(t) be the partial sum of interarrival times\namong the first \u230at\u230b jobs that pass through the filtering system and arrive at the queueing\nsystem, and An\nps,0(t) be the number of jobs that pass through the filtering system and arrive at\nthe queueing system up to time t, i.e., An\nps,0(t) = PAn\n0 (t)\ni=1 I(f\u03b8(Xn\ni ) \u2265 zFL). Also, let \u02dcUn\nps,0 and\n\u02dcAn\nps,0 be the corresponding diffusion-scaled arrival process, defined as\n\u02dcUn\nps,0(t) = n\u22121/2[An\nps,0(nt) \u2212 nt \u00b7 (\u039bn\n2X\nk=1\npn\nkgn\nk (zFL))\u22121], \u2200 t \u2208 [0, 1],\n\u02dcAn\nps,0(t) = n\u22121/2[An\nps,0(nt) \u2212 nt \u00b7 \u039bn\n2X\nk=1\npn\nkgn\nk (zFL)], \u2200 t \u2208 [0, 1];\n(iv) (Arrival process of each reviewer) Let Un\nps,r(t) := P\u230at\u230b\ns=1 un\ns,r be the partial sum of interarrival\ntimes among the first \u230at\u230b jobs that are assigned to reviewer r, and An\nps,r(t) be the number of\njobs that are assigned to reviewer r up to time t, i.e., An\nps,r(t) = PAn\nps,0(t)\nj=1 Bjr. Moreover, let\n\u02dcUn\nps(t) = {\u02dcUn\nps,r(t)}r\u2208\u0393(zFL), \u02dcAn\nps(t) = { \u02dcAn\nps,r(t)}r\u2208\u0393(zFL) be the corresponding diffusion-scaled\n70",
            "source": "prompt",
            "quality_score": 0.0,
            "metadata": {
              "content_type": [
                "Result/Finding"
              ],
              "difficulty_level": 4,
              "retrieval_hints": [
                "What is the proof of the heavy traffic lower bound?",
                "How is the workload process connected to the theorem?",
                "What are the properties of the optimal solution?"
              ],
              "summary": "The chunk provides a detailed proof of the heavy traffic lower bound, analyzing the behavior of a specific function under certain conditions and establishing connections to workload processes."
            }
          },
          {
            "chunk_id": "prompt_70",
            "title": "__auto__",
            "text": "arrival process, defined as\n\u02dcUn\nps,r(t) = n\u22121/2\nh\nUn\nps,r(nt) \u2212 nt \u00b7 \u0393(zFL)\n\u039bn\nP2\nk=1 pn\nkgn\nk (zFL)\ni\n, \u2200 t \u2208 [0, 1],\n\u02dcAn\nps,r(t) = n\u22121/2\nh\nAn\nps,r(nt) \u2212 nt \u00b7 \u039bn\n\u0393(zFL)\n2X\nk=1\npn\nkgn\nk (zFL)\ni\n, \u2200 t \u2208 [0, 1];\n(v) (Split probability) Let pn\nfl,k be the probability that a job arriving at the triage system is of\nclass k and is filtered out by the filtering system, i.e., pn\nfl,k = pn\nk(1 \u2212 gn\nk (zFL)), and pn\nps be the\nprobability that a job arriving at the triage system passes through the filtering system, i.e.,\npn\nps = P2\nk=1 pn\nkgn\nk (zFL). Moreover, let pfl,k and pps be the corresponding limiting probability\ndefined as pfl,k = pk(1 \u2212 gk(zFL)) and pps = P2\nk=1 pkgk(zFL);\n(vi) (Spliting process) Let Sp fl,0(t) be the number of jobs that are filtered out by the filtering system\namong the first \u230at\u230b jobs arriving at the triage system, and Sp ps,r(t) be the number of jobs that\nare assigned to reviewer r among the first \u230at\u230b jobs arriving at the triage system. Moreover, let\nfSpfl(t) = {fSpfl,k(t)}k\u2208{1,2}, fSpps(t) = {fSpps,r(t)}r\u2208\u0393(zFL) be the corresponding diffusion-scaled\nsplitting process, defined as\nfSpfl,k(t) = n\u22121/2[Spfl,k(nt) \u2212 pn\nfl,k \u00b7 nt], \u2200 t \u2208 [0, 1], k \u2208 {1, 2}\nfSpps,r(t) = n\u22121/2[Spps,r(nt) \u2212 pn\nps \u00b7 nt\n\u0393(zFL)], \u2200 t \u2208 [0, 1].\nSimilar to Definition 8, we define processes above on [0, n] or [0, 1] for analysis simplicity. These\nprocesses can be naturally extended to [0 , +\u221e) to apply the martingale FCLT (Lemma 5) and\nFCLT for split processes from [68, Theorem 9.5.1], which yields the joint convergence result below.\nWith a slight abuse of notation, we adopt Assumption H to guarantee unform integrability of\nquantities associated with the triage system.\nLemma 28 (Joint convergence of the AI-based triage system) . Given a classifier f\u03b8, filtering\nlevel zFL, the number of hired reviewers \u0393(zFL), and a sequence of queueing systems, suppose\nthat Assumptions F, G, and H hold. Then, we have that: (i) there exists Brownian motion\n( \u02dcA0, fSpfl, fSpps) such that ( \u02dcAn\n0 , fSp\nn\nfl, fSp\nn\nps) \u21d2 ( \u02dcA0, fSpfl, fSpps) in (D\u0393(zFL)+3, W J1); (ii) there exist\ncontinuous stochastic processes ( \u02dcAfl,1, \u02dcAfl,2, \u02dcAps) such that\n( \u02dcAn\nfl,1, \u02dcAn\nfl,2, \u02dcAn\nps) \u21d2 ( \u02dcAfl,1, \u02dcAfl,2, \u02dcAps), in (D\u0393(zFL)+2, W J1),\nwhere \u02dcAfl,k(t) = pfl,k \u02dcA0(t) + fSpfl,k(\u039bt) and \u02dcAps,r(t) = pps \u02dcA0(t)\n\u0393(zFL) + fSpps,r(\u039bt); (iii) there exists contin-\nuous stochastic processes ( \u02dcUfl,1, \u02dcUfl,2, \u02dcUps) such that\n( \u02dcUn\nfl,1, \u02dcUn\nfl,2, \u02dcUn\nps) \u21d2 ( \u02dcUfl,1, \u02dcUfl,2, \u02dcUps), in (D\u0393(zFL)+2, W J1).\nProof As for (i), according to Assumption H, we have that Var[ un\n1 ] < +\u221e for each n, and\nVar[un\n1 ] converges to some constant \u03c32\nu. Then, by martingale FCLT (Lemma 5), it is easy to show\nthat ( \u02dcUn\n0 , fSp\nn\nfl, fSp\nn\nps) jointly convrges to ( \u02dcU0, fSpfl, fSpps). Here, \u02dcU0 is a zero-drift Brownian mo-\ntion with variance being some \u03c32\nu, and fSpps is a zero-drift Bronian motion with covariance matrix\nbeing \u03a3 = ( \u03c32\nr1,r2), where \u03c32\nr1,r1 = \u0393(zFL)\u22121\n\u03932(zFL) and \u03c32\nr1,r2 = \u2212 1\n\u03932(zFL), \u2200 r1 \u0338= r2. According to [68,\n71",
            "source": "prompt",
            "quality_score": 0.0,
            "metadata": {
              "content_type": [
                "Result/Finding"
              ],
              "difficulty_level": 4,
              "retrieval_hints": [
                "What is the proof of the heavy traffic lower bound?",
                "How is the workload process connected to the theorem?",
                "What are the properties of the optimal solution?"
              ],
              "summary": "The chunk provides a detailed proof of the heavy traffic lower bound, analyzing the behavior of a specific function under certain conditions and establishing connections to workload processes."
            }
          },
          {
            "chunk_id": "prompt_71",
            "title": "__auto__",
            "text": "Corollary 13.8.1], the joint convergence of ( \u02dcA0, fSpfl, fSpps) follows immediately. (ii) is a direct con-\nsequence of (i) and [68, Theorem 9.5.1]. Then, by [68, Corollary 13.8.1], (iii) is a corollary of (ii).\nWith a slight abuse of notation, we extend from Definition 8 and Section 2 in order to define\nZn\nkl,r, Rn\nl,r, V n\nps,r on the jobs that are assigned to each reviewerr. Let \u02dcZ\nn\n:= { \u02dcZ\nn\nkl,r}k,l\u2208{1,2},r\u2208[\u0393(zFL)],\n\u02dcR\nn\n:= { \u02dcR\nn\nl,r}l\u2208{1,2},r\u2208[\u0393(zFL)], \u02dcVn\nps := {\u02dcV n\nps,r}r\u2208[\u0393(zFL)] be the corresponding diffusion-scaled pro-\ncesses. As the job assignment process is independent of any other random objects by Assumption G,\nit is easy to show that {( \u02dcZ\nn\nkl,r, \u02dcR\nn\nl,r, \u02dcV n\nps,r)} are i.i.d. processes across all reviewers. Therefore, by\nindependence and Lemma 9, we can extend Lemma 8 to achieve joint convergence of ( \u02dcZ\nn\n, \u02dcR\nn\n, \u02dcVn\nps)\nover all reviewers.\nLemma 29 (Joint weak convergence of the AI-based triage system I) . Suppose that Assump-\ntions F, G, and H hold. Then, there exist Brownian motions (\u02dcZ, \u02dcR, \u02dcVps) such that\n(\u02dcZ\nn\n, \u02dcR\nn\n, \u02dcVn\nps) \u21d2 (\u02dcZ, \u02dcR, \u02dcVps), in (D7\u0393(zFL), W J1).\nNext, we claim that ( \u02dcUn\nfl,1, \u02dcUn\nfl,2, \u02dcUn\nps) and ( \u02dcZ\nn\n, \u02dcR\nn\n, \u02dcVn\nps) are independent processes under As-\nsumption F. Recall that by Definition 14, Un\nps,0(t) denotes the partial sum of interarrival times\namong the first \u230at\u230b jobs that pass throught the filtering system. Let{un\nj : j \u2208 N} and {(Xn\nj , vn\nj , Yn\nj ) :\nj \u2208 N} be the interarrival time and tuples for jobs that pass through the filtering system . Then, we\nhave that Un\nps,0(t) := P\u230at\u230b\nj=1 un\nj .\nWe first show that {un\nj : j \u2208 N} and {(Xn\nj , vn\nj , Yn\nj ) : j \u2208 N} are independent. Let {un\ni : i \u2208 N}\nand {(Xn\ni , vn\ni , Yn\ni ) : i \u2208 N} be the interarrival times and tuples for all jobs arriving at the triage\nsystem. Note that the primitive sequences {un\ni : i \u2208 N} and {(Xn\ni , vn\ni , Yn\ni ) : i \u2208 N} are independent\nby Assumption F (ii). Therefore, by construction, {un\nj : j \u2208 N} are the thinned interarrival times\nfrom {un\ni : i \u2208 N}, where each arriving job is retained independetly with equal probability pn\nps.\nMoreover, since {(Xn\ni , vn\ni , Yn\ni ) : i \u2208 N} are i.i.d. by Assumption F (i), {(Xn\nj , vn\nj , Yn\nj ) : j \u2208 N} are\nalso i.i.d., following the conditional distribution ( Xn\n1 , vn\n1 , Yn\n1 ) | f\u03b8(Xn\n1 ) \u2265 zFL. It is important to\nnote that although {un\nj : j \u2208 N} depends on {(Xn\ni , vn\ni , Yn\ni ) : i \u2208 N} (through whether a general\njob is retained, i.e., f\u03b8(Xn\ni ) \u2265 zFL), the realization of un\nj can not provide additional information\non a job that is known to have been retained and its ( Xn\nj , vn\nj , Yn\nj ): we only know that such job\nsatisfies f\u03b8(Xn\nj ) \u2265 zFL on (Xn\nj , vn\nj , Yn\nj ). Therefore, un\nj and (Xn\nj , vn\nj , Yn\nj ) are independent according\nto independence by Assumption F (ii).\nAccording to analysis above, Un\nps,0(t) and {(Xn\nj , vn\nj , Yn\nj ) : j \u2208 N} are independent, as the former\nis a function of {un\nj : j \u2208 N}. Let {(Xn\ns,r, vn\ns,r, Yn\ns,r) : s \u2208 N} be the tuples for jobs assigned to\nsome reviewer r, which is splited from {(Xn\nj , vn\nj , Yn\nj ) : j \u2208 N} according to the reviewer assignment\n{Bn\nj : j \u2208 N}. Then, since {Bn\nj : j \u2208 N} is independent of any other random objects by Assump-\ntion F, we can adopt a similar approach to establish independence between ( \u02dcUn\nfl,1, \u02dcUn\nfl,2, \u02dcUn\nps) and\n{(Xn\ns,r, vn\ns,r, Yn\ns,r) : s \u2208 N, r\u2208 [\u0393(zFL)]}, which further yields independence between ( \u02dcUn\nfl,1, \u02dcUn\nfl,2, \u02dcUn\nps)\nand ( \u02dcZ\nn\n, \u02dcR\nn\n, \u02dcVn\nps). Finally, according to Lemmas 9, 28, and 29, such independence leads to the\njoint weak convergence of the AI triage system below (Lemma 30), which extends Lemma 3.\nLemma 30 (Joint weak convergence of the AI-based triage system II) . Suppose that Assump-\ntions F, G, and H hold. Then, we have that\n( \u02dcUn\nfl,1, \u02dcUn\nfl,2, \u02dcUn\nps, \u02dcZ\nn\n, \u02dcR\nn\n, \u02dcVn\nps) \u21d2 ( \u02dcUfl,1, \u02dcUfl,2, \u02dcUps, \u02dcZ, \u02dcR, \u02dcVps), in (D8\u0393(zFL)+2, W J1).\n72",
            "source": "prompt",
            "quality_score": 0.0,
            "metadata": {
              "content_type": [
                "Result/Finding"
              ],
              "difficulty_level": 4,
              "retrieval_hints": [
                "What is the proof of the heavy traffic lower bound?",
                "How is the workload process connected to the theorem?",
                "What are the properties of the optimal solution?"
              ],
              "summary": "The chunk provides a detailed proof of the heavy traffic lower bound, analyzing the behavior of a specific function under certain conditions and establishing connections to workload processes."
            }
          },
          {
            "chunk_id": "prompt_72",
            "title": "__auto__",
            "text": "Similarly to Lemma 4, we can then strengthen the convergence to uniform topology and conduct\nsample path analysis on copies of the original processes. With a slight abuse of notation, we still\nuse (\u2126copy, Fcopy, Pcopy) to denote the common probability space.\nLemma 31 (Uniform Convergence of the AI Triage System) . Suppose that Assumptions F, G,\nand H hold. Then, there exist stochastic processes ( \u02dcUn\nfl,1, \u02dcUn\nfl,2, \u02dcUn\nps, \u02dcZ\nn\n, \u02dcR\nn\n, \u02dcVps), \u2200 n \u2265 1 and\n( \u02dcUfl,1, \u02dcUfl,2, \u02dcUps, \u02dcZ, \u02dcR, \u02dcVps) defined on a common probability space (\u2126copy, Fcopy, Pcopy) such that\n( \u02dcUn\nfl,1, \u02dcUn\nfl,2, \u02dcUn\nps, \u02dcZ\nn\n, \u02dcR\nn\n, \u02dcVps), \u2200 n \u2265 1 and ( \u02dcUfl,1, \u02dcUfl,2, \u02dcUps, \u02dcZ, \u02dcR, \u02dcVps) are identical in distribution\nwith their original counterparts and\n( \u02dcUn\nfl,1, \u02dcUn\nfl,2, \u02dcUn\nps, \u02dcZ\nn\n, \u02dcR\nn\n, \u02dcVps) \u2192 ( \u02dcUfl,1, \u02dcUfl,2, \u02dcUps, \u02dcZ, \u02dcR, \u02dcVps), in (D8\u0393(zFL)+2, \u2225 \u00b7 \u2225), Pcopy \u2212 a.s..\nG.2 Sample path analysis of each reviewer\nIn this section, we conduct sample path analysis for each reviewer. We adopt a similar analysis\napproach as in Section 3 and 4. In particular, we consider copies of the original processes defined\non the common probability space Pcopy, as shown in Lemma 31. We establish all subsequent results\nregarding almost sure convergence for the copied processes, which can then be converted back into\ncorresponding weak convergence results for the original processes.\nHeavy Traffic Condition for Each Reviewer We first show that our Assumptions F and G\nare compatible with Assumptions A and B we adopt for each single-server queueing system.\nDefinition 13. Given a classifier f\u03b8, filtering level zFL, tpxicity level zTX, the number of hired\nreviewers \u0393(zFL), and a sequence of queueing systems, suppose that Assumptions F and G hold.\nWe define the following for any system n and reviewer r:\n(i) (Class prevalence) Let pn\nk,r(zFL) be the conditional probability that a job that passes through\nthe filtering system and is assigned to reviewer r is of class k, i.e., pn\nk,r(zFL) := Pn[Y n\n1k,r =\n1 | f\u03b8(Xn\n1,r) \u2265 zFL]. Moreover, let pk(zFL) be the limiting probability, defined as pk(zFL) :=\npkgk(zFL)\np1g1(zFL)+p2g2(zFL);\n(ii) (Confusion matrix) Let qn\nkl,r(z) be the conditional probability that a class k job arriving at re-\nviewer r is predicted as class l, i.e., qn\nkl,r(z) := Pn[Y n\n1l,r = 1 | f\u03b8(Xn\n1,r) \u2265 zFL, Yn\n1k,r = 1]. More-\nover, let qkl(z) be the limiting probability, defined as qk1(zFL, zTX) = gk(zTX)\ngk(zFL) , qk2(zFL, zTX) =\ngk(zFL)\u2212gk(ztx)\ngk(zFL) , \u2200 k \u2208 {1, 2};\n(iii) (Arrival rate) Let \u03bbn\nr = \u039bn\n\u0393(zFL)[pn\n1 gn\n1 (zFL) + pn\n2 gn\n2 (zFL)] be the arrival rate of jobs assigned to\nreviewer r. Moreover, let \u03bb = \u039b\n\u0393(zFL)[p1g1(zFL) + p2g2(zFL)] be the limiting arrival rate.\nWe define the arrival rate \u03bbn\nr based on Lemma 28, which shows that n\u22121An\nps,r(nt) = \u039bnt\n\u0393(zFL) \u00b7\nP2\nk=1 pn\nkgn\nk (zFL)+o(1). According to Assumptions F and G, it is easy to verify that class prevalence,\nconfusion matrix, and arrival rate all converges to their limiting values at the rate of n1/2.\nLemma 32. Given a classifier f\u03b8, filtering level zFL, toxicity level zTX, the number of hired review-\ners \u0393(zFL), and a sequence of queueing systems, suppose that Assumptions F and G hold. Then,\nfor any k, l\u2208 {1, 2}, an reveiwer r \u2208 [\u0393(zFL)], we have that\nn1/2(\u03bbn\nr \u2212 \u03bb) \u2192 0, n 1/2(pn\nk,r(zFL) \u2212 pk(zFL)) \u2192 0, n 1/2(qn\nkl,r(z) \u2212 qkl(z)) \u2192 0.\n73",
            "source": "prompt",
            "quality_score": 0.0,
            "metadata": {
              "content_type": [
                "Result/Finding"
              ],
              "difficulty_level": 4,
              "retrieval_hints": [
                "What is the proof of the heavy traffic lower bound?",
                "How is the workload process connected to the theorem?",
                "What are the properties of the optimal solution?"
              ],
              "summary": "The chunk provides a detailed proof of the heavy traffic lower bound, analyzing the behavior of a specific function under certain conditions and establishing connections to workload processes."
            }
          },
          {
            "chunk_id": "prompt_73",
            "title": "__auto__",
            "text": "As a direct corollary of Lemma 32 and Assumption G (ii), for each reviewer r, their limiting traffic\nintensity satisfies\n\u03bb\n2X\nk=1\npk(zFL)\n\u00b5k\n= \u039b\n\u0393(zFL)[p1g1(zFL) + p2g2(zFL)] \u00b7\n2X\nk=1\npkgk(zFL)\n\u00b5k(p1g1(zFL) + p2g2(zFL)) = 1.\nTherefore, all reviewers operate under heavy traffic conditions and satisfy Assumption A and B.\nThis enables us to directly apply results for the single-server queueing system to each reviewer.\nSince the analysis is similar, we only present the main results below and skip proof details.\nEndogenous Processes of the AI-based Triage System We define the concerned endogenous\nprocesses below to analyze the AI-based triage system following Definition 11.\nDefinition 14 (Endogenous processes of the AI-based triage system). Given the filtering level zFL,\ntoxicity level zTX, and the number of hired reviewers \u0393(zFL), for each system n and reviewer r, we\ndefine the following processes:\n(i) (Input process for predicted classes) Let Ln\nl,r(t) be the total service time requested by all jobs\npredicted as classl and assigned to reviewer r by time t \u2208 [0, n], i.e., Ln\nl,r(t) = PAn\nps,r(t)\ns=1 Y n\nsl,rvn\ns,r,\nt \u2208 [0, n]. Moreover, let \u02dcL\nn\nl,r(t) be the corresponding diffusion-scaled process, defined as\n\u02dcL\nn\nl (t) = n\u22121/2\nh\nLn\nl,r(nt) \u2212 \u039bn\n\u0393(zFL)\nKX\nk=1\npn\nkgn\nk (zFL)\n\u00b5n\nk\nqn\nkl(z) \u00b7 nt\ni\n, t \u2208 [0, 1].\n(ii) (Cumulative total input process) Let Ln\n+(t; z, r) = P\nl Ln\nl,r(t), t\u2208 [0, n] be the cumulative total\ninput process and \u02dcLn\n+(t; z, r) := PK\nl=1 \u02dcL\nn\nl,r(t), t \u2208 [0, 1] be the corresponding diffusion-scaled\nprocess, i.e.,\n\u02dcLn\n+(t; z, r) = n\u22121/2\nh\nLn\n+(nt; z, r) \u2212 \u039bn\n\u0393(zFL)\nKX\nk=1\npn\nkgn\nk (zFL)\n\u00b5n\nk\n\u00b7 nt\ni\n, \u2200 t \u2208 [0, 1].\n(iii) (Policy process) Let Tn\nl,r(t) be total amount of time during [0, t] that the server r allocates to\njobs from predicted class l;\n(iv) (Remaining workload process) Let Wn\nl,r(t) be the remaining service time requested by jobs\npredicted as class l and present\u2014waiting for service or being served\u2014by reviewer r at time\nt \u2208 [0, n]\nWn\nl,r(t) = Ln\nl,r(t) \u2212 Tn\nl,r(t), t \u2208 [0, n].\nand \u02dcW\nn\nl,r(t) := n\u22121/2Wn\nl,r(nt), \u2200 t \u2208 [0, 1] be the corresponding diffusion scaled process.\n(v) (Total remaining workload process) Let Wn\n+(t; z, r) = P\nl Wn\nl,r(t) be the total remaining work-\nload p rocess and \u02dcWn\n+(t; z, r) := n\u22121/2 PK\nl=1 Wn\nl (nt; z, r), \u2200 t \u2208 [0, 1] be the corresponding\ndiffusion scaled process.\nThen, by extending Lemma 13 and Proposition 1, we have the following results for the endogenous\nprocesses of each reviewer r.\n74",
            "source": "prompt",
            "quality_score": 0.0,
            "metadata": {
              "content_type": [
                "Result/Finding"
              ],
              "difficulty_level": 4,
              "retrieval_hints": [
                "What is the proof of the heavy traffic lower bound?",
                "How is the workload process connected to the theorem?",
                "What are the properties of the optimal solution?"
              ],
              "summary": "The chunk provides a detailed proof of the heavy traffic lower bound, analyzing the behavior of a specific function under certain conditions and establishing connections to workload processes."
            }
          },
          {
            "chunk_id": "prompt_74",
            "title": "__auto__",
            "text": "Lemma 33 (Convergence of \u02dcLn\n+(t; z, r) and \u02dcWn\n+(t; z, r)). Suppose that Assumptions F, G, and H\nhold.\n(i) for a sequence of feasible policies {\u03c0n}, we have that for each reviewer r,\n\u02dcLn\n+(\u00b7; z, r) \u2192 \u02dcL+(\u00b7; z, r)in (D, \u2225 \u00b7 \u2225) Pcopy \u2212 a.s., where\n\u02dcL+(t; z, r) := \u02dcVps,r\n\u0010 \u039bt\n\u0393(zFL)[p1g1(zFL) + p2g2(zFL)]\n\u0011\n+\nKX\nk=1\npk(zFL)\n\u00b5k\n\u02dcAps,r(t), t \u2208 [0, 1].\n(ii) for a sequence of work-conserving p-FCFS feasible policy, we have that for each reviewer r,\n\u02dcWn\n+(\u00b7; z, r) \u2192 \u02dcW+(\u00b7; z, r) := \u03d5(\u02dcLn\n+(\u00b7; z, r)) in (D, \u2225 \u00b7 \u2225) Pcopy \u2212 a.s., where \u03d5 is the reflection\nmapping.\nStarting from Lemma 33, we can then follow the sample path analysis and establish Theorem 5;\nwe skip the detailed proof here.\nG.3 Simulation of the total cost of the AI-based Triage System\nAs shown in Theorem 5, the limiting total cost is solely determined by (i) the limiting exogenous\nquantities, such as arrival rate \u039b, class prevalence pk(zFL), confusion matrix qkl(zFL), etc; and (ii)\nthe limiting total workload process \u02dcW+(\u00b7; z, r). Though (i) can be easily estimated, (ii) requires a\nmore detailed analysis to assist a practical estimation.\nAccording to Lemma 33, \u02dcW+(\u00b7; z, r) is a continuous stochastic process. Therefore, it suf-\nfices to approximate the integral by a Riemann sum. In particular, we have that \u02dcW+(t; z, r) :=\n\u03d5(\u02dcLn\n+(t; z, r)), where\n\u02dcLn\n+(t; z, r) \u2192 \u02dcL+(t; z, r) := \u02dcVps,r\n\u0010 \u039bt\n\u0393(zFL)[p1g1(zFL) + p2g2(zFL)]\n\u0011\n+\nKX\nk=1\npk(zFL)\n\u00b5k\n\u02dcAps,r(t).\nIn the sequel, we analyze \u02dcAps,r(t) and \u02dcVps,r separately. By Lemma 28, we have that \u02dcAps,r(t) =\npps \u02dcA0(t)\n\u0393(zFL) + fSpps,r(\u039bt). Note that \u02dcU0 is a zero-drift Brownian motion with variance being \u03c32\nu < +\u221e\nby Assumption H, which can be estimated similarly as in Section A.2.1. Then, by [68, Corollary\n13.8.1], we have that \u02dcA0(t) = \u2212\u039b \u02dcU0(\u039bt) and\n\u02dcAps,r(t) = \u2212 \u039bpps\n\u0393(zFL)\n\u02dcU0(\u039bt) + fSpps,r(\u039bt).\nHere, fSpps is a zero-drift Bronian motion with covariance matrix being \u03a3 = (\u03c32\nr1,r2), where \u03c32\nr1,r1 =\n\u0393(zFL)\u22121\n\u03932(zFL) and \u03c32\nr1,r2 = \u2212 1\n\u03932(zFL), \u2200 r1 \u0338= r2; see discussion following [68, Theorem 9.5.1]. For \u02dcVps,r,\naccording to Assumption H, it is easy to verify that Var[ vn\ns,r] < +\u221e for each n and converges to\nsome constant \u03c32\nv(zFL) = \u03b1v,1p1(zFL)+\u03b1v,2p2(zFL)\u2212\n\u0000 1\n\u00b51\np1(zFL)+ 1\n\u00b52\np2(zFL)\n\u00012. Then, by martingale\nFCLT (Lemma 5), we have that \u02dcVps,r is a zero-drift Brownian motion with variance being \u03c32\nv(zFL).\nIn this way, we rewrite \u02dcW+(t; z, r) as a function of (multi-dimensional) Brownian motion, whose\nRiemann sum can be easily simulated.\n75",
            "source": "prompt",
            "quality_score": 0.0,
            "metadata": {
              "content_type": [
                "Result/Finding"
              ],
              "difficulty_level": 4,
              "retrieval_hints": [
                "What is the proof of the heavy traffic lower bound?",
                "How is the workload process connected to the theorem?",
                "What are the properties of the optimal solution?"
              ],
              "summary": "The chunk provides a detailed proof of the heavy traffic lower bound, analyzing the behavior of a specific function under certain conditions and establishing connections to workload processes."
            }
          }
        ],
        "metrics": {
          "method": "prompt",
          "chunk_count": 75,
          "total_chars": 221040,
          "avg_chunk_length": 2947.2,
          "processing_time": 236.4882996082306,
          "quality_scores": {
            "structure_analysis": 1.0,
            "boundary_detection": 1.0,
            "coherence_validation": 1.0,
            "metadata_enrichment": 1.0,
            "quality_validation": 1.0
          },
          "issues": []
        }
      },
      "comparison": {
        "pypdf_limitations": [
          "Returns entire document as single chunk",
          "No semantic understanding",
          "No structure preservation",
          "Poor RAG retrieval performance",
          "No metadata for filtering"
        ],
        "sherpa_limitations": [
          "Relies on visual layout which may fail",
          "No semantic reasoning for boundaries",
          "No metadata enrichment",
          "May produce single chunk on simple layouts",
          "Cannot detect implicit topic shifts"
        ],
        "prompt_advantages": [
          "Semantic understanding of document structure",
          "Intelligent boundary detection based on topic shifts",
          "Rich metadata for improved RAG retrieval",
          "Multi-pass validation ensures chunk coherence",
          "Works on any document regardless of layout",
          "Handles implicit structure without headers",
          "Proper chunk sizing with min/max constraints"
        ],
        "metrics_comparison": {
          "chunk_granularity": {
            "pypdf": 1,
            "sherpa": 0,
            "prompt": 75,
            "winner": "prompt"
          },
          "avg_chunk_size": {
            "pypdf": 221188,
            "sherpa": 0,
            "prompt": 2947.2,
            "optimal_range": "300-800 characters for RAG"
          },
          "processing_time": {
            "pypdf": 3.3191590309143066,
            "sherpa": 19.53934669494629,
            "prompt": 236.4882996082306,
            "note": "Prompt method trades speed for quality"
          }
        },
        "recommendation": "Use prompt-based chunking for high-value documents requiring accurate RAG retrieval"
      }
    },
    {
      "pypdf": {
        "chunks": [
          {
            "chunk_id": "pypdf_0",
            "title": "__entire_document__",
            "text": "KRISH SONI <sonikrish994@gmail.com>\nYour payment to Porkbun LLC is complete\nAmazon Pay <no-reply@amazon.com> Tue, Jan 6, 2026 at 9:23 AM\nTo: sonikrish994@gmail.com\nHi Krish Soni,\nWe have processed your payment of $25.97 using the payment method shown.\nThank you for using Amazon Pay.\nPurchase summary\nMerchant information\nPorkbun LLC\nsupport@porkbun.com\n+18557675286\nCharge amount $25.97 USD\nPayment method MasterCard **4823\nPayment date Tuesday, January 6, 2026 at 9:23:53 AM IST\nAmazon Pay payment IDP01-9167148-6098574\nSee your purchase details\nHow was your experience using Amazon Pay?\n Dissatisfied\n \n Neutral\n \n Satisfied\nAmazon Pay buyer support\n1/6/26, 2:21 PM Gmail - Your payment to Porkbun LLC is complete\nhttps://mail.google.com/mail/u/0/?ik=439833d2a1&view=pt&search=all&permmsgid=msg-f:1853538051892262201&simpl=msg-f:1853538051892\u2026 1/2\n\nViewing orders and transactions\nTo check all your Amazon Pay transactions, sign in to Your Amazon Pay Activity with\nyour Amazon credentials.\nHandling returns and refunds\nIf you have issues with an order, want a refund or want to exchange an item, contact\nthe merchant first. If you don\u2019t receive a reply from the merchant within three\nbusiness days, or are unable to come to an agreement, you can dispute the\ntransaction via the Buyer Dispute Program.\nNeed more help?\nIf you have additional questions about your order, contact us.\n\u00a92026 Amazon.com, Inc. or its affiliates. Amazon and all related marks are trademarks of\nAmazon.com, Inc. or its affiliates, Amazon.com, Inc. 410 Terry Avenue N., Seattle, WA\n98109.\nBy using Amazon Pay, you agree to Amazon\u2019s privacy notice and conditions of use\n\u00a9 Amazon.com, Inc. or its affiliates\nAmazon, Amazon.com, Amazon Pay, and all related logos\nare trademarks of Amazon.com, Inc. or its affiliates.\nAll other trademarks are the property of their respective owners.\nFor more information about payment processing provided by Amazon Payments, Inc., or to\nresolve a complaint related to payment processing, see Money Transmitter Licenses\n1/6/26, 2:21 PM Gmail - Your payment to Porkbun LLC is complete\nhttps://mail.google.com/mail/u/0/?ik=439833d2a1&view=pt&search=all&permmsgid=msg-f:1853538051892262201&simpl=msg-f:1853538051892\u2026 2/2",
            "source": "pypdf",
            "quality_score": 0.0
          }
        ],
        "metrics": {
          "method": "pypdf",
          "chunk_count": 1,
          "total_chars": 2222,
          "avg_chunk_length": 2222,
          "processing_time": 0.0667715072631836,
          "quality_scores": {},
          "issues": [
            "No semantic chunking - returns entire document as single chunk",
            "No structure preservation",
            "No metadata enrichment",
            "Poor for RAG retrieval"
          ]
        }
      },
      "sherpa": {
        "chunks": [],
        "metrics": {
          "method": "sherpa",
          "chunk_count": 0,
          "total_chars": 0,
          "avg_chunk_length": 0,
          "processing_time": 0.892315149307251,
          "quality_scores": {},
          "issues": [
            "Layout detection weak - produced single chunk",
            "No semantic boundary detection",
            "No metadata enrichment",
            "Relies on visual layout which may not reflect semantic structure"
          ]
        }
      },
      "prompt": {
        "chunks": [
          {
            "chunk_id": "prompt_0",
            "title": "__auto__",
            "text": "KRISH SONI <sonikrish994@gmail.com>\nYour payment to Porkbun LLC is complete\nAmazon Pay <no-reply@amazon.com> Tue, Jan 6, 2026 at 9:23 AM\nTo: sonikrish994@gmail.com\nHi Krish Soni,\nWe have processed your payment of $25.97 using the payment method shown.\nThank you for using Amazon Pay.\nPurchase summary\nMerchant information\nPorkbun LLC\nsupport@porkbun.com\n+18557675286\nCharge amount $25.97 USD\nPayment method MasterCard **4823\nPayment date Tuesday, January 6, 2026 at 9:23:53 AM IST\nAmazon Pay payment IDP01-9167148-6098574\nSee your purchase details\nHow was your experience using Amazon Pay?\n Dissatisfied\n \n Neutral\n \n Satisfied\nAmazon Pay buyer support\n1/6/26, 2:21 PM Gmail - Your payment to Porkbun LLC is complete\nhttps://mail.google.com/mail/u/0/?ik=439833d2a1&view=pt&search=all&permmsgid=msg-f:1853538051892262201&simpl=msg-f:1853538051892\u2026 1/2",
            "source": "prompt",
            "quality_score": 8.0,
            "metadata": {
              "content_type": [
                "Other"
              ],
              "difficulty_level": 1,
              "retrieval_hints": [
                "What is the payment confirmation for Krish Soni?",
                "Who processed the payment to Porkbun LLC?"
              ],
              "summary": "This chunk contains a payment confirmation email for a transaction made by Krish Soni to Porkbun LLC through Amazon Pay."
            }
          },
          {
            "chunk_id": "prompt_1",
            "title": "__auto__",
            "text": "Viewing orders and transactions\nTo check all your Amazon Pay transactions, sign in to Your Amazon Pay Activity with\nyour Amazon credentials.\nHandling returns and refunds\nIf you have issues with an order, want a refund or want to exchange an item, contact\nthe merchant first. If you don\u2019t receive a reply from the merchant within three\nbusiness days, or are unable to come to an agreement, you can dispute the\ntransaction via the Buyer Dispute Program.\nNeed more help?\nIf you have additional questions about your order, contact us.\n\u00a92026 Amazon.com, Inc. or its affiliates. Amazon and all related marks are trademarks of\nAmazon.com, Inc. or its affiliates, Amazon.com, Inc. 410 Terry Avenue N., Seattle, WA\n98109.\nBy using Amazon Pay, you agree to Amazon\u2019s privacy notice and conditions of use\n\u00a9 Amazon.com, Inc. or its affiliates\nAmazon, Amazon.com, Amazon Pay, and all related logos\nare trademarks of Amazon.com, Inc. or its affiliates.\nAll other trademarks are the property of their respective owners.\nFor more information about payment processing provided by Amazon Payments, Inc., or to\nresolve a complaint related to payment processing, see Money Transmitter Licenses\n1/6/26, 2:21 PM Gmail - Your payment to Porkbun LLC is complete\nhttps://mail.google.com/mail/u/0/?ik=439833d2a1&view=pt&search=all&permmsgid=msg-f:1853538051892262201&simpl=msg-f:1853538051892\u2026 2/2",
            "source": "prompt",
            "quality_score": 8.0,
            "metadata": {
              "content_type": [
                "Procedure",
                "Other"
              ],
              "difficulty_level": 2,
              "retrieval_hints": [
                "How to check Amazon Pay transactions?",
                "What to do if I have issues with an Amazon order?",
                "How to dispute a transaction on Amazon Pay?"
              ],
              "summary": "This section provides guidance on viewing Amazon Pay transactions, handling returns and refunds, and how to seek further assistance."
            }
          }
        ],
        "metrics": {
          "method": "prompt",
          "chunk_count": 2,
          "total_chars": 2220,
          "avg_chunk_length": 1110.0,
          "processing_time": 37.263652324676514,
          "quality_scores": {
            "structure_analysis": 1.0,
            "boundary_detection": 1.0,
            "coherence_validation": 1.0,
            "metadata_enrichment": 1.0,
            "quality_validation": 1.0
          },
          "issues": []
        }
      },
      "comparison": {
        "pypdf_limitations": [
          "Returns entire document as single chunk",
          "No semantic understanding",
          "No structure preservation",
          "Poor RAG retrieval performance",
          "No metadata for filtering"
        ],
        "sherpa_limitations": [
          "Relies on visual layout which may fail",
          "No semantic reasoning for boundaries",
          "No metadata enrichment",
          "May produce single chunk on simple layouts",
          "Cannot detect implicit topic shifts"
        ],
        "prompt_advantages": [
          "Semantic understanding of document structure",
          "Intelligent boundary detection based on topic shifts",
          "Rich metadata for improved RAG retrieval",
          "Multi-pass validation ensures chunk coherence",
          "Works on any document regardless of layout",
          "Handles implicit structure without headers",
          "Proper chunk sizing with min/max constraints"
        ],
        "metrics_comparison": {
          "chunk_granularity": {
            "pypdf": 1,
            "sherpa": 0,
            "prompt": 2,
            "winner": "prompt"
          },
          "avg_chunk_size": {
            "pypdf": 2222,
            "sherpa": 0,
            "prompt": 1110.0,
            "optimal_range": "300-800 characters for RAG"
          },
          "processing_time": {
            "pypdf": 0.0667715072631836,
            "sherpa": 0.892315149307251,
            "prompt": 37.263652324676514,
            "note": "Prompt method trades speed for quality"
          }
        },
        "recommendation": "Use prompt-based chunking for high-value documents requiring accurate RAG retrieval"
      }
    },
    {
      "pypdf": {
        "chunks": [
          {
            "chunk_id": "pypdf_0",
            "title": "__entire_document__",
            "text": "Compose\nLabels\nMoreMore\nInboxInbox 55\nStarredStarred\nSnoozedSnoozed\nSentSent\nDraftsDrafts 1616\nPurchasesPurchases 44\nPromotionsPromotions 1919\nporkbun.com | Order - Thank You - 9172\nOrder from Porkbun\nOrder placed\nOrder number\n9172013\nBased on this email\nView order\n<support@porkbun.com>\nto me\nPorkbun Support Dept.\nSearch mail\n1/6/26, 2:21 PM porkbun.com | Order - Thank You - 9172013 - sonikrish994@gmail.com - Gmail\nhttps://mail.google.com/mail/u/0/#inbox/FMfcgzQfBGdkSnJMNVDxQqSGNztHWplc 1/1",
            "source": "pypdf",
            "quality_score": 0.0
          }
        ],
        "metrics": {
          "method": "pypdf",
          "chunk_count": 1,
          "total_chars": 495,
          "avg_chunk_length": 495,
          "processing_time": 0.26740503311157227,
          "quality_scores": {},
          "issues": [
            "No semantic chunking - returns entire document as single chunk",
            "No structure preservation",
            "No metadata enrichment",
            "Poor for RAG retrieval"
          ]
        }
      },
      "sherpa": {
        "chunks": [],
        "metrics": {
          "method": "sherpa",
          "chunk_count": 0,
          "total_chars": 0,
          "avg_chunk_length": 0,
          "processing_time": 0.9568791389465332,
          "quality_scores": {},
          "issues": [
            "Layout detection weak - produced single chunk",
            "No semantic boundary detection",
            "No metadata enrichment",
            "Relies on visual layout which may not reflect semantic structure"
          ]
        }
      },
      "prompt": {
        "chunks": [],
        "metrics": {
          "method": "prompt",
          "chunk_count": 0,
          "total_chars": 0,
          "avg_chunk_length": 0,
          "processing_time": 0.061525821685791016,
          "quality_scores": {},
          "issues": [
            "Processing failed: Insufficient content for semantic chunking"
          ]
        }
      },
      "comparison": {
        "pypdf_limitations": [
          "Returns entire document as single chunk",
          "No semantic understanding",
          "No structure preservation",
          "Poor RAG retrieval performance",
          "No metadata for filtering"
        ],
        "sherpa_limitations": [
          "Relies on visual layout which may fail",
          "No semantic reasoning for boundaries",
          "No metadata enrichment",
          "May produce single chunk on simple layouts",
          "Cannot detect implicit topic shifts"
        ],
        "prompt_advantages": [
          "Semantic understanding of document structure",
          "Intelligent boundary detection based on topic shifts",
          "Rich metadata for improved RAG retrieval",
          "Multi-pass validation ensures chunk coherence",
          "Works on any document regardless of layout",
          "Handles implicit structure without headers",
          "Proper chunk sizing with min/max constraints"
        ],
        "metrics_comparison": {
          "chunk_granularity": {
            "pypdf": 1,
            "sherpa": 0,
            "prompt": 0,
            "winner": "sherpa"
          },
          "avg_chunk_size": {
            "pypdf": 495,
            "sherpa": 0,
            "prompt": 0,
            "optimal_range": "300-800 characters for RAG"
          },
          "processing_time": {
            "pypdf": 0.26740503311157227,
            "sherpa": 0.9568791389465332,
            "prompt": 0.061525821685791016,
            "note": "Prompt method trades speed for quality"
          }
        },
        "recommendation": "Use prompt-based chunking for high-value documents requiring accurate RAG retrieval"
      }
    },
    {
      "pypdf": {
        "chunks": [
          {
            "chunk_id": "pypdf_0",
            "title": "__entire_document__",
            "text": "Docusign Envelope ID: D719288F-210D-48D0-BBD2-5FE4A609623B \n \nGRANT AGREEMENT \nThe parties to this agreement (this \u201cAgreement\u201d) are: \nLONGVIEW LABS, LLC \n2261 Market Street, #4945 \nCA 94114 San Francisco \nUnited States \nRepresented by Gregory Albritton, CEO, henceforth referred to as \u201cFunder\u201d; \nAnd \nHaard Dishant Solanki (Sentio) \nKrish Vishal Soni (Sentio) \nHenceforth referred to as \u201cGrantee\u201d, referred to collectively as the \u201cParties\u201d and each individually \nas a \u201cParty\u201d. \nFunder and Grantee agree as follows: \n1. CORE TERMS \n1.1. Grant Amount. Funder commits to making available to  Grantee the total amount of $5,000 \nUSD (the \u201cFunding\u201d) in exchange for the Future Token and Investment Considerations as \ndescribed in Section 1.4 hereof. \n1.2. Use of Grant. Grantee will use the Grant funds exclusively for  the purposes stated hereby \nand in accordance with Annex I (the \u201cGrant Plan\u201d). \n1.3. Grant Term. Access to the Funding will last for  a maximum period of three (3) months (the \n\u201cGrant Term\u201d), during which both Parties will be bound by the terms of this Agreement, \nnotwithstanding the right of both Parties to negotiate an extension. \n1.4. Future Token and Investment Considerations. \na) Most Favored Nation (MFN) Status: If Grantee issues tokens or secures token -related \ninvestments for the funded project, Funder shall  receive MFN status for three (3) years from \nthis Agreement\u2019s date. \nb) MFN Terms: Funder shall be offered the most favorable terms given to any other party \nregarding token price, allocation, vesting, and special rights. \nc) Participation Right: Funder has the right to participate in any token distribution or \ninvestment round, including any simple agreements for future equity offered and/or issued by \nthe Grantee, under the best available terms. \nd) Warrant Investment: If Grantee issues tokens, the Parties shall enter into a token warrant \nwith investment terms as mutually agreed upon between  the Parties prior to the issuance of \nsuch tokens. \nDocusign Envelope ID: 7E6A308B-9A73-474A-83CF-EB707F74545E\n\nDocusign Envelope ID: D719288F-210D-48D0-BBD2-5FE4A609623B \n \ne) Notice: Grantee will promptly inform Funder of any plans for token issuance or token-\nrelated investments. \nf) Compliance: All terms are subject to applicable laws and regulations. \ng) Good Faith: Specific terms will be negotiated in good faith, considering the Funding's value \nrelative to total project funding. \n1.5. Additional Funding. The Funder may, at its sole discretion, provide additional funding during \nthe Grant Term or any agreed extension. Such additional funding will be subject to this \nAgreement's terms unless otherwise specified in writing. The Grantee must accept in writing and \nprovide a plan for the use of additional funds. \n2. COMMUNICATION AND REPORTS \n \n2.1. Contact Persons. Grantee and Funder will each appoint one (1) individual to act as principal \ncontact persons (\u201cContact Persons\u201d) for notices and other communications under this Agreement \nas listed in Annex II. Grantee and Funder may change its Contact Pers on at any time by written \nnotice to the other party. \n2.2. Reporting. Grantee will provide Funder with narrative, technical and financial reports as \nfollows: \na) Progress Reports: Grantee shall submit bi -weekly progress reports detailing the work \ncompleted, challenges encountered, and next steps. These  reports shall be due every other \nFriday by 5:00 PM IST. \nb) Financial Reports: Grantee shall submit monthly financial reports detailing the use of grant \nfunds, including itemized expenses and any remaining balance. These reports shall be due \non the last day of each month. \nc) Final Report: Upon completion of the grant term or earlier termination, Grantee shall submit \na comprehensive final report within thirty (30) days, summarizing the project outcomes, \nlessons learned, and a detailed financial statement of all grant funds used. \nd) Additional Reports: Funder may request additional reports or information as reasonably \nrequired, with Grantee to provide such reports within ten (10) business days of the request. \nAll reports shall be submitted electronically to the Funder's designated Contact Person. \n2.3. Electronic Communications. The Parties agree that all notices, disclosures and other \ncommunications pursuant to this Agreement may be submitted electronically via email. \n3. GRANT ADMINISTRATION \nDocusign Envelope ID: 7E6A308B-9A73-474A-83CF-EB707F74545E\n\nDocusign Envelope ID: D719288F-210D-48D0-BBD2-5FE4A609623B \n \n3.1. Delivery of Grant. The Funding will be deposited into a banking institution that accepts USD. \nThere also may be a need to use USDC on Ethereum, where applicable. An additional KYC doc \nwill be required if that is the chosen path. \n3.2. Funds Management. Upon receiving the Funding, Grantee will manage the Funding in \naccordance with applicable laws, the provisions of this Agreement and any other terms  agreed \nbetween the Parties in writing. \n3.3. Changed Circumstances. Grantee will notify Funder if, because of factual or changes in \ncircumstances, it is no longer possible for the Grant to serve its original purpose as described in \nthe Grant Plan. In that case, Grantee will present to Funder an alternate use of the Funding that \nwill require the Funder\u2019s written approval in order  to be accepted. If not accepted, Grantee shall \nreturn unused funds to Funder within thirty (30) calendar days of Funder rejecting  the alternate \nuse of Funding. \n4. COMPLIANCE \n4.1. Identification. Grantee agrees to and complies with the personal and/or company \nidentification requirements set forth by the Funder pursuant to  fulfilling standard KYC practices. \nFurthermore, if Grantee secures funding from its own or third party sources, Grantee  agrees to \ncomply on request from Funder with applicable laws and regulations requiring the identification of \nthe legitimate source of funds. \n4.2. Tax Compliance. Grantee acknowledges, understands and agrees that: (a) the receipt of \nthe Funding may have tax consequences for Grantee; (b) Grantee is solely responsible for \nGrantee\u2019s compliance with Grantee\u2019s tax obligations; and (c) Funder bears no liab ility or \nresponsibility with respect to any tax consequences to Grantee. \n4.3. Anti-Terrorism. Neither Grantee nor Funder will: (a) engage in illegal activities; or (b) \nprovide resources or support to, receive resources or support from, or associate in any way with \nany individual or entity that engages in drug trafficking or activities of terrorism. \n4.4. Compliance with Local Laws. \n \na) Grantee acknowledges and agrees to comply with all applicable laws, regulations, and \nrequirements in India, particularly those related to receiving foreign funding. This includes, but \nis not limited to, compliance with the Foreign Contribution (Regulation) Act, 2010 (FCRA) if \napplicable. \nb) Grantee shall be responsible for obtaining any necessary approvals, registrations, or \npermissions required under Indian law to receive and use the grant funds. \nc) Grantee shall promptly inform Funder of any legal or regulatory issues that may affect the \nreceipt or use of the grant funds. \nDocusign Envelope ID: 7E6A308B-9A73-474A-83CF-EB707F74545E\n\nDocusign Envelope ID: D719288F-210D-48D0-BBD2-5FE4A609623B \n \nd) In the event that compliance with local laws prevents or significantly impedes the use of \nthe Funding as intended, both Parties agree to negotiate in good faith to find an  alternative \nsolution or to terminate this Agreement as per Section 5.1. \ne) Funder reserves the right to suspend or terminate this Agreement if Grantee fails to comply \nwith applicable local laws and regulations. \n5. TERMINATION \n \n5.1. Grant Termination. Either Party may terminate this Agreement by providing reasonable \nnotice, without the need for provision of reasons; provided, however, that the provisions of \nSections 1.4(a) and (c) shall survive the  termination of this Agreement. The termination shall be \ncommunicated via electronic mail to the Contact Persons. Upon reception of the termination \nnotice, any unused Funding will not be spent and shall be returned to Funder within thirty (30) \ncalendar days of communicating the termination notice. \n5.2. Grant Suspension. Without prejudice to the Funder's other rights and remedies, the Funder \nmay reduce, withhold or suspend payment of any Funding due to the Grantee\u2019s failure to or delay \nin fulfilling its obligations under the Grant Plan. \n5.3. Grant Funding Recovery. If Grantee is wound up or goes into liquidation, administration, \nreceivership or bankruptcy, or enters into any compromise or other arrangement of its debts with \nits creditors, Funder will be entitled to recover any Funding  that has not been spent and/or may \nwithhold any further payments. \n6. GENERAL PROVISIONS \n \n6.1. Entire Agreement. This Agreement expresses the complete and exclusive agreement \nbetween Grantee and Funder, and supersedes any and all prior or contemporaneous written and \noral agreements, communications, or course of dealing between Grantee and Funder relating to \nits subject matter. \n6.2. Amendments. This Agreement may be amended only as stated in writing and signed by \nboth Grantee and Funder which recites that it is an amendment to this Agreement. Electronic \nsignatures are acceptable. \n6.3. Publicity - Acknowledgement of Funding. The Funder reserves the right to make public \ncommunications about the provision of a grant to Grantee, while Grantee will not make any public \ncommunications related to the Grant without the prior written consent of Funder. \n6.4. Third Party Beneficiaries. This Agreement is for the exclusive benefit of Grantee and \nFunder, and not for the benefit of any third party, including, without limitation, any partner, \nemployee, or volunteer of Grantee. \n6.5. Governing Law; Dispute Resolution. This Agreement and any dispute or claim arising out of \nor in connection with them or their subject matter or formation (including non-contractual disputes \nor claims) shall be exclusively governed by and construed in accordance with the law \nDocusign Envelope ID: 7E6A308B-9A73-474A-83CF-EB707F74545E\n\nDocusign Envelope ID: D719288F-210D-48D0-BBD2-5FE4A609623B \n \nof the United States of America and the courts of the USA shall have exclusive jurisdiction to \nsettle any dispute or claim that arises out of or in connection with this Agreement or their subject \nmatter or formation (including non- contractual disputes or claims). \n6.6. Intellectual Property Rights. Any intellectual property rights which arise in the course of the \ninvestment of the Funding by the Grantee will belong to the Grantee provided that  the Grantee \nhereby grants to the Funder a worldwide, perpetual, royalty free  license to use such intellectual \nproperty rights for any purpose directly connected with this Agreement. Besides the above \nmentioned exception, this Agreement will not grant either Party any rights over the other Party\u2019s \nintellectual property rights. In particular, neither Party will own  or assert any interest in the other \nParty\u2019s existing intellectual property rights. \n6.7. Non-infringement. The Grantee warrants that it will take all reasonable steps to ensure that \nits implementation of the Project under this Agreement will not infringe any  intellectual property \nrights of any third Party. The Grantee agrees to indemnify and hold the Funder harmless against \nall liability, loss, damage, costs and expenses (including legal costs) which the Funder may incur \nor suffer as a result of any claim of alleged or actual infringement of a third party\u2019s intellectual \nproperty rights arising out of the Grantee\u2019s negligent implementation of the Project. \n6.8. Confidentiality. Each Party will treat the other\u2019s information as confidential, keep it safe and \nnot disclose it to a third person without the original owner\u2019s prior written consent unless disclosure \nis expressly permitted by this Agreement. \n6.9. Force Majeure. Grantee will not be required to perform or be held liable for failure to perform \nif nonperformance is caused by labor strikes, work stoppages, war, hostilities, a national \nemergency, acts of God, epidemics, quarantines, natural disasters, power failures,  or any other \ncauses beyond Grantee\u2019s control. Grantee will notify and consult with Funder regarding the event \nand how to minimize its impact, and in all cases will make commercially reasonable efforts to \naddress the problem and carry out its obligations. \n6.10. Severability. If any provision of this Agreement is held to be invalid, illegal, or unenforceable \nin whole or in part, the remaining provisions shall not be affected and shall continue to be valid, \nlegal, and enforceable as though the invalid, illegal, or unenforceable parts had not been included \nin this Agreement. In the event that any provision is held to be unenforceable, the Parties agree \nto substitute such provision with a valid provision that most closely approximates the intent and \neconomic effect of the unenforceable provision. \nDocusign Envelope ID: 7E6A308B-9A73-474A-83CF-EB707F74545E\n\nDocusign Envelope ID: D719288F-210D-48D0-BBD2-5FE4A609623B \n \n- Signature Page - \n \nIN WITNESS WHEREOF, the parties have caused this Agreement to be executed by their duly \nauthorized representatives on the date of  10/26/2024 . \n \nFUNDER \nLongview Labs, LLC \n \nBy:   \n \nAuthorized Signatory \nName: Gregory Albritton \nTitle: CEO \n \nGRANTEE \nHaard Dishant Solanki (Sentio) \n \nBy:   \n \nAuthorized Signatory \nName: Haard Dishant Solanki \n \n \n \n  Krish Vishal Soni (Sentio) \n \nBy:   \n \n \nAuthorized Signatory \nName: Krish Vishal Soni \n \n \n \n- Signature Page - \nDocusign Envelope ID: 7E6A308B-9A73-474A-83CF-EB707F74545E\n\n\nDocusign Envelope ID: D719288F-210D-48D0-BBD2-5FE4A609623B \n \n \n \n \nTerms of the Grant \nTotal Grant Amount: $5,000 USD \nANNEX I \nGRANT PLAN \nPayment Schedule: One (1) lump sum payment, with potential to extend. \nUse of Grant Funding: \n- Company formation expenses; \n- Developing products, services, or features which rely on the AO  Computer, Arweave, or \nArFleet networks (the \u201cNetworks\u201d) for their main functionality, run  their core components \non the Networks, or otherwise significantly expand, strengthen and foster the adoption of \nthe Networks; \nGrant Schedule: \n- Provide biweekly updates to hi@arweaveindia.com with cc to audrey@longviewlabs.co \nand g0@longviewlabs.co. \n- Have submitted company formation documents by November 20th, 2024. \n- Show clear progress via Notion dashboard management by Arweave India. \n- Be prepared for potential further investment on or before Demo Day, which means you \nhave an investable company with required registrations, etc. \nDocusign Envelope ID: 7E6A308B-9A73-474A-83CF-EB707F74545E\n\nDocusign Envelope ID: D719288F-210D-48D0-BBD2-5FE4A609623B \n \nANNEX II \nCONTACT PERSONS \nFunder Main Contact Persons (to receive communications besides the Signatory): \naudrey@longviewlabs.co \nGrantee Main Contact Persons (to receive communications besides the Signatory): \nhaardsolanki.itm@gmail.com \nDocusign Envelope ID: 7E6A308B-9A73-474A-83CF-EB707F74545E",
            "source": "pypdf",
            "quality_score": 0.0
          }
        ],
        "metrics": {
          "method": "pypdf",
          "chunk_count": 1,
          "total_chars": 15125,
          "avg_chunk_length": 15125,
          "processing_time": 1.9193997383117676,
          "quality_scores": {},
          "issues": [
            "No semantic chunking - returns entire document as single chunk",
            "No structure preservation",
            "No metadata enrichment",
            "Poor for RAG retrieval"
          ]
        }
      },
      "sherpa": {
        "chunks": [],
        "metrics": {
          "method": "sherpa",
          "chunk_count": 0,
          "total_chars": 0,
          "avg_chunk_length": 0,
          "processing_time": 1.5562937259674072,
          "quality_scores": {},
          "issues": [
            "Layout detection weak - produced single chunk",
            "No semantic boundary detection",
            "No metadata enrichment",
            "Relies on visual layout which may not reflect semantic structure"
          ]
        }
      },
      "prompt": {
        "chunks": [
          {
            "chunk_id": "prompt_0",
            "title": "Docusign Envelope ID: D719288F-210D-48D0-BBD2-5FE4A609623B \n \nGRANT AGREEMENT \nT",
            "text": "Docusign Envelope ID: D719288F-210D-48D0-BBD2-5FE4A609623B \n \nGRANT AGREEMENT \nThe parties to this agreement (this \u201cAgreement\u201d) are: \nLONGVIEW LABS, LLC \n2261 Market Street, #4945 \nCA 94114 San Francisco \nUnited States \nRepresented by Gregory Albritton, CEO, henceforth referred to as \u201cFunder\u201d; \nAnd \nHaard Dishant Solanki (Sentio) \nKrish Vishal Soni (Sentio) \nHenceforth referred to as \u201cGrantee\u201d, referred to collectively as the \u201cParties\u201d and each individually \nas a \u201cParty\u201d. \nFunder and Grantee agree as follows: \n1. CORE TERMS \n1.1. Grant Amount. Funder commits to making available to  Grantee the total amount of $5,000 \nUSD (the \u201cFunding\u201d) in exchange for the Future Token and Investment Considerations as \ndescribed in Section 1.4 hereof. \n1.2. Use of Grant. Grantee will use the Grant funds exclusively for  the purposes stated hereby \nand in accordance with Annex I (the \u201cGrant Plan\u201d). \n1.3. Grant Term. Access to the Funding will last for  a maximum period of three (3) months (the \n\u201cGrant Term\u201d), during which both Parties will be bound by the terms of this Agreement, \nnotwithstanding the right of both Parties to negotiate an extension. \n1.4. Future Token and Investment Considerations. \na) Most Favored Nation (MFN) Status: If Grantee issues tokens or secures token -related \ninvestments for the funded project, Funder shall  receive MFN status for three (3) years from \nthis Agreement\u2019s date. \nb) MFN Terms: Funder shall be offered the most favorable terms given to any other party \nregarding token price, allocation, vesting, and special rights. \nc) Participation Right: Funder has the right to participate in any token distribution or \ninvestment round, including any simple agreements for future equity offered and/or issued by \nthe Grantee, under the best available terms. \nd) Warrant Investment: If Grantee issues tokens, the Parties shall enter into a token warrant \nwith investment terms as mutually agreed upon between  the Parties prior to the issuance of \nsuch tokens. \nDocusign Envelope ID: 7E6A308B-9A73-474A-83CF-EB707F74545E",
            "source": "prompt",
            "quality_score": 0.0,
            "metadata": {
              "content_type": [
                "Definition",
                "Procedure"
              ],
              "difficulty_level": 3,
              "retrieval_hints": [
                "What are the core terms of the grant agreement?",
                "Who are the parties involved in the grant agreement?",
                "What is the grant amount and its intended use?"
              ],
              "summary": "This document outlines the terms of a grant agreement between LONGVIEW LABS, LLC and the Grantee, detailing the grant amount, usage, and conditions related to token issuance."
            }
          },
          {
            "chunk_id": "prompt_1",
            "title": "Docusign Envelope ID: D719288F-210D-48D0-BBD2-5FE4A609623B \n \nGRANT AGREEMENT \nT",
            "text": "Docusign Envelope ID: D719288F-210D-48D0-BBD2-5FE4A609623B \n \ne) Notice: Grantee will promptly inform Funder of any plans for token issuance or token-\nrelated investments. \nf) Compliance: All terms are subject to applicable laws and regulations. \ng) Good Faith: Specific terms will be negotiated in good faith, considering the Funding's value \nrelative to total project funding. \n1.5. Additional Funding. The Funder may, at its sole discretion, provide additional funding during \nthe Grant Term or any agreed extension. Such additional funding will be subject to this \nAgreement's terms unless otherwise specified in writing. The Grantee must accept in writing and \nprovide a plan for the use of additional funds. \n2. COMMUNICATION AND REPORTS \n \n2.1. Contact Persons. Grantee and Funder will each appoint one (1) individual to act as principal \ncontact persons (\u201cContact Persons\u201d) for notices and other communications under this Agreement \nas listed in Annex II. Grantee and Funder may change its Contact Pers on at any time by written \nnotice to the other party. \n2.2. Reporting. Grantee will provide Funder with narrative, technical and financial reports as \nfollows: \na) Progress Reports: Grantee shall submit bi -weekly progress reports detailing the work \ncompleted, challenges encountered, and next steps. These  reports shall be due every other \nFriday by 5:00 PM IST. \nb) Financial Reports: Grantee shall submit monthly financial reports detailing the use of grant \nfunds, including itemized expenses and any remaining balance. These reports shall be due \non the last day of each month. \nc) Final Report: Upon completion of the grant term or earlier termination, Grantee shall submit \na comprehensive final report within thirty (30) days, summarizing the project outcomes, \nlessons learned, and a detailed financial statement of all grant funds used. \nd) Additional Reports: Funder may request additional reports or information as reasonably \nrequired, with Grantee to provide such reports within ten (10) business days of the request. \nAll reports shall be submitted electronically to the Funder's designated Contact Person. \n2.3. Electronic Communications. The Parties agree that all notices, disclosures and other \ncommunications pursuant to this Agreement may be submitted electronically via email. \n3. GRANT ADMINISTRATION \nDocusign Envelope ID: 7E6A308B-9A73-474A-83CF-EB707F74545E",
            "source": "prompt",
            "quality_score": 0.0,
            "metadata": {
              "content_type": [
                "Definition",
                "Procedure"
              ],
              "difficulty_level": 3,
              "retrieval_hints": [
                "What are the core terms of the grant agreement?",
                "Who are the parties involved in the grant agreement?",
                "What is the grant amount and its intended use?"
              ],
              "summary": "This document outlines the terms of a grant agreement between LONGVIEW LABS, LLC and the Grantee, detailing the grant amount, usage, and conditions related to token issuance."
            }
          },
          {
            "chunk_id": "prompt_2",
            "title": "Docusign Envelope ID: D719288F-210D-48D0-BBD2-5FE4A609623B \n \nGRANT AGREEMENT \nT",
            "text": "Docusign Envelope ID: D719288F-210D-48D0-BBD2-5FE4A609623B \n \n3.1. Delivery of Grant. The Funding will be deposited into a banking institution that accepts USD. \nThere also may be a need to use USDC on Ethereum, where applicable. An additional KYC doc \nwill be required if that is the chosen path. \n3.2. Funds Management. Upon receiving the Funding, Grantee will manage the Funding in \naccordance with applicable laws, the provisions of this Agreement and any other terms  agreed \nbetween the Parties in writing. \n3.3. Changed Circumstances. Grantee will notify Funder if, because of factual or changes in \ncircumstances, it is no longer possible for the Grant to serve its original purpose as described in \nthe Grant Plan. In that case, Grantee will present to Funder an alternate use of the Funding that \nwill require the Funder\u2019s written approval in order  to be accepted. If not accepted, Grantee shall \nreturn unused funds to Funder within thirty (30) calendar days of Funder rejecting  the alternate \nuse of Funding. \n4. COMPLIANCE \n4.1. Identification. Grantee agrees to and complies with the personal and/or company \nidentification requirements set forth by the Funder pursuant to  fulfilling standard KYC practices. \nFurthermore, if Grantee secures funding from its own or third party sources, Grantee  agrees to \ncomply on request from Funder with applicable laws and regulations requiring the identification of \nthe legitimate source of funds. \n4.2. Tax Compliance. Grantee acknowledges, understands and agrees that: (a) the receipt of \nthe Funding may have tax consequences for Grantee; (b) Grantee is solely responsible for \nGrantee\u2019s compliance with Grantee\u2019s tax obligations; and (c) Funder bears no liab ility or \nresponsibility with respect to any tax consequences to Grantee. \n4.3. Anti-Terrorism. Neither Grantee nor Funder will: (a) engage in illegal activities; or (b) \nprovide resources or support to, receive resources or support from, or associate in any way with \nany individual or entity that engages in drug trafficking or activities of terrorism. \n4.4. Compliance with Local Laws. \n \na) Grantee acknowledges and agrees to comply with all applicable laws, regulations, and \nrequirements in India, particularly those related to receiving foreign funding. This includes, but \nis not limited to, compliance with the Foreign Contribution (Regulation) Act, 2010 (FCRA) if \napplicable. \nb) Grantee shall be responsible for obtaining any necessary approvals, registrations, or \npermissions required under Indian law to receive and use the grant funds. \nc) Grantee shall promptly inform Funder of any legal or regulatory issues that may affect the \nreceipt or use of the grant funds. \nDocusign Envelope ID: 7E6A308B-9A73-474A-83CF-EB707F74545E",
            "source": "prompt",
            "quality_score": 0.0,
            "metadata": {
              "content_type": [
                "Definition",
                "Procedure"
              ],
              "difficulty_level": 3,
              "retrieval_hints": [
                "What are the core terms of the grant agreement?",
                "Who are the parties involved in the grant agreement?",
                "What is the grant amount and its intended use?"
              ],
              "summary": "This document outlines the terms of a grant agreement between LONGVIEW LABS, LLC and the Grantee, detailing the grant amount, usage, and conditions related to token issuance."
            }
          },
          {
            "chunk_id": "prompt_3",
            "title": "Docusign Envelope ID: D719288F-210D-48D0-BBD2-5FE4A609623B \n \nGRANT AGREEMENT \nT",
            "text": "Docusign Envelope ID: D719288F-210D-48D0-BBD2-5FE4A609623B \n \nd) In the event that compliance with local laws prevents or significantly impedes the use of \nthe Funding as intended, both Parties agree to negotiate in good faith to find an  alternative \nsolution or to terminate this Agreement as per Section 5.1. \ne) Funder reserves the right to suspend or terminate this Agreement if Grantee fails to comply \nwith applicable local laws and regulations. \n5. TERMINATION \n \n5.1. Grant Termination. Either Party may terminate this Agreement by providing reasonable \nnotice, without the need for provision of reasons; provided, however, that the provisions of \nSections 1.4(a) and (c) shall survive the  termination of this Agreement. The termination shall be \ncommunicated via electronic mail to the Contact Persons. Upon reception of the termination \nnotice, any unused Funding will not be spent and shall be returned to Funder within thirty (30) \ncalendar days of communicating the termination notice. \n5.2. Grant Suspension. Without prejudice to the Funder's other rights and remedies, the Funder \nmay reduce, withhold or suspend payment of any Funding due to the Grantee\u2019s failure to or delay \nin fulfilling its obligations under the Grant Plan. \n5.3. Grant Funding Recovery. If Grantee is wound up or goes into liquidation, administration, \nreceivership or bankruptcy, or enters into any compromise or other arrangement of its debts with \nits creditors, Funder will be entitled to recover any Funding  that has not been spent and/or may \nwithhold any further payments. \n6. GENERAL PROVISIONS \n \n6.1. Entire Agreement. This Agreement expresses the complete and exclusive agreement \nbetween Grantee and Funder, and supersedes any and all prior or contemporaneous written and \noral agreements, communications, or course of dealing between Grantee and Funder relating to \nits subject matter. \n6.2. Amendments. This Agreement may be amended only as stated in writing and signed by \nboth Grantee and Funder which recites that it is an amendment to this Agreement. Electronic \nsignatures are acceptable. \n6.3. Publicity - Acknowledgement of Funding. The Funder reserves the right to make public \ncommunications about the provision of a grant to Grantee, while Grantee will not make any public \ncommunications related to the Grant without the prior written consent of Funder. \n6.4. Third Party Beneficiaries. This Agreement is for the exclusive benefit of Grantee and \nFunder, and not for the benefit of any third party, including, without limitation, any partner, \nemployee, or volunteer of Grantee. \n6.5. Governing Law; Dispute Resolution. This Agreement and any dispute or claim arising out of \nor in connection with them or their subject matter or formation (including non-contractual disputes \nor claims) shall be exclusively governed by and construed in accordance with the law \nDocusign Envelope ID: 7E6A308B-9A73-474A-83CF-EB707F74545E",
            "source": "prompt",
            "quality_score": 0.0,
            "metadata": {
              "content_type": [
                "Definition",
                "Procedure"
              ],
              "difficulty_level": 3,
              "retrieval_hints": [
                "What are the core terms of the grant agreement?",
                "Who are the parties involved in the grant agreement?",
                "What is the grant amount and its intended use?"
              ],
              "summary": "This document outlines the terms of a grant agreement between LONGVIEW LABS, LLC and the Grantee, detailing the grant amount, usage, and conditions related to token issuance."
            }
          },
          {
            "chunk_id": "prompt_4",
            "title": "Docusign Envelope ID: D719288F-210D-48D0-BBD2-5FE4A609623B \n \nGRANT AGREEMENT \nT",
            "text": "Docusign Envelope ID: D719288F-210D-48D0-BBD2-5FE4A609623B \n \nof the United States of America and the courts of the USA shall have exclusive jurisdiction to \nsettle any dispute or claim that arises out of or in connection with this Agreement or their subject \nmatter or formation (including non- contractual disputes or claims). \n6.6. Intellectual Property Rights. Any intellectual property rights which arise in the course of the \ninvestment of the Funding by the Grantee will belong to the Grantee provided that  the Grantee \nhereby grants to the Funder a worldwide, perpetual, royalty free  license to use such intellectual \nproperty rights for any purpose directly connected with this Agreement. Besides the above \nmentioned exception, this Agreement will not grant either Party any rights over the other Party\u2019s \nintellectual property rights. In particular, neither Party will own  or assert any interest in the other \nParty\u2019s existing intellectual property rights. \n6.7. Non-infringement. The Grantee warrants that it will take all reasonable steps to ensure that \nits implementation of the Project under this Agreement will not infringe any  intellectual property \nrights of any third Party. The Grantee agrees to indemnify and hold the Funder harmless against \nall liability, loss, damage, costs and expenses (including legal costs) which the Funder may incur \nor suffer as a result of any claim of alleged or actual infringement of a third party\u2019s intellectual \nproperty rights arising out of the Grantee\u2019s negligent implementation of the Project. \n6.8. Confidentiality. Each Party will treat the other\u2019s information as confidential, keep it safe and \nnot disclose it to a third person without the original owner\u2019s prior written consent unless disclosure \nis expressly permitted by this Agreement. \n6.9. Force Majeure. Grantee will not be required to perform or be held liable for failure to perform \nif nonperformance is caused by labor strikes, work stoppages, war, hostilities, a national \nemergency, acts of God, epidemics, quarantines, natural disasters, power failures,  or any other \ncauses beyond Grantee\u2019s control. Grantee will notify and consult with Funder regarding the event \nand how to minimize its impact, and in all cases will make commercially reasonable efforts to \naddress the problem and carry out its obligations. \n6.10. Severability. If any provision of this Agreement is held to be invalid, illegal, or unenforceable \nin whole or in part, the remaining provisions shall not be affected and shall continue to be valid, \nlegal, and enforceable as though the invalid, illegal, or unenforceable parts had not been included \nin this Agreement. In the event that any provision is held to be unenforceable, the Parties agree \nto substitute such provision with a valid provision that most closely approximates the intent and \neconomic effect of the unenforceable provision. \nDocusign Envelope ID: 7E6A308B-9A73-474A-83CF-EB707F74545E",
            "source": "prompt",
            "quality_score": 0.0,
            "metadata": {
              "content_type": [
                "Definition",
                "Procedure"
              ],
              "difficulty_level": 3,
              "retrieval_hints": [
                "What are the core terms of the grant agreement?",
                "Who are the parties involved in the grant agreement?",
                "What is the grant amount and its intended use?"
              ],
              "summary": "This document outlines the terms of a grant agreement between LONGVIEW LABS, LLC and the Grantee, detailing the grant amount, usage, and conditions related to token issuance."
            }
          },
          {
            "chunk_id": "prompt_5",
            "title": "Docusign Envelope ID: D719288F-210D-48D0-BBD2-5FE4A609623B \n \nGRANT AGREEMENT \nT",
            "text": "Docusign Envelope ID: D719288F-210D-48D0-BBD2-5FE4A609623B \n \n- Signature Page - \n \nIN WITNESS WHEREOF, the parties have caused this Agreement to be executed by their duly \nauthorized representatives on the date of  10/26/2024 . \n \nFUNDER \nLongview Labs, LLC \n \nBy:   \n \nAuthorized Signatory \nName: Gregory Albritton \nTitle: CEO \n \nGRANTEE \nHaard Dishant Solanki (Sentio) \n \nBy:   \n \nAuthorized Signatory \nName: Haard Dishant Solanki \n \n \n \n  Krish Vishal Soni (Sentio) \n \nBy:   \n \n \nAuthorized Signatory \nName: Krish Vishal Soni \n \n \n \n- Signature Page - \nDocusign Envelope ID: 7E6A308B-9A73-474A-83CF-EB707F74545E",
            "source": "prompt",
            "quality_score": 8.0,
            "metadata": {
              "content_type": [
                "Definition",
                "Procedure"
              ],
              "difficulty_level": 2,
              "retrieval_hints": [
                "What is the Docusign Envelope ID for the grant agreement?",
                "Who are the authorized signatories for the grant agreement?"
              ],
              "summary": "This document outlines the execution of a grant agreement, including the authorized signatories and the Docusign Envelope IDs."
            }
          },
          {
            "chunk_id": "prompt_6",
            "title": "Docusign Envelope ID: D719288F-210D-48D0-BBD2-5FE4A609623B \n \nGRANT AGREEMENT \nT",
            "text": "Docusign Envelope ID: D719288F-210D-48D0-BBD2-5FE4A609623B \n \n \n \n \nTerms of the Grant \nTotal Grant Amount: $5,000 USD \nANNEX I \nGRANT PLAN \nPayment Schedule: One (1) lump sum payment, with potential to extend. \nUse of Grant Funding: \n- Company formation expenses; \n- Developing products, services, or features which rely on the AO  Computer, Arweave, or \nArFleet networks (the \u201cNetworks\u201d) for their main functionality, run  their core components \non the Networks, or otherwise significantly expand, strengthen and foster the adoption of \nthe Networks; \nGrant Schedule: \n- Provide biweekly updates to hi@arweaveindia.com with cc to audrey@longviewlabs.co \nand g0@longviewlabs.co. \n- Have submitted company formation documents by November 20th, 2024. \n- Show clear progress via Notion dashboard management by Arweave India. \n- Be prepared for potential further investment on or before Demo Day, which means you \nhave an investable company with required registrations, etc. \nDocusign Envelope ID: 7E6A308B-9A73-474A-83CF-EB707F74545E",
            "source": "prompt",
            "quality_score": 8.0,
            "metadata": {
              "content_type": [
                "Definition",
                "Procedure"
              ],
              "difficulty_level": 3,
              "retrieval_hints": [
                "What are the terms of the grant agreement?",
                "What is the payment schedule for the grant?",
                "What are the use cases for the grant funding?"
              ],
              "summary": "The document outlines the terms of a grant agreement, including the total grant amount, payment schedule, and specific uses for the funding."
            }
          },
          {
            "chunk_id": "prompt_7",
            "title": "Docusign Envelope ID: D719288F-210D-48D0-BBD2-5FE4A609623B \n \nGRANT AGREEMENT \nT",
            "text": "Docusign Envelope ID: D719288F-210D-48D0-BBD2-5FE4A609623B \n \nANNEX II \nCONTACT PERSONS \nFunder Main Contact Persons (to receive communications besides the Signatory): \naudrey@longviewlabs.co \nGrantee Main Contact Persons (to receive communications besides the Signatory): \nhaardsolanki.itm@gmail.com \nDocusign Envelope ID: 7E6A308B-9A73-474A-83CF-EB707F74545E",
            "source": "prompt",
            "quality_score": 8.0,
            "metadata": {
              "content_type": [
                "Definition",
                "Context"
              ],
              "difficulty_level": 2,
              "retrieval_hints": [
                "What are the contact persons for the grant agreement?",
                "What is the Docusign Envelope ID for the grant agreement?"
              ],
              "summary": "This chunk provides contact information for the main contact persons associated with a grant agreement, along with relevant Docusign Envelope IDs."
            }
          }
        ],
        "metrics": {
          "method": "prompt",
          "chunk_count": 8,
          "total_chars": 15110,
          "avg_chunk_length": 1888.75,
          "processing_time": 77.57928538322449,
          "quality_scores": {
            "structure_analysis": 1.0,
            "boundary_detection": 1.0,
            "coherence_validation": 1.0,
            "metadata_enrichment": 1.0,
            "quality_validation": 1.0
          },
          "issues": []
        }
      },
      "comparison": {
        "pypdf_limitations": [
          "Returns entire document as single chunk",
          "No semantic understanding",
          "No structure preservation",
          "Poor RAG retrieval performance",
          "No metadata for filtering"
        ],
        "sherpa_limitations": [
          "Relies on visual layout which may fail",
          "No semantic reasoning for boundaries",
          "No metadata enrichment",
          "May produce single chunk on simple layouts",
          "Cannot detect implicit topic shifts"
        ],
        "prompt_advantages": [
          "Semantic understanding of document structure",
          "Intelligent boundary detection based on topic shifts",
          "Rich metadata for improved RAG retrieval",
          "Multi-pass validation ensures chunk coherence",
          "Works on any document regardless of layout",
          "Handles implicit structure without headers",
          "Proper chunk sizing with min/max constraints"
        ],
        "metrics_comparison": {
          "chunk_granularity": {
            "pypdf": 1,
            "sherpa": 0,
            "prompt": 8,
            "winner": "prompt"
          },
          "avg_chunk_size": {
            "pypdf": 15125,
            "sherpa": 0,
            "prompt": 1888.75,
            "optimal_range": "300-800 characters for RAG"
          },
          "processing_time": {
            "pypdf": 1.9193997383117676,
            "sherpa": 1.5562937259674072,
            "prompt": 77.57928538322449,
            "note": "Prompt method trades speed for quality"
          }
        },
        "recommendation": "Use prompt-based chunking for high-value documents requiring accurate RAG retrieval"
      }
    }
  ]
}